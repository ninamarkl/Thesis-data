Publication Year,Author,Title,Publication Title,ISBN,DOI,Url,Abstract Note,Date,Date Added,Date Modified,Access Date,Pages,Publisher,Language,Manual Tags,Conference Name
2011,"Andreeva, Bistra; Wolska, Magdalena",The “fortis-lenis” distinction in Bulgarian and German,Interspeech 2011,,10.21437/Interspeech.2011-682,https://www.isca-speech.org/archive/interspeech_2011/andreeva11_interspeech.html,"The present study investigates the voicing contrast in Bulgarian and German. Analyses of two production experiments are reported. In the first experiment logatoms were constructed containing /p, t, k/ and /b, d, g/ in intervocalic position. In the second experiment one Bulgarian and one German sentence were elicited in different focus conditions resulting in different accentuation levels. Based on the obtained data we analyze the phonetic implementation of the phonological categories voiced vs. voiceless and the influence of focus condition and accentuation. It is shown, that: First, the two languages differ in the phonetic realization of /p, t, k/ but not /b, d, g/ in intervocalic position in terms of voice onset time (short lag in Bulgarian and long lag in German). Second, accentuation levels are realised in different ways in the two languages.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:13,2669-2672,ISCA,en,prosody,Interspeech 2011
2012,"Andreeva, Bistra; Barry, William; Wolska, Magdalena",Language differences in the perceptual weight of prominence-lending properties,Interspeech 2012,,10.21437/Interspeech.2012-635,https://www.isca-speech.org/archive/interspeech_2012/andreeva12_interspeech.html,"A Bulgarian and a German sentence were presented to Bulgarian and German listeners together with a question which either expected an early narrow focus or a late narrow focus. The answering sentences were manipulated so that the word in the latefocused position ranged from completely de-accented to strongly accented. The early focused position was neutral, allowing latefocus perception with late strong accentuation and early focus with de-accentuation of the late-focus position. Accentuation strength of the late position was varied by changing the duration, intensity and f0 values individually between accented and low de-accented. Subjects were asked to judge the suitability of the answers to the question. Results show the relative contribution of the three parameters to the acceptability of the word in the late focus position as focally accented or de-accented. Differences between Bulgarian and German in the relative weighting of the parameters are revealed.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:13,2426-2429,ISCA,en,prosody,Interspeech 2012
2004,"Angkititrakul, Pongtep; Baghaii, Sepideh; Hansen, John H. L.",Cluster-dependent modeling and confidence measure processing for in-set/out-of-set speaker identification,Interspeech 2004,,10.21437/Interspeech.2004-537,https://www.isca-speech.org/archive/interspeech_2004/angkititrakul04_interspeech.html,"In this paper, we propose an approach to address the problem of text-independent open-set speaker identiﬁcation. The in-set speakers are clustered into smaller subsets without merging speaker models. The Anti-Speaker or Background Model is then adapted for each subset which minimizes the identiﬁcation errors of the pseudo impostors during the training stage. Score normalization is applied to align all the in-set speaker score distributions to share a single scale. Finally, conﬁdence measure processing is used to identify in-set versus out-of-set speakers. Experiments with TIMIT and the CU-Accent corpora show an improvement in Equal Error Rate on ¢ ¢ the average of 20.28 and 8.35 over the baseline performance respectively. Finally, a probe experiment is also included that considers prosody for in-set speaker detection.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:13,2385-2388,ISCA,en,L1-or-L2,Interspeech 2004
2011,"Anumanchipalli, Gopala Krishna; Oliveira, Luís C.; Black, Alan W.",A statistical phrase/accent model for intonation modeling,Interspeech 2011,,10.21437/Interspeech.2011-36,https://www.isca-speech.org/archive/interspeech_2011/anumanchipalli11_interspeech.html,"This paper proposes a statistical phrase/accent model of voice fundamental frequency(F0) for speech synthesis. It presents an approach for automatic extraction and modeling of phrase and accent phenomena from F0 contours by taking into account their overall trends in the training data. An iterative optimization algorithm is described to extract these components, minimizing the reconstruction error of the F0 contour. This method of modeling local and global components of F0 separately is shown to be better than conventional F0 models used in Statistical Parametric Speech Synthesis (SPSS). Perceptual evaluations conﬁrm that the proposed model is signiﬁcantly better than baseline SPSS F0 models in 3 prosodically diverse tasks –read speech, radio broadcast speech and audio book speech.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:13,1813-1816,ISCA,en,prosody,Interspeech 2011
2013,"Aryal, Sandesh; Felps, Daniel; Gutierrez-Osuna, Ricardo",Foreign accent conversion through voice morphing,Interspeech 2013,,10.21437/Interspeech.2013-671,https://www.isca-speech.org/archive/interspeech_2013/aryal13_interspeech.html,"We present a voice morphing strategy that can be used to generate a continuum of accent transformations between a foreign speaker and a native speaker. The approach performs a cepstral decomposition of speech into spectral slope and spectral detail. Accent conversions are then generated by combining the spectral slope of the foreign speaker with a morph of the spectral detail of the native speaker. Spectral morphing is achieved by representing the spectral detail through pulse density modulation and averaging pulses in a pair-wise fashion. The technique is validated on parallel recordings from two ARCTIC speakers using both objective and subjective measures of acoustic quality, speaker identity and foreign accent.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:13,3077-3081,ISCA,en,L2,Interspeech 2013
2015,"Aryal, Sandesh; Gutierrez-Osuna, Ricardo",Articulatory-based conversion of foreign accents with deep neural networks,Interspeech 2015,,10.21437/Interspeech.2015-145,https://www.isca-speech.org/archive/interspeech_2015/aryal15_interspeech.html,"We present an articulatory-based method for real-time accent conversion using deep neural networks (DNN). The approach consists of two steps. First, we train a DNN articulatory synthesizer for the non-native speaker that estimates acoustics from contextualized articulatory gestures. Then we drive the DNN with articulatory gestures from a reference native speaker –mapped to the nonnative articulatory space via a Procrustes transform. We evaluate the accent-conversion performance of the DNN through a series of listening tests of intelligibility, voice identity and nonnative accentedness. Compared to a baseline method based on Gaussian mixture models, the DNN accent conversions were found to be 31% more intelligible, and were perceived more native-like in 68% of the cases. The DNN also succeeded in preserving the voice identity of the nonnative speaker.",06/09/2015,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:13,3385-3389,ISCA,en,L2,Interspeech 2015
2016,"Aryal, Sandesh; Gutierrez-Osuna, Ricardo",Comparing Articulatory and Acoustic Strategies for Reducing Non-Native Accents,Interspeech 2016,,10.21437/Interspeech.2016-1131,https://www.isca-speech.org/archive/interspeech_2016/aryal16_interspeech.html,"This article presents an experimental comparison of two types of techniques, articulatory and acoustic, for transforming nonnative speech to sound more native-like. Articulatory techniques use articulators from a native speaker to drive an articulatory synthesizer of the non-native speaker. These methods have a good theoretical justification, but articulatory measurements (e.g., via electromagnetic articulography) are difficult to obtain. In contrast, acoustic methods use techniques from the voice conversion literature to build a mapping between the two acoustic spaces, making them more attractive for practical applications (e.g., language learning). We compare two representative implementations of these approaches, both based on statistical parametric speech synthesis. Through a series of perceptual listening tests, we evaluate the two approaches in terms of accent reduction, speech intelligibility and speaker quality. Our results show that the acoustic method is more effective than the articulatory method in reducing perceptual ratings of non-native accents, and also produces synthesis of higher intelligibility while preserving voice quality.",08/09/2016,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:13,312-316,ISCA,en,L2,Interspeech 2016
2012,"Ashby, Simone; Barbosa, Sílvia; Brandão, Silvia; Ferreira, José Pedro; Janssen, Maarten; Silva, Catarina; Viaro, Mário Eduardo",A Rule Based Pronunciation Generator and Regional Accent Databank for Portuguese,,,,,"One of the major obstacles in deploying spoken language technologies (SLTs) in the developing world is a lack of key linguistic resources – e.g. electronic dictionaries, phonetically aligned corpora, pronunciation lexicons, etc. – that describe the non-dominant varieties spoken in such countries and regions. In this paper, we describe the work of the LUPo (Portuguese Unisyn Lexicon) project to model standard and non-standard varieties of spoken Portuguese from around the globe, and: (1) deliver a free, open-source tool for the automatic generation of accent-specific pronunciation lexica within the existing online lexical knowledge base, the Portal da Língua Portuguesa; and (2) provide the research and speech technology communities with a free, online, searchable database, the Portuguese RADbank, dedicated to the description of regional varieties of spoken Portuguese. Both resources are presented as bases for adapting SLTs to regional varieties spoken in the Luso-African and Luso-Asian world, as well as to non-standard varieties of Brazilian and European Portuguese.",2012,22/02/2023 10:34,22/02/2023 10:34,,,,en,L1,
,"Astrinaki, Maria; Yamagishi, Junichi; King, Simon",Reactive accent interpolation through an interactive map application,,,,,"In this paper, we present our ﬁrst prototype system for interactive accent control using HMM-based speech synthesis. In this application, voices in various English accents including American, Canadian and British, are controlled and interpolated by the user using gestures acquired via an interactive geographical map in real time. Users can choose the gender of the voices to manipulate and the accent interpolation strategy: either interpolation of all available speakers within an area or the N -nearest speakers around a point.",,22/02/2023 10:34,22/02/2023 10:34,,,,en,L1-or-L2,
2012,"Avanzi, Mathieu; Dubosson, Pauline; Schwab, Sandra; Obin, Nicolas","Accentual transfer from Swiss-German to French. a study of ""francais federal""",Interspeech 2012,,10.21437/Interspeech.2012-37,https://www.isca-speech.org/archive/interspeech_2012/avanzi12_interspeech.html,"This study aims at examining the accentual and phrasing properties of a variety of L2 French commonly called “Français Fédéral”, a variety of French spoken in Switzerland by speakers who have a Swiss-German dialect as a mother tongue. For this, we compared the data of 4 groups of 4 speakers: 2 groups of 4 native French speakers from Neuchâtel and from Paris, and 2 groups of 4 Swiss-German French speakers from Bern and Zürich. The data are semi-automatically processed, and three main prosodic features relating to accentuation and phrasing are examined: prominence distribution and metrical weight of the Phonological Phrase, respect of Phonological Phrase formation constraints (Align-XP and No-clash), and realizations of sandhis phenomena within and across the Phonological Phrases boundaries. Our findings suggest that “Français Fédéral” share several features with a lexical accentuation system rather than with a supra-lexical accentuation system.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:13,106-109,ISCA,en,prosody,Interspeech 2012
2012,"Avanzi, Mathieu; Dubosson, Pauline; Schwab, Sandra",Effects of dialectal origin on articulation rate in French,Interspeech 2012,,10.21437/Interspeech.2012-201,https://www.isca-speech.org/archive/interspeech_2012/avanzi12b_interspeech.html,"This paper compares the articulation rate of 4 varieties of French: Parisian French (PA); Swiss French spoken in Neuchâtel (NE) and French spoken by Swiss German speakers (BE and ZH) who have been living in a French-speaking environment (in Neuchâtel) for 20 years at least. The objective is twofold: to assess the differences in articulation rate between native French speakers of a standard variety (PA) and native French speakers of a regional variety (NE), and to address whether the non-native speakers (BE and ZH) exhibit a different behavior regarding their articulation rate compared with the native speakers of the corresponding variety (NE). Aside from the ""regional"" factor, this study takes into account additional factors that may have an influence on articulation rate: the gender and age of the speakers, the speech style (reading or conversational) and the number of syllables within the Accentual Phrase.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:13,651-654,ISCA,en,L1,Interspeech 2012
2008,"Badino, Leonardo; Clark, Robert A. J.; Strom, Volker",Including pitch accent optionality in unit selection text-to-speech synthesis,Interspeech 2008,,10.21437/Interspeech.2008-549,https://www.isca-speech.org/archive/interspeech_2008/badino08_interspeech.html,A signiﬁcant variability in pitch accent placement is found when comparing the patterns of prosodic prominence realized by different English speakers reading the same sentences.,22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:13,2118-2121,ISCA,en,prosody,Interspeech 2008
2012,"Badino, Leonardo; Clark, Robert A. J.; Wester, Mirjam",Towards hierarchical prosodic prominence generation in TTS synthesis,Interspeech 2012,,10.21437/Interspeech.2012-628,https://www.isca-speech.org/archive/interspeech_2012/badino12_interspeech.html,"We address the problem of identiﬁcation (from text) and generation of pitch accents in HMM-based English TTS synthesis. We show, through a large scale perceptual test, that a large improvement of the binary discrimination between pitch accented and non-accented words has no effect on the quality of the speech generated by the system. On the other side adding a third accent type that emphatically marks words that convey ”contrastive” focus (automatically identiﬁed from text) produces beneﬁcial effects on the synthesized speech. These results support the accounts on prosodic prominence that consider the prosodic patterns of utterances as hierarchical structured and point out the limits of a ﬂattening of such structure resulting from a simple accent/non-accent distinction.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:13,2398-2401,ISCA,en,prosody,Interspeech 2012
2007,"Barry, William; Andreeva, Bistra; Steiner, Ingmar",The phonetic exponency of phrasal accentuation in French and German,Interspeech 2007,,10.21437/Interspeech.2007-355,https://www.isca-speech.org/archive/interspeech_2007/barry07_interspeech.html,"The acoustic-phonetic properties of words spoken with three different levels of accentuation (de-accented, pre-nuclear and nuclear accented in broad-focus and nuclear accented in narrow-focus) are examined in question-answer elicited sentences and iterative imitations (on the syllable da) produced by six French and six German speakers. Normalised parameter values allow a comparative weighting of the properties employed in differentiating the three levels of accentuation. Clear differences are found between French and German in the weighting hierarchy of the acoustic properties.",27/08/2007,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:13,1010-1013,ISCA,en,prosody,Interspeech 2007
2013,"Behravan, Hamid; Hautamäki, Ville; Kinnunen, Tomi",Foreign accent detection from spoken Finnish using i-vectors,Interspeech 2013,,10.21437/Interspeech.2013-42,https://www.isca-speech.org/archive/interspeech_2013/behravan13_interspeech.html,"I-vector based recognition is a well-established technique in state-of-the-art speaker and language recognition but its use in dialect and accent classiﬁcation has received less attention. We represent an experimental study of i-vector based dialect classiﬁcation, with a special focus on foreign accent detection from spoken Finnish. Using the CallFriend corpus, we ﬁrst study how recognition accuracy is affected by the choices of various i-vector system parameters, such as the number of Gaussians, i-vector dimensionality and reduction method. We then apply the same methods on the Finnish national foreign language certiﬁcate (FSD) corpus and compare the results to traditional Gaussian mixture model - universal background model (GMM-UBM) recognizer. The results, in terms of equal error rate, indicate that i-vectors outperform GMM-UBM as one expects. We also notice that in foreign accent detection, 7 out of 9 accents were more accurately detected by Gaussian scoring than by cosine scoring.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:13,79-83,ISCA,en,L2,Interspeech 2013
2009,"Beňuš, Štefan",Are we `in sync': turn-taking in collaborative dialogues,Interspeech 2009,,10.21437/Interspeech.2009-618,https://www.isca-speech.org/archive/interspeech_2009/benus09b_interspeech.html,"We used a corpus of collaborative task oriented dialogues in American English to compare two units of rhythmic structure – pitch accents and syllables – within the coupled oscillator model of rhythmical entrainment in turn-taking proposed in [1]. We found that pitch accents are a slightly better fit than syllables as the unit of rhythmical structure for the model, but we also observed weak support for the model in general. Some turn-taking types were rhythmically more salient than others.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,2167-2170,ISCA,en,prosody,Interspeech 2009
2006,"Beskow, Jonas; Granström, Björn; House, David",Visual correlates to prominence in several expressive modes,Interspeech 2006,,10.21437/Interspeech.2006-375,https://www.isca-speech.org/archive/interspeech_2006/beskow06_interspeech.html,"In this paper, we present measurements of visual, facial parameters obtained from a speech corpus consisting of short, read utterances in which focal accent was systematically varied. The utterances were recorded in a variety of expressive modes including certain, confirming, questioning, uncertain, happy, angry and neutral. Results showed that in all expressive modes, words with focal accent are accompanied by a greater variation of the facial parameters than are words in non-focal positions. Moreover, interesting differences between the expressions in terms of different parameters were found.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,paper 1922-Tue3WeO.1-0,ISCA,en,prosody,Interspeech 2006
2013,"Best, Catherine T.; Shaw, Jason A.; Clancy, Elizabeth",Recognizing words across regional accents: the role of perceptual assimilation in lexical competition,Interspeech 2013,,10.21437/Interspeech.2013-504,https://www.isca-speech.org/archive/interspeech_2013/best13_interspeech.html,"Unfamiliar regional accents disrupt spoken word recognition by L2 and L1 learners and L1 adults, and confuse ASR and smart systems. Little is known, however, about which aspects of non-native accents hinder word recognition, or what processes are involved. We assessed how Australian English (AusE) listeners’ recognition of words in unfamiliar accents is affected by two types of cross-accent perceptual assimilation: 1) other-accent phones that constitute ‘deviant’ versions of the matching AusE phonemes (Category Goodness assimilation: CG); 2) phones that cross a native phonological boundary, i.e., assimilate to mismatching AusE phonemes (Category Shift: CS). Eyetracking (“visual world”) revealed the timecourse of lexical competition during online identification of words spoken in Jamaican (JaME: vowel differences from AusE) and Cockney English (CknE: consonant differences), while choosing among four printed choice words: target, onset and offset competitors, unrelated distracter. Recognition was slower, and both competitor types were considered more and longer for JaME and CknE than AusE pronunciations; these effects were stronger for CS than CG differences. We conclude that: 1) perceptual assimilation plays a key role in cross-accent word recognition; 2) lexical competition involves not only onsets but also later aspects of words; 3) vowel and consonant variations affect lexical competition similarly.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,2128-2132,ISCA,en,L1,Interspeech 2013
2015,"Bhat, Chitralekha; Kopparapu, Sunil",Viseme comparison based on phonetic cues for varying speech accents,Interspeech 2015,,10.21437/Interspeech.2015-676,https://www.isca-speech.org/archive/interspeech_2015/bhat15_interspeech.html,"Human interaction through speech is a multisensory activity, wherein the spoken audio is perceived using both auditory and visual cues. However, in the absence of auditory stimulus, speech content can be perceived through lip reading, using the dynamics of the social context. In our earlier work [1], we had presented a tool enabling hearing impaired to understand spoken speech in videos, through lip reading. During evaluation it was found that a hearing impaired person, trained to lip read Indian English was unable to lip read speech in other accents of English. We hypothesize that this difﬁculty can be attributed to a difference in viseme formation arising from underlying phonetic characteristics. In this paper, we present a comparison between auditory and visual space for the same speech utterance in English, as spoken by an Indian and a Croatian national. Results show a clear correlation between distances in the visual and auditory domain at viseme level. We then evaluate the feasibility of building visual subtitles through viseme adaptation from unknown accent to known accent.",06/09/2015,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,3412-3416,ISCA,en,L2,Interspeech 2015
2008,"Bi, Fukun; Yang, Jian; Xu, Dan",Automatic accent classification using ensemble methods,Interspeech 2008,,10.21437/Interspeech.2008-234,https://www.isca-speech.org/archive/interspeech_2008/bi08_interspeech.html,"Accent classification technologies directly influence the performance of the state-of-the-art speech recognition system. In this paper, we propose a novel scheme for accent classification, which uses decision-templates (DT) ensemble algorithm to combine base classifiers built on acoustic feature subsets. Different feature subsets can provide sufficient diversity among base classifiers, which is known as a necessary condition for improvement in ensemble performance. Compared with those methods of Majority Voting ensemble and Support Vector Machine, our ensemble scheme can achieve the highest performance. On the other hand, we investigate the possible reasons why ensemble systems can provide potential performance, in terms of diversity analysis. In our experiments, a native Mandarin speech corpus and a non-native multi-accent Mandarin speech corpus which contains three typical minorities’ accents in Yunnan, China, are adopted.",22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,755-758,ISCA,en,L1,Interspeech 2008
2011,"Biadsy, Fadi; Hirschberg, Julia; Ellis, Daniel P. W.",Dialect and accent recognition using phonetic-segmentation supervectors,Interspeech 2011,,10.21437/Interspeech.2011-285,https://www.isca-speech.org/archive/interspeech_2011/biadsy11_interspeech.html,"We describe a new approach to automatic dialect and accent recognition which exceeds state-of-the-art performance in three recognition tasks. This approach improves the accuracy and substantially lower the time complexity of our earlier phoneticbased kernel approach for dialect recognition. In contrast to state-of-the-art acoustic-based systems, our approach employs phone labels and segmentation to constrain the acoustic models. Given a speaker’s utterance, we ﬁrst obtain phone hypotheses using a phone recognizer and then extract GMM-supervectors for each phone type, effectively summarizing the speaker’s phonetic characteristics in a single vector of phone-type supervectors. Using these vectors, we design a kernel function that computes the phonetic similarities between pairs of utterances to train SVM classiﬁers to identify dialects. Comparing this approach to the state-of-the-art, we obtain a 12.9% relative improvement in EER on Arabic dialects, and a 17.9% relative improvement for American vs. Indian English dialects. We also see a 53.5% relative improvement over a GMM-UBM on American Southern vs. Non-Southern English.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,745-748,ISCA,en,L1,Interspeech 2011
2011,"Biadsy, Fadi; Wang, William Yang; Rosenberg, Andrew; Hirschberg, Julia","Intoxication detection using phonetic, phonotactic and prosodic cues",Interspeech 2011,,10.21437/Interspeech.2011-803,https://www.isca-speech.org/archive/interspeech_2011/biadsy11b_interspeech.html,"In this paper, we investigate multiple approaches for automatically detecting intoxicated speakers given samples of their speech. Intoxicated speech in a given language can be viewed simply as a different accent of this language; therefore we adopt our recent approach to dialect and accent recognition to detect intoxication. The system models phonetic structural differences across sober and intoxicated speakers. This approach employs SVM with a kernel function that computes similarities between adapted phone GMMs which summarize speakers’ phonetic characteristics in their utterances. We also investigate additional cues, such as prosodic events, phonotactics and phonetic durations under intoxicated and sober conditions. We ﬁnd that our phonetic-based system when combined with phonotactic features provides us with our best result on the ofﬁcial development set, an accuracy of 73% and an equal error rate of 26.3%, signiﬁcantly higher than the ofﬁcial baseline.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,3209-3212,ISCA,en,L1,Interspeech 2011
2019,"Biadsy, Fadi; Weiss, Ron J.; Moreno, Pedro J.; Kanvesky, Dimitri; Jia, Ye",Parrotron: An End-to-End Speech-to-Speech Conversion Model and its Applications to Hearing-Impaired Speech and Speech Separation,Interspeech 2019,,10.21437/Interspeech.2019-1789,https://www.isca-speech.org/archive/interspeech_2019/biadsy19_interspeech.html,"We describe Parrotron, an end-to-end-trained speech-to-speech conversion model that maps an input spectrogram directly to another spectrogram, without utilizing any intermediate discrete representation. The network is composed of an encoder, spectrogram and phoneme decoders, followed by a vocoder to synthesize a time-domain waveform. We demonstrate that this model can be trained to normalize speech from any speaker regardless of accent, prosody, and background noise, into the voice of a single canonical target speaker with a ﬁxed accent and consistent articulation and prosody. We further show that this normalization model can be adapted to normalize highly atypical speech from a deaf speaker, resulting in signiﬁcant improvements in intelligibility and naturalness, measured via a speech recognizer and listening tests. Finally, demonstrating the utility of this model on other speech tasks, we show that the same model architecture can be trained to perform a speech separation task.",15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,4115-4119,ISCA,en,L1-or-L2,Interspeech 2019
2006,"Bijeljac-Babic, Ranka; Dodane, Christelle; Metta, Sabine; Gérard, Claire","Productions in bilinguism, early foreign language learning and monolinguism: a prosodic comparison",Interspeech 2006,,10.21437/Interspeech.2006-412,https://www.isca-speech.org/archive/interspeech_2006/bijeljacbabic06_interspeech.html,"The degree of L2 foreign accent is likely to vary, according to the age of the acquisition, the length of contact with L2 and the possible interaction between L1 and L2. This study examined how children who master French and English at different levels pronounce disyllabic words in both languages. Acoustic analysis (F0, duration and amplitude) of syllables in disyllabic words were compared between 8 bilingual children (French-English, aged between 3;6 and 6;1 years) and 16 monolingual children (8 French children and 8 English children of the same age) and confronted to the analysis of 20 (7 years aged) early French Learners of English (FLE) children. Results showed that the bilingual children acquired prosodic patterns in both languages. However, the accent of their disyllabic words differed from those of the monolingual children. French 7 years old-aged learners of English, after only two years of acquisition, produced the native-like accent. Our findings modulate the “critical age” hypothesis and bring some new elements in favour of the L1 and L2 obligatory interaction hypothesis.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,paper 1582-Tue3CaP.4-0,ISCA,en,prosody,Interspeech 2006
2005,"Bishop, Judith; Peake, Marc; Sityaev, Dmitry",Intonational sequences in tuscan Italian,Interspeech 2005,,10.21437/Interspeech.2005-507,https://www.isca-speech.org/archive/interspeech_2005/bishop05_interspeech.html,"Sequential distributions of intonational pitch accents in a hand-labelled, read speech corpus of Tuscan Italian are analysed in relation to (1) the global frequencies of accents; (2) evidence of consistent patterns of association between accents. A subset of syntactically controlled nominal phrases are examined to determine whether the fact of their constituting a coherent syntactic unit has any effect on their patterns of sequential tone distribution, i.e. whether they are associated with a given tune. Some evidence is found for patterns of association between accents, and between sequences of accents and our chosen type of nominal phrase.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,1421-1424,ISCA,en,prosody,Interspeech 2005
2011,"Boula de Mareüil, Philippe; Rouas, Jean-Luc; Yapomo, Manuela",In search of cues discriminating West-african accents in French,Interspeech 2011,,10.21437/Interspeech.2011-280,https://www.isca-speech.org/archive/interspeech_2011/boulademareuil11_interspeech.html,"This study investigates to what extent West-African French accents can be distinguished, based on recordings made in Burkina Faso, Ivory Coast, Mali and Senegal. First, a perceptual experiment was conducted, suggesting that these accents are well identified by West-African listeners (especially the Senegal and Ivory Coast accents). Second, prosodic and segmental cues were studied by using speech processing methods such as automatic phoneme alignment. Results show that the Senegal accent (with a tendency toward word-initial stress followed by a falling pitch movement) and the Ivory Coast accent (with a tendency to delete/vocalise the /R/ consonant) are most distinct from standard French and among the West-African accents under investigation.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,725-728,ISCA,en,L1,Interspeech 2011
2008,"Bouselmi, Ghazi; Fohr, Dominique; Illina, Irina",Multi-accent and accent-independent non-native speech recognition,Interspeech 2008,,10.21437/Interspeech.2008-670,https://www.isca-speech.org/archive/interspeech_2008/bouselmi08b_interspeech.html,"In this article we present a study of a multi-accent and accentindependent non-native speech recognition. We propose several approaches based on phonetic confusion and acoustic adaptation. The goal of this article is to investigate the feasibility of multi-accent non-native speech recognition without detecting the origin of the speaker. Tests on the HIWIRE corpus show that multi-accent pronunciation modeling and acoustic adaptation reduce the WER by up to 76% compared to results of canonical models of the target language. We also investigate accentindependent approaches in order to assess the robustness of the proposed methods to unseen foreign accents. Experiments show that our approaches correctly handle unseen accents and give up to 55% WER reduction, compared to the models of the target language. Finally, the proposed pronunciation modeling approach maintains the recognition accuracy on canonical native speech as assessed by our experiments on the TIMIT corpus.",22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,2703-2706,ISCA,en,L1-or-L2,Interspeech 2008
2004,"Brahimi, Belynda; Mareuil, Philippe Boula de; Gendrot, Cedric",Role of segmental and suprasegmental cues in the perception of Maghrebian-accented French,Interspeech 2004,,10.21437/Interspeech.2004-153,https://www.isca-speech.org/archive/interspeech_2004/brahimi04_interspeech.html,"The general objective of this study is to clear up the relative importance of prosody in the identification of a foreign accent. The methodology we propose, based on the prosody transplantation paradigm, can be applied to different languages or language varieties. Here, it is applied to Magrhrebianaccented French: we wanted to study what is perceived when the segmental and suprasegmental characteristics of Maghrebian and native French speakers are crossed. Results obtained with French listeners (accent degree rating task) and Algerian listeners (origin identification task) converge and suggest that the articulation of phonemes overrides prosody to account for Maghrebian accents in French.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,341-344,ISCA,en,L2,Interspeech 2004
2012,"Braun, Bettina",Where to associate stressed additive particles? evidence from speech prosody,Interspeech 2012,,10.21437/Interspeech.2012-208,https://www.isca-speech.org/archive/interspeech_2012/braun12_interspeech.html,"Theoretical approaches mostly associate stressed additive particles (e.g., auch in German) with contrastive topics. Empirical data show that these associated constituents (ACs) are produced more prominently than unassociated ones; however, they are not produced as contrastive topics. This paper compares the prosodic realizations of ACs, contrastive and non-contrastive topics. We found no differences in accent types but later alignment for contrastive than non-contrastive topics; ACs lie in-between. An unrestricted sentence completion task tested whether listeners produce more additive particles upon hearing fragments with contrastive compared to non-contrastive topics. Completions containing additive particles were generally very rare, but crucially more frequent in sentences with a contrastive topic compared to a non-contrastive topic. We conclude that stressed additive particles associate with prominent accents, which may often be contrastive topics.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,679-682,ISCA,en,prosody,Interspeech 2012
2013,"Braun, Bettina; Asano, Yuki","Double contrast is signalled by prenuclear and nuclear accent types alone, not by f0-plateaux",Interspeech 2013,,10.21437/Interspeech.2013-80,https://www.isca-speech.org/archive/interspeech_2013/braun13b_interspeech.html,"In two speeded acceptability experiments we tested which combination of prenuclear accent, nuclear accent and f0interpolation between them is best suited to signal a double contrast in German (i.e., a contrastive topic followed by a contrastive focus). The experimental utterances differed in the prenuclear accent (medial- vs. late-peak, i.e., L+H* vs. L*+H), the nuclear accent (early- vs. medial-peak, i.e., H+L* vs. H*) and the f0-interpolation between them (high or dipping). All utterances were judged for their acceptability in a contrastive (Experiment 1) and a non-contrastive context (control Experiment 2). Our results showed that the combination of a late-peak prenuclear accent (L*+H) and an early-peak nuclear accent (H+L*) is best suited to signal a double contrast, independent of the f0-interpolation. The reaction time data also support the view that the f0-interpolation is not necessary for the interpretation of a double contrast.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,263-266,ISCA,en,prosody,Interspeech 2013
2005,"Brenier, Jason M.; Cer, Daniel M.; Jurafsky, Daniel",The detection of emphatic words using acoustic and lexical features,Interspeech 2005,,10.21437/Interspeech.2005-576,https://www.isca-speech.org/archive/interspeech_2005/brenier05_interspeech.html,"In this study, we describe an automatic detector for prosodically salient or emphasized words in speech. Knowledge of whether a word is emphatic or not could improve Text-to-Speech synthesis as well as spoken language summarization. Previous work on emphasis detection has focused on the automatic recognition of pitch accents. Our model extends earlier research by automatically identifying emphatic pitch accents, a subset of pitch accents that mark special discourse functions with extreme degrees of salience. The overall best performance achieved by our system was 87.8% correct, 8.0% above baseline performance. The results of a feature selection algorithm show that the top-performing features in our models are primarily acoustic measures. Our work identiﬁes important cues for emphasis in speech and shows that it is possible for an automated system to distinguish between two levels of perceived prominence in pitch accents with a high degree of accuracy.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,3297-3300,ISCA,en,prosody,Interspeech 2005
2018,"Bruguier, Antoine; Zen, Heiga; Arkhangorodsky, Arkady",Sequence-to-sequence Neural Network Model with 2D Attention for Learning Japanese Pitch Accents,Interspeech 2018,,10.21437/Interspeech.2018-1381,https://www.isca-speech.org/archive/interspeech_2018/bruguier18_interspeech.html,"Many Japanese text-to-speech (TTS) systems use word-level pitch accents as one of their prosodic features. Combination of a pronunciation dictionary including lexical pitch accents and a statistical model representing the word accent sandhi is often used to predict pitch accents from a text. However, using human transcribers to build the dictionary and training data for the model is tedious and expensive. This paper proposes a neural pitch accent recognition model. This model combines the information from audio, and its transcription (word sequence in hiragana characters) via two-dimensional attention and outputs word-level pitch accents. Experimental results show a reduction in the word pitch accent prediction error rate over that with text only. It lowers the load of human annotators when building a pronunciation dictionary. As the approach is general, it can be used to do pronunciation learning in other languages as well.",02/09/2018,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,1284-1287,ISCA,en,prosody,Interspeech 2018
2013,"Brunellière, Angèle; Dufour, Sophie",Electrophysiological evidence for benefits of imitation during the processing of spoken words embedded in sentential contexts,Interspeech 2013,,10.21437/Interspeech.2013-356,https://www.isca-speech.org/archive/interspeech_2013/brunelliere13_interspeech.html,"This event-related potential study examined the impact of imitating an unfamiliar accent on the processing of spoken words embedded in sentential contexts produced in that accent. The cloze probability effect in two groups of southern French speakers after they had to either listen to or imitate sentences spoken by a Belgian French speaker was tested. Speakers who did not imitate the unfamiliar accent showed a cloze probability effect on the phonological N200 wave, while those who did imitate the accent showed no effect on this component. Over a later time window, both groups showed a cloze probability effect on the N400, which is associated with lexical and semantic processing. Taken together, these results give clear evidence for processing benefits from the imitation of speech patterns, particularly at an acoustic/phonological level of processing.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,1345-1349,ISCA,en,prosody,Interspeech 2013
2014,"Cernak, Milos; Lazaridis, Alexandros; Garner, Philip N.; Motlicek, Petr",Stress and accent transmission in HMM-based syllable-context very low bit rate speech coding,Interspeech 2014,,10.21437/Interspeech.2014-587,https://www.isca-speech.org/archive/interspeech_2014/cernak14_interspeech.html,"In this paper, we propose a solution to reconstruct stress and accent contextual factors at the receiver of a very low bitrate speech codec built on recognition/synthesis architecture. In speech synthesis, accent and stress symbols are predicted from the text, which is not available at the receiver side of the speech codec. Therefore, speech signal-based symbols, generated as syllable-level log average F0 and energy acoustic measures, quantized using a scalar quantization, are used instead of accentual and stress symbols for HMM-based speech synthesis. Results from incremental real-time speech synthesis conﬁrmed, that a combination of F0 and energy signal-based symbols can replace their counterparts of text-based binary accent and stress symbols developed for text-to-speech systems. The estimated transmission bit-rate overhead is about 14 bits/second per acoustic measure.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,2799-2803,ISCA,en,prosody,Interspeech 2014
2005,"Chen, Aoju; Os, Els den",Effects of pitch accent type on interpreting information status in synthetic speech,Interspeech 2005,,10.21437/Interspeech.2005-600,https://www.isca-speech.org/archive/interspeech_2005/chen05d_interspeech.html,"Unit selection synthesis has made it possible to produce speech with high quality. However, because it allows little control over intonation, it may produce speech with contextually inappropriate intonation. In the signalling of information status, intonation, in particular, choice of pitch accent, has been taken into account in a number of dialogue systems. Previous research shows that this can improve the perceived intonational appropriateness of synthetic speech. Using an eye-tracking paradigm, this study investigates how pitch accents H*L and L*H and deaccentuation affect the interpretation of information status in synthetic speech in English. It was found that H*L biases listeners’ interpretation to new information but L*H, like deaccentuation, biases listeners’ interpretation to given information. These results indicate that listeners can and do make use of intonational cues in the interpretation of information status in synthetic speech and lend strong support to the integration of intonational signalling of information status into unit selection synthesis.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,1913-1916,ISCA,en,prosody,Interspeech 2005
2014,"Chen, Mingming; Yang, Zhanlei; Zheng, Hao; Liu, Wenju",Improving native accent identification using deep neural networks,Interspeech 2014,,10.21437/Interspeech.2014-486,https://www.isca-speech.org/archive/interspeech_2014/chen14k_interspeech.html,"In this paper, we utilize deep neural networks(DNNs) to automatically identify native accents in English and Mandarin when no text, speaker or gender information is available for the speech data. Compared to the Gaussian mixture model(GMM) based conventional methods, the proposed method beneﬁts from two main advantages: ﬁrst, DNNs are discriminative models which can provide better discrimination on confusion regions of different accents; second, they have the hierarchical nonlinear feature extraction capability which can learn discriminative high-level features for the speciﬁed task. In detail, the speech data of all accents is used to train DNNs, and in the testing stage, we ﬁrst identify the accent label of each frame, then determine the sentence label by the majority voting conducted on the frame labels. The experiments on accented English and Mandarin corpus demonstrate that, compared to the GMM based methods, our proposed method can signiﬁcantly improve the frame accuracy as well as sentence accuracy on the test set. Moreover, the performance of the proposed method can be further improved by using context information.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,2170-2174,ISCA,en,L1,Interspeech 2014
2015,"Chen, Mingming; Yang, Zhanlei; Liang, Jizhong; Li, Yanpeng; Liu, Wenju",Improving deep neural networks based multi-accent Mandarin speech recognition using i-vectors and accent-specific top layer,Interspeech 2015,,10.21437/Interspeech.2015-718,https://www.isca-speech.org/archive/interspeech_2015/chen15s_interspeech.html,"In this paper, we propose a method that use i-vectors and model adaptation techniques to improve the performance of deep neural networks(DNNs) based multi-accent Mandarin speech recognition. I-vectors which are speaker-speciﬁc features have been proved to be effective when used in accent identiﬁcation. They can be used in company with conventional spectral features as the input features of DNNs to improve the discrimination for different accents. Meanwhile, we adapt DNNs to different accents by using an accent-speciﬁc top layer and shared hidden layers. The accent-speciﬁc top layer is used to adapt to different accents while the share hidden layers which can be seen as feature extractors can extract discriminative highlevel features between different accents. These two techniques are complementary and can be easily combined together. Our experiments on the 400-hours Intel Accented Mandarin Speech Recognition Corpus show that our proposed method can signiﬁcantly improve the performance of DNNs-based accented Mandarin speech recognition.",06/09/2015,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,3620-3624,ISCA,en,L1,Interspeech 2015
2013,"Cheng, Jian; Bojja, Nikhil; Chen, Xin",Automatic accent quantification of indian speakers of English,Interspeech 2013,,10.21437/Interspeech.2013-579,https://www.isca-speech.org/archive/interspeech_2013/cheng13_interspeech.html,"In addition to measuring job candidates spoken English proﬁciency, quantifying the degree of accentedness may help companies assign employees to appropriate job categories, or identify employees who could beneﬁt from additional speech training. In this paper, we discuss methods for automatic accent quantiﬁcation of Indian English speakers. Similar to techniques used in speaker recognition, we used Gaussian mixture models (GMMs) for the modeling of accent spectral characteristics in different groups of subjects. Computationally, we veriﬁed that certain consonants in Indian English have more discriminative power than others in quantifying an Indian accent. As a result, we propose the idea of using GMMs to model only certain phonemes with high predictive power. By combining features from GMMs with others, we achieved a human-machine correlation coefﬁcient of 0.84 at the participant level. The results validate the use of new proposed methods to quantify accents automatically.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:14,2574-2578,ISCA,en,L2,Interspeech 2013
2018,"Chodroff, Eleanor; Cole, Jennifer","Information Structure, Affect and Prenuclear Prominence in American English",Interspeech 2018,,10.21437/Interspeech.2018-1529,https://www.isca-speech.org/archive/interspeech_2018/chodroff18_interspeech.html,"The influence of information structure (IS: givenness, accessibility, newness and focus) on pitch accent assignment and acoustic prominence measures of prenuclear words was investigated for American English speech elicited through read production of mini-stories. Results showed a consistent pattern of accenting the initial content word in the sentence, supporting an analysis of prenuclear accent as structural, or ‘rhythmic’. While no association was observed between IS and accent type (e.g., H*, L*, L+H*, L*+H), the acoustic-phonetic realization of prominence was modulated by information structure. In particular, words that carry contrastive focus generally showed more extreme f0 excursions relative to the average. In addition, there was a strong influence of speaking style or ‘affect’ on both pitch accent type and the acoustic-phonetic realization of prominence. Speakers were more likely to produce L+H* accents in a lively than a neutral speaking style. Differences in affect were also strongly reflected in f0 excursion, duration, and amplitude within the target word. Overall, this study indicates both linguistic (information structure) and paralinguistic (affect) influences on the phonetic implementation of prenuclear prominence, with varying influence of these two factors on the phonological assignment of prenuclear pitch accents.",02/09/2018,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,1848-1852,ISCA,en,prosody,Interspeech 2018
2004,"Chung, Sungyup; Hirose, Keikichi; Minematsu, Nobuaki",N-gram language modeling of Japanese using bunsetsu boundaries,Interspeech 2004,,10.21437/Interspeech.2004-355,https://www.isca-speech.org/archive/interspeech_2004/chung04b_interspeech.html,"A new scheme of N-gram language modeling was proposed for Japanese, where word N-grams were calculated separately for the two cases: crossing and not crossing bunsetsu boundaries. Here, bunsetsu is a basic grammatical (and pronunciation) unit of Japanese. A similar scheme using accent phrase boundaries instead of bunsetsu boundaries has already been proposed by the authors with a certain success, but it suffered from the training data shortage, because assignment of accent phrase boundaries requires a speech corpus. In contrast, bunsetsu boundaries can be detected automatically from a written text with a rather high accuracy using a parser. It was shown from the experiment that a perplexity reduction was possible by estimating bunsetsu boundaries from the history longer than N-1 words in the case of N-gram modeling and by selecting one from two types of models (crossing and not crossing bunsetsu boundaries) according to the estimation. When 1 or 3 years of Mainichi Newspaper corpus was used for the training of tri-grams, the proposed scheme could reduce the perplexity by around 8% from the baseline modeling (without separation). The proposed language modeling was applied to a continuous speech recognition, and it showed that an improvement in word recognition rate was possible especially when the training corpus was small (1 year of newspaper).",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,993-996,ISCA,en,prosody,Interspeech 2004
2022,"Chung, Raymond; Mak, Brian",Synthesizing Near Native-accented Speech for a Non-native Speaker by Imitating the Pronunciation and Prosody of a Native Speaker,Interspeech 2022,,10.21437/Interspeech.2022-11124,https://www.isca-speech.org/archive/interspeech_2022/chung22_interspeech.html,"This paper investigates how to reduce foreign accent in the synthesis of native (L1) speech for a non-native (L2) speaker. We focus on two major aspects of foreign accents: mispronunciations and improper prosody (rhythm, phonemes duration, and pauses). Firstly, to reduce mispronunciations, the melspectrograms generated by an L2 text-to-speech (TTS) model are fed to a pre-trained speech recognizer and the mispronunciation information is fed back to the TTS model during back-propagation to help the model learn correct native melspectrograms. Secondly, to imitate L1 speech prosody, a recent data augmentation (DA) technique originally proposed for speaking style transfer is applied to transfer L1 speaking style to L2 speakers. The DA technique creates additional L2 speeches when L2 speakers try to imitate L1 speeches. Automatic speech recognition on native-accented speeches synthesized from nonnative speakers by the proposed method gives a lower word error rate. The speaker embeddings produced by a pre-trained speaker veriﬁer from the original L2 speakers’ speech and their synthesized speech are highly similar. Finally, subjective MOS scores on the synthesized speech show that they have good quality and reduced accentedness.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,4302-4306,ISCA,en,L2,Interspeech 2022
2004,"Cincarek, Tobias; Gruhn, Rainer; Nakamura, Satoshi",Speech recognition for multiple non-native accent groups with speaker-group-dependent acoustic models,Interspeech 2004,,10.21437/Interspeech.2004-569,https://www.isca-speech.org/archive/interspeech_2004/cincarek04_interspeech.html,"In this paper, the recognition performance for non-native English speech with two different kinds of speaker-groupdependent acoustic models is investigated. The approaches for creating speaker groups include knowledge-based grouping of non-native speakers by their ﬁrst language, and the automatic clustering of speakers. Clustering is based on speakerdependent acoustic models in speaker Eigenspace. The acoustic model for each speaker group is obtained by bootstrapping with pre-segmented speech data or adaptation of a speakerindependent native baseline model. For the decoding of a nonnative speaker’s utterance not seen during the training or adaptation phase, the selection of a model suitable to cope with the accent characteristics of that speaker is necessary. Here, ideal selection via an oracle and parallel decoding are examined. Evaluation is conducted in a hotel reservation task for ﬁve major accent groups, including German, French, Indonesian, Chinese and Japanese speakers. Recognition results with speakerdependent and an accent-independent non-native model will also be reported.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,1509-1512,ISCA,en,L2,Interspeech 2004
2006,"Clarke, Constance; Jurafsky, Daniel",Limitations of MLLR adaptation with Spanish-accented English: an error analysis,Interspeech 2006,,10.21437/Interspeech.2006-342,https://www.isca-speech.org/archive/interspeech_2006/clarke06_interspeech.html,"We studied the effect of MLLR adaptation with Spanishaccented English to understand the strengths and weaknesses of MLLR with unseen foreign accents. We trained a global MLLR transform on 10 adaptation sentences per speaker, giving a 3.4% absolute decrease in phone error rate. We then studied the pattern of improvements across phones and phone classes. Phones that improved the least tended to be those that do not exist in Spanish. Results suggest the poorer performance is related to increased insertion and substituter rates during the adaptation phase, as well as greater acoustic variability.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,paper 1611-Tue2BuP.7-0,ISCA,en,L2,Interspeech 2006
2011,"Cole, Jennifer; Shattuck-Hufnagel, Stefanie",The phonology and phonetics of perceived prosody: what do listeners imitate?,Interspeech 2011,,10.21437/Interspeech.2011-395,https://www.isca-speech.org/archive/interspeech_2011/cole11_interspeech.html,"An imitation experiment tests the hypothesis that when asked to reproduce a spontaneously-spoken utterance that they hear, speakers imitate the prosody of the stimulus in its phonological structure more accurately than the phonetic details. Results suggest that speakers rarely distort the presence of a pitch accent or an intonational phrase boundary, but more often change the nature of the phonetic cues, e.g. the duration of a pause or the occurrence of irregular pitch periods associated with boundaries and accents in American English. These findings argue for an encoding of phonological prosodic structure that is separate from the phonetic cues that signal that structure.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,969-972,ISCA,en,prosody,Interspeech 2011
2013,"Cruz, Marisa; Frota, Sónia",On the relation between intonational phrasing and pitch accent distribution. evidence from European Portuguese varieties,Interspeech 2013,,10.21437/Interspeech.2013-88,https://www.isca-speech.org/archive/interspeech_2013/cruz13_interspeech.html,"Intonational phrasing and pitch accent distribution (PAD) have been proposed to be interdependent (Portuguese) and independent properties of prosodic systems (Egyptian). This paper examines the relation between intonational phrasing and pitch accent distribution in two center-southern varieties of European Portuguese - Alentejo (Ale) and Algarve (Alg). Sentences obtained in a reading task systematically varied syntactic complexity (presence/absence of branching in subjects and objects) and length (in number of syllables). The results showed that (S)(VO) prevails in Ale, whereas in Alg (SVO) is preferred as in Standard European Portuguese (SEP). Unlike in SEP, both in Ale and Alg nearly every prosodic word is pitch accented, yielding a dense PAD. If in Ale intonational phrasing and PAD seem to be correlated (more phrases, dense PAD) the same does not apply in Alg (fewer phrases, but dense PAD). Our findings favor the view of phrasing and PAD as orthogonal dimensions to take into account in a description of prosodic variation within and across languages.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,300-304,ISCA,en,prosody,Interspeech 2013
2005,"Dalton, Martha; Ní Chasaide, Ailbhe",Peak timing in two dialects of connaught irish,Interspeech 2005,,10.21437/Interspeech.2005-496,https://www.isca-speech.org/archive/interspeech_2005/dalton05_interspeech.html,A comparison of the peak location in nuclear and initial prenuclear accents was carried out for two closely related dialects of Connaught Irish: Cois Fharraige and Inis Oirr. This was done across conditions where the number of unstressed syllables following the nuclear and preceding the initial prenuclear accents was varied from 2-0. Clear differences in peak timing emerged between the two dialects. In Cois Fharraige Irish the timing of the peak is unaffected by the presence and/or number of adjacent unstressed syllables. In Inis Oirr Irish there is variability in peak timing for both prenuclear and nuclear positions. In nuclear position Inis Oirr peak realizations for the different conditions range from the left edge of the accented vowel to the post accented vowel. In prenuclear position realizations range from the left-edge of the accented vowel as far as the right edge of the post accented syllable.,04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,1377-1380,ISCA,en,prosody,Interspeech 2005
2008,"D'Arcy, Shona; Russell, Martin J.",Experiments with the ABI (accents of the british isles) speech corpus,Interspeech 2008,,10.21437/Interspeech.2008-137,https://www.isca-speech.org/archive/interspeech_2008/darcy08_interspeech.html,,22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,293-296,ISCA,en,L1,Interspeech 2008
2020,"Das, Anurag; Zhao, Guanlong; Levis, John; Chukharev-Hudilainen, Evgeny; Gutierrez-Osuna, Ricardo",Understanding the Effect of Voice Quality and Accent on Talker Similarity,Interspeech 2020,,10.21437/Interspeech.2020-2910,https://www.isca-speech.org/archive/interspeech_2020/das20_interspeech.html,"This paper presents a methodology to study the role of nonnative accents on talker recognition by humans. The methodology combines a state-of-the-art accent-conversion system to resynthesize the voice of a speaker with a different accent of her/his own, and a protocol for perceptual listening tests to measure the relative contribution of accent and voice quality on speaker similarity. Using a corpus of non-native and native speakers, we generated accent conversions in two different directions: non-native speakers with native accents, and native speakers with non-native accents. Then, we asked listeners to rate the similarity between 50 pairs of real or synthesized speakers. Using a linear mixed effects model, we ﬁnd that (for our corpus) the effect of voice quality is ﬁve times as large as that of non-native accent, and that the effect goes away when speakers share the same (native) accent. We discuss the potential signiﬁcance of this work in earwitness identiﬁcation and sociophonetics.",25/10/2020,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,1763-1767,ISCA,en,L1-or-L2,Interspeech 2020
2021,"Das, Nilaksh; Bodapati, Sravan; Sunkara, Monica; Srinivasan, Sundararajan; Chau, Duen Horng",Best of Both Worlds: Robust Accented Speech Recognition with Adversarial Transfer Learning,Interspeech 2021,,10.21437/Interspeech.2021-1888,https://www.isca-speech.org/archive/interspeech_2021/das21b_interspeech.html,"Training deep neural networks for automatic speech recognition (ASR) requires large amounts of transcribed speech. This becomes a bottleneck for training robust models for accented speech which typically contains high variability in pronunciation and other semantics, since obtaining large amounts of annotated accented data is both tedious and costly. Often, we only have access to large amounts of unannotated speech from different accents. In this work, we leverage this unannotated data to provide semantic regularization to an ASR model that has been trained only on one accent, to improve its performance for multiple accents. We propose Accent Pre-Training (Acc-PT), a semi-supervised training strategy that combines transfer learning and adversarial training. Our approach improves the performance of a state-of-the-art ASR model by 33% on average over the baseline across multiple accents, training only on annotated samples from one standard accent, and as little as 105 minutes of unannotated speech from a target accent.",30/08/2021,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,1314-1318,ISCA,en,L1-or-L2,Interspeech 2021
2008,"Dashiell, Amy; Hutchinson, Brian; Margolis, Anna; Ostendorf, Mari",Non-segmental duration feature extraction for prosodic classification,Interspeech 2008,,10.21437/Interspeech.2008-336,https://www.isca-speech.org/archive/interspeech_2008/dashiell08_interspeech.html,"This paper presents a set of novel duration features for detecting pitch accent and phrase boundaries, which depend on articulatory timing rather than segmental duration information. The features are computed from the detected syllable nuclei and boundaries, using peaks and valleys in an energy contour but also leveraging information from a simple HMM phone manner class recognizer to increase recall. In experiments on the hand-segmented TIMIT corpus, we obtain greater than 90% Fmeasure for vowel detection. In prosody detection experiments on the BU Radio News corpus, comparing to a segmental feature baseline, we obtain similar performance for pitch accent detection and slightly worse boundary detection from the new features without the need for phonetic alignments.",22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,1092-1095,ISCA,en,prosody,Interspeech 2008
2018,"Davis, Chris; Kim, Jeesun",Characterizing Rhythm Differences between Strong and Weak Accented L2 Speech,Interspeech 2018,,10.21437/Interspeech.2018-1798,https://www.isca-speech.org/archive/interspeech_2018/davis18_interspeech.html,"This study examined the rhythmic characteristics of accented L2 speech by using two relatively novel measures of prosodic rhythm: The S-AMPH measure, an index of the degree of synchrony between the stress and syllable amplitude modulation rates; and the Allan Factor measure, that determines the nested clustering of temporal events (in this case peaks in the amplitude envelope) over different timescales. An extremegroup design was used to select strong versus weak foreign accent recordings from a group of Korean and French L2 English talkers saying the same 69-word English passage. For the Korean talkers, both the S-AMPH and the Allan Factor measures differed as a function of the strength of foreign accent. This was not the case for the French talkers, where neither measure differed as a function of foreign accent strength. The difference in outcome between the Korean and French talkers suggests that the measures are not indexing some general property of L2 accent (e.g., production fluency) but rather that picking up some property specific to the strongly accented Korean talkers. We consider several options.",02/09/2018,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,2568-2572,ISCA,en,L2,Interspeech 2018
2013,"DeMarco, Andrea; Cox, Stephen J.",Native accent classification via i-vectors and speaker compensation fusion,Interspeech 2013,,10.21437/Interspeech.2013-382,https://www.isca-speech.org/archive/interspeech_2013/demarco13_interspeech.html,"We present a comprehensive analysis of the use of I-vector based classiﬁers for the classiﬁcation of unlabelled acoustic data as native British accents. We demonstrate the different behaviours of various popular dimensionality reduction techniques that have been previously used in problems such as speaker and language classiﬁcation. Our results show that a fusion of I-vector based systems gives state-of-the-art performance for unlabelled classiﬁcation of British accent speech data, reaching ∼81% accuracy.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,1472-1476,ISCA,en,L1,Interspeech 2013
2019,"Deme, Andrea; Bartók, Márton; Gráczi, Tekla Etelka; Csapó, Tamás Gábor; Markó, Alexandra",V-to-V Coarticulation Induced Acoustic and Articulatory Variability of Vowels: The Effect of Pitch-Accent,Interspeech 2019,,10.21437/Interspeech.2019-2890,https://www.isca-speech.org/archive/interspeech_2019/deme19_interspeech.html,"In the present study we analyzed vowel variation induced by carryover V-to-V coarticulation under the effect of pitch-accent as a function of vowel quality (using a minimally constrained intervening consonant to maximize V-to-V effects). We tested if /i/ is more resistant to coarticulation than /u/, and if both vowels show increased coarticulatory resistance in pitchaccented syllables. Our approach was unprecedented in the sense that it involved the analysis of parallel acoustic (F2) and articulatory (x-axis dorsum position) data in a great number of speakers (9 speaker), and real words of Hungarian. To analyze the degree of coarticulation, we adopted the locus equation approach, and fitted linear models on vowel onset and midpoint data, and calculated the differences between coarticulated and non-coarticulated vowels in both domains. To measure variability, we calculated standard deviations of midpoint F2 values and dorsum positions.",15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,3317-3321,ISCA,en,prosody,Interspeech 2019
2006,"Deng, Y.; Li, X.; Kwan, C.; Xu, R.; Raj, B.; Stern, Richard M.; Williamson, D.",An integrated approach to improve speech recognition rate for non-native speakers,Interspeech 2006,,10.21437/Interspeech.2006-481,https://www.isca-speech.org/archive/interspeech_2006/deng06_interspeech.html,"The current speech interfaces in many military applications may be adequate for native speakers. However, the recognition rate drops quite a lot for non-native speakers (people with foreign accents). This is mainly because the non-native speakers have large temporal and intra-phoneme variations when they pronounce the same words. This problem is also complicated by the presence of loud environmental noise such as tank noise, helicopter noise, etc. In this paper, we proposed a novel speech feature adaptation algorithm for continuous accent and environmental adaptation. This feature-based adaptation method is then integrated with conventional model-based maximum likelihood linear regression (MLLR) algorithm. Extensive experiments have been performed on the NATO non-native speech corpus with baseline acoustic model trained on native American English. The proposed feature-based adaptation algorithm improved the average recognition accuracy by 15%, while the MLLR model-based adaptation achieved 11% improvement. The combined adaptation achieved overall recognition accuracy improvement of 29.5%, and word error rate reduction of 31.8%.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,paper 1472-Wed2A2O.5-0,ISCA,en,L2,Interspeech 2006
2021,"Deng, Keqi; Cao, Songjun; Ma, Long",Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning,Interspeech 2021,,10.21437/Interspeech.2021-1186,https://www.isca-speech.org/archive/interspeech_2021/deng21b_interspeech.html,"Recently, self-supervised pre-training has gained success in automatic speech recognition (ASR). However, considering the difference between speech accents in real scenarios, how to identify accents and use accent features to improve ASR is still challenging. In this paper, we employ the self-supervised pre-training method for both accent identiﬁcation and accented speech recognition tasks. For the former task, a standard deviation constraint loss (SDC-loss) based end-to-end (E2E) architecture is proposed to identify accents under the same language. As for accented speech recognition task, we design an accent-dependent ASR system, which can utilize additional accent input features. Furthermore, we propose a frame-level accent feature, which is extracted based on the proposed accent identiﬁcation model and can be dynamically adjusted. We pretrain our models using 960 hours unlabeled LibriSpeech dataset and ﬁne-tune them on AESRC2020 speech dataset. The experimental results show that our proposed accent-dependent ASR system is signiﬁcantly ahead of the AESRC2020 baseline and achieves 6.5% relative word error rate (WER) reduction compared with our accent-independent ASR system.",30/08/2021,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,1504-1508,ISCA,en,L1-or-L2,Interspeech 2021
2014,"Desplanques, Brecht; Demuynck, Kris; Martens, Jean-Pierre",Robust language recognition via adaptive language factor extraction,Interspeech 2014,,10.21437/Interspeech.2014-484,https://www.isca-speech.org/archive/interspeech_2014/desplanques14_interspeech.html,"This paper presents a technique to adapt an acoustically based language classiﬁer to the background conditions and speaker accents. This adaptation improves language classiﬁcation on a broad spectrum of TV broadcasts. The core of the system consists of an iVector-based setup in which language and channel variabilities are modeled separately. The subsequent language classiﬁer (the backend) operates on the language factors, i.e. those features in the extracted iVectors that explain the observed language variability. The proposed technique adapts the language variability model to the background conditions and to the speaker accents present in the audio. The effect of the adaptation is evaluated on a 28 hours corpus composed of documentaries and monolingual as well as multilingual broadcast news shows. Consistent improvements in the automatic identiﬁcation of Flemish (Belgian Dutch), English and French are demonstrated for all broadcast types.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,2160-2164,ISCA,en,L2,Interspeech 2014
2015,"Desplanques, Brecht; Demuynck, Kris; Martens, Jean-Pierre",Factor analysis for speaker segmentation and improved speaker diarization,Interspeech 2015,,10.21437/Interspeech.2015-106,https://www.isca-speech.org/archive/interspeech_2015/desplanques15_interspeech.html,"Speaker diarization includes two steps: speaker segmentation and speaker clustering. Speaker segmentation searches for speaker boundaries, whereas speaker clustering aims at grouping speech segments of the same speaker. In this work, the segmentation is improved by replacing the Bayesian Information Criterion (BIC) with a new iVector-based approach. Unlike BIC-based methods which trigger on any acoustic dissimilarities, the proposed method suppresses phonetic variations and accentuates speaker differences. More speciﬁcally our method generates boundaries based on the distance between two speaker factor vectors that are extracted on a frame-byframe basis. The extraction relies on an eigenvoice matrix so that large differences between speaker factor vectors indicate a different speaker. A Mahalanobis-based distance measure, in which the covariance matrix compensates for the remaining and detrimental phonetic variability, is shown to generate accurate boundaries. The detected segments are clustered by a state-ofthe-art iVector Probabilistic Linear Discriminant Analysis system. Experiments on the COST278 multilingual broadcast news database show relative reductions of 50% in boundary detection errors. The speaker error rate is reduced by 8% relative.",06/09/2015,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,3081-3085,ISCA,en,not-accent,Interspeech 2015
2006,"Dilley, Laura; Breen, Mara; Bolivar, Marti; Kraemer, John; Gibson, Edward",A comparison of inter-transcriber reliability for two systems of prosodic annotation: rap (rhythm and pitch) and toBI (tones and break indices),Interspeech 2006,,10.21437/Interspeech.2006-111,https://www.isca-speech.org/archive/interspeech_2006/dilley06_interspeech.html,"Agreement was investigated among five labelers for the use of two prosodic annotation systems: the ToBI (Tones and Break Indices) system [1,2] and the RaP (Rhythm and Pitch) system [3]. Each system permits the labeling of pitch accents and two levels of phrasal boundaries; RaP also permits labeling of speech rhythm and distinguishes multiple levels of prominence on syllables. After training with computerized materials and getting expert feedback, coders applied each system to a corpus of read and spontaneous speech (36 minutes for ToBI and 19 for RaP). Inter-coder reliability was computed according to two metrics: transcriber-syllable-pairs and the kappa statistic. High agreement was obtained for both systems for pitch accent presence, pitch accent type, boundary presence, boundary type, and, for RaP, presence and strength of metrical prominences. Agreement levels for ToBI were similar to those of previous studies [4,5], indicating that participants were proficient coders. Moreover, the high level of agreement demonstrated for the RaP system indicates that RaP is a viable alternative to ToBI for prosodic labeling of large speech corpora.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,paper 1619-Mon2A3O.6-0,ISCA,en,prosody,Interspeech 2006
2009,"Dimitrova, Diana V.; Redeker, Gisela; Hoeks, John C. J.",Did you say a BLUE banana? the prosody of contrast and abnormality in bulgarian and dutch,Interspeech 2009,,10.21437/Interspeech.2009-296,https://www.isca-speech.org/archive/interspeech_2009/dimitrova09_interspeech.html,"In a production experiment on Bulgarian that was based on a previous study on Dutch [1], we investigated the role of prosody when linguistic and extra-linguistic information coincide or contradict. Speakers described abnormally colored fruits in conditions where contrastive focus and discourse relations were varied. We found that the coincidence of contrast and abnormality enhances accentuation in Bulgarian as it did in Dutch. Surprisingly, when both factors are in conflict, the prosodic prominence of abnormality often overruled focus accentuation in both Bulgarian and Dutch, though the languages also show marked differences.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,999-1002,ISCA,en,prosody,Interspeech 2009
2006,"Ding, Pei; He, Lei; Yan, Xiang; Hao, Jie",Robust automatic speech recognition for accented Mandarin in car environments,Interspeech 2006,,10.21437/Interspeech.2006-637,https://www.isca-speech.org/archive/interspeech_2006/ding06_interspeech.html,,17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,paper 1764-Thu2CaP.6-0,ISCA,en,L1,Interspeech 2006
2008,"Ding, Guo-Hong",Phonetic confusion analysis and robust phone set generation for Shanghai-accented Mandarin speech recognition,Interspeech 2008,,10.21437/Interspeech.2008-344,https://www.isca-speech.org/archive/interspeech_2008/ding08d_interspeech.html,"In this paper, accent issues are discussed for Shanghai-accented Mandarin speech recognition. The phonetic confusion is analyzed in detail based on the alignment between the surface form and the baseform transcriptions. Mutual information is used as the measure to extract the most confusing phoneme pairs. It was found that each phoneme in one pair can be easily misrecognized with the other. To remove the phonetic confusion, it is better to replace the two phonemes in one pair with a newly generated one. Consequentially new phone sets are derived. The phonetic confusion analysis and the experimental evaluation are performed on a Shanghai-accented Mandarin speech corpus. Experimental results show that compared to the canonical phone set, the generated one can reduce the substitution error greatly and achieve a 0.72% absolute Chinese character error rate (CER) reduction. When it is combined with pronunciation modeling, the absolute CER reduction is 1.58%.",22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:15,1129-1132,ISCA,en,L1,Interspeech 2008
2004,"Dohen, Marion; Loevenbruck, Helene","Pre-focal rephrasing, focal enhancement and postfocal deaccentuation in French",Interspeech 2004,,10.21437/Interspeech.2004-296,https://www.isca-speech.org/archive/interspeech_2004/dohen04_interspeech.html,"This study aims at better describing the acoustic correlates of contrastive focus in French. A corpus was recorded from a male native speaker of French. It consisted of sentences with a subject-verb-object (SVO) structure under four conditions: focus on each phrase (S,V,O) and broad focus. The focal, pre-focal and post-focal constituents were studied separately. The acoustic analysis showed that: a) the pitch of the focal constituent rises, b) that of the surrounding constituents decreases, c) the duration of the focal syllables and of the pre-focal syllable increases, the onset of the focal constituent increasing the most, d) the pre-focal sequence is rephrased, e) the post-focal sequence is deaccented.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,785-788,ISCA,en,prosody,Interspeech 2004
2005,"Dubeda, Tomás; Votrubec, Jan","Acoustic analysis of Czech stress: intonation, duration and intensity revisited",Interspeech 2005,,10.21437/Interspeech.2005-509,https://www.isca-speech.org/archive/interspeech_2005/dubeda05_interspeech.html,"By examining acoustic marks of Czech stress, this paper attempts to provide an answer to the question of whether or not perceived accents in the Czech language have an objective existence. A neural network is used to predict the position of accents without lexical information. Three parameters (intonation, duration and intensity) are considered individually, in pairs and altogether. Fundamental frequency seems to be the best predictor of stress, both alone and combined with other parameters. The analysis of the individual prediction errors allows for a closer look at factors which are critical in accent prediction.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,1429-1432,ISCA,en,prosody,Interspeech 2005
2010,"Duběda, Tomáš",flat pitch accents in Czech,Interspeech 2010,,10.21437/Interspeech.2010-503,https://www.isca-speech.org/archive/interspeech_2010/dubeda10b_interspeech.html,"In this paper we investigate a particular type of stress marking in Czech, in which the syllable perceived as prominent is not accompanied by any clearly audible change in the overall pitch course. The paper gives a perceptual, phonotactic and acoustic account of these “flat pitch accents”. No positional effects or semantic correlates of words bearing this type of accent were found. Flat accents have significantly reduced intonational variability, as expected, and their durational and dynamic correlates are partly different from other accent types. However, none of these findings speaks in favour of compensation between prosodic parameters.",26/09/2010,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,1756-1759,ISCA,en,prosody,Interspeech 2010
2010,"Duběda, Tomáš",Positional variability of pitch accents in Czech,Interspeech 2010,,10.21437/Interspeech.2010-504,https://www.isca-speech.org/archive/interspeech_2010/dubeda10c_interspeech.html,"An analysis of prenuclear accents in read speech is carried out with the aim of finding instances of regularity in their distribution. Significant differences are identified with respect to position within the phrase and phrase length, some of which are correlated with declination and pitch span narrowing. Only a weak interaction is found between nuclear and prenuclear pitch accents. No tendency of using only one type of pitch accents in a phrase could be found. The autosegmental approach seems to be a viable means of analyzing prenuclear intonation in Czech.",26/09/2010,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,1760-1763,ISCA,en,prosody,Interspeech 2010
2011,"Duběda, Tomáš",Perceptual sensitivity to prenuclear and nuclear intonational patterns,Interspeech 2011,,10.21437/Interspeech.2011-451,https://www.isca-speech.org/archive/interspeech_2011/dubeda11_interspeech.html,"We describe a perceptual experiment whose goal is to compare perceptual sensitivity to pitch accent contrasts in nuclear and prenuclear positions. The material consists of Czech sentences which have been resynthesized with controlled intonation. The results show that changes in nuclear pitch accents are perceived more sharply than changes in prenuclear pitch accents, and that the H* accent is perceptually more salient than the other accent types (L*H, L* and S*). The effect of constituent edge on the perception of intonational contrasts has not been confirmed.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,1369-1372,ISCA,en,prosody,Interspeech 2011
2004,"Effendy, Nazrul; Maneenoi, Ekkarit; Charnvivit, Patavee; Jitapunkul, Somchai",Intonation recognition for indonesian speech based on fujisaki model,Interspeech 2004,,10.21437/Interspeech.2004-746,https://www.isca-speech.org/archive/interspeech_2004/effendy04_interspeech.html,"In this paper, we proposed to use the Fujisaki parameter to distinguish between declarative and interrogative intonation in Indonesian speech. Four combinations of Fujisaki parameter were selected as the features to distinguish between declarative and interrogative intonation. The first combination is only the amplitude of last accent command. The second combination consists of the amplitude of last accent command and the magnitude of last phrase command. The third combination consists of Fb, the amplitude of last accent command, and the magnitude of last phrase command. The fourth combination consists of Fb/100, the amplitude of last accent command, and the magnitude of last phrase command.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,2973-2976,ISCA,en,prosody,Interspeech 2004
2013,"Eriksson, Anders; Barbosa, Plínio A.; Åkesson, Joel","The acoustics of word stress in Swedish: a function of stress level, speaking style and word accent",Interspeech 2013,,10.21437/Interspeech.2013-226,https://www.isca-speech.org/archive/interspeech_2013/eriksson13_interspeech.html,"The study presented here is one in a series of studies intended to describe the acoustics of word stress for several typologically different languages in a common framework. The idea is that, when fully developed the methodology should be applicable to any language in the same way regardless of prosodic type. The languages included in the present round of data collection and analyzes are Brazilian Portuguese, English, Estonian, French, Italian and Swedish. The acoustic variables examined here are F0-level, F0-variation, Duration, and Spectral Emphasis for all vowels in the data. All parameters are tested with respect to their correlation with stress level (primary, secondary, unstressed), speaking style (wordlist reading, phrase reading, spontaneous speech) and tonal word accent. The most robust results concerning stress level are found for Duration and F0-variation. Speaking style turned out to play a minimal role. The only robust effect was found for duration which was longer in word list reading. Word accent had a significant effect on F0-variation, and Duration.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,778-782,ISCA,en,prosody,Interspeech 2013
2012,"Escudero-Mancebo, David; Estebas-Vilaplana, Eva",Visualizing tool for evaluating inter-label similarity in prosodic labeling experiments,Interspeech 2012,,10.21437/Interspeech.2012-624,https://www.isca-speech.org/archive/interspeech_2012/escuderomancebo12_interspeech.html,This paper presents a technique that allows us to detect similarities among prosodic labels used to describe pitch accents within the ToBI framework. The inter-label proximity is determined empirically as a result of the evidence obtained in contingency tables of inter-transcriber agreement tests and in the confusion matrices used in automatic prosodic labeling experiments. This tool may be useful to decide which labels can be grouped together when a simpliﬁed representation is required.,09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,2382-2385,ISCA,en,prosody,Interspeech 2012
2016,"Ferras, M.; Madikeri, Srikanth; Dey, S.; Motlicek, Petr; Bourlard, Hervé",Inter-Task System Fusion for Speaker Recognition,Interspeech 2016,,10.21437/Interspeech.2016-1179,https://www.isca-speech.org/archive/interspeech_2016/ferras16_interspeech.html,"Fusion is a common approach to improving the performance of speaker recognition systems. Multiple systems using different data, features or algorithms tend to bring complementary contributions to the ﬁnal decisions being made. It is known that factors such as native language or accent contribute to speaker identity. In this paper, we explore inter-task fusion approaches to incorporating side information from accent and language identiﬁcation systems to improve the performance of a speaker veriﬁcation system. We explore both score level and model level approaches, linear logistic regression and linear discriminant analysis respectively, reporting signiﬁcant gains on accented and multi-lingual data sets of the NIST Speaker Recognition Evaluation 2008 data. Equal error rate and expected rank metrics are reported for speaker veriﬁcation and speaker identiﬁcation tasks.",08/09/2016,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,1810-1814,ISCA,en,L1-or-L2,Interspeech 2016
2022,"Finkelstein, Lev; Zen, Heiga; Casagrande, Norman; Chan, Chun-an; Jia, Ye; Kenter, Tom; Petelin, Alex; Shen, Jonathan; Wan, Vincent; Zhang, Yu; Wu, Yonghui; Clark, Robert",Training Text-To-Speech Systems From Synthetic Data: A Practical Approach For Accent Transfer Tasks,Interspeech 2022,,10.21437/Interspeech.2022-10115,https://www.isca-speech.org/archive/interspeech_2022/finkelstein22_interspeech.html,"Transfer tasks in text-to-speech (TTS) synthesis — where one or more aspects of the speech of one set of speakers is transferred to another set of speakers that do not feature these aspects originally — remains a challenging task. One of the challenges is that models that have high-quality transfer capabilities can have issues in stability, making them impractical for user-facing critical tasks. This paper demonstrates that transfer can be obtained by training a robust TTS system on data generated by a less robust TTS system designed for a high-quality transfer task; in particular, a CHiVE-BERT monolingual TTS system is trained on the output of a Tacotron model designed for accent transfer. While some quality loss is inevitable with this approach, experimental results show that the models trained on synthetic data this way can produce high quality audio displaying accent transfer, while preserving speaker characteristics such as speaking style.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,4571-4575,ISCA,en,L1-or-L2,Interspeech 2022
2014,"Fox, Robert Allen; Jacewicz, Ewa; Hardjono, Florence",Non-native perception of regionally accented speech in a multitalker context,Interspeech 2014,,10.21437/Interspeech.2014-546,https://www.isca-speech.org/archive/interspeech_2014/fox14b_interspeech.html,"Noisy listening conditions are challenging to non-native listeners who typically perform poorly while attending to several competing talkers. This study examined whether nonnative listeners are able to utilize dialect-related cues in the target and in the masking speech, even if they do not reach the proficiency level of the native listeners. 35 Indonesian-English bilinguals residing in the United States were presented with speech stimuli from two American English dialects, General American English and Southern American English, which were systematically varied both in the target sentences and in 2-talker masking babble at three sound-to-noise ratios (SNR). We found that the non-native listeners were (1) sensitive to dialect-specific phonetic details in speech of competing talkers and (2) performed in a manner similar to native listeners despite their apparent deficit. However, their performance differed significantly when the speech levels of the competing talkers were equal (0 dB SNR). The differential sensitivity of non-native listeners may reflect their inability to separate utterances of competing talkers when there is not enough contrast in their voice levels. In turn, the lack of sufficient contrast may reduce their ability to benefit from the phonetic-acoustic details necessary to encode the signal and comprehend a message.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,2548-2552,ISCA,en,L1,Interspeech 2014
2005,"Fujisaki, Hiroya; Ohno, Sumio",Analysis and modeling of fundamental frequency contours of hindi utterances,Interspeech 2005,,10.21437/Interspeech.2005-505,https://www.isca-speech.org/archive/interspeech_2005/fujisaki05_interspeech.html,"This paper describes the results of a preliminary study on the applicability of the command-response model to F0 contours of spoken Hindi, an official language of India with almost 400 million native speakers in the world. Analysis of observed F0 contours of a number of utterances by two native speakers indicated that the model with provisions for positive and negative accent commands applies quite well to all the utterances analyzed, and the estimated commands are found to be closely related to the linguistic contents of the utterances. One of the peculiar features of F0 contours of Hindi is the occurrence of a negative accent command at most phraseinitial positions, often followed by a positive accent command.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,1413-1416,ISCA,en,prosody,Interspeech 2005
2018,"Fukuda, Takashi; Fernandez, Raul; Rosenberg, Andrew; Thomas, Samuel; Ramabhadran, Bhuvana; Sorin, Alexander; Kurata, Gakuto",Data Augmentation Improves Recognition of Foreign Accented Speech,Interspeech 2018,,10.21437/Interspeech.2018-1211,https://www.isca-speech.org/archive/interspeech_2018/fukuda18_interspeech.html,"Speech recognition of foreign accented (non-native or L2) speech remains a challenge to the state-of-the-art. The most common approach to address this scenario involves the collection and transcription of accented speech, and incorporating this into the training data. However, the amount of accented data is dwarfed by the amount of material from native (L1) speakers, limiting the impact of the additional material. In this work, we address this problem via data augmentation. We create modiﬁed copies of two accents, Latin American and Asian accented English speech with voice transformation (modifying glottal source and vocal tract parameters), noise addition, and speed modiﬁcation. We investigate both supervised (where transcription of the accented data is available) and unsupervised approaches to using the accented data and associated augmentations. We ﬁnd that all augmentations provide improvements, with the largest gains coming from speed modiﬁcation, then voice transformation and noise addition providing the least improvement. The improvements from training accent speciﬁc models with the augmented data are substantial. Improvements from supervised and unsupervised adaptation (or training with soft labels) with the augmented data are relatively minor. Overall, we ﬁnd speed modiﬁcation to be a remarkably reliable data augmentation technique for improving recognition of foreign accented speech. Our strategies with associated augmentations provide Word Error Rate (WER) reductions of up to 30% relative over a baseline trained with only the accented data.",02/09/2018,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,2409-2413,ISCA,en,L2,Interspeech 2018
2009,"Gakuru, Mucemi",Development of a kenyan English text to speech system: a method of developing a TTS for a previously undefined English dialect,Interspeech 2009,,10.21437/Interspeech.2009-592,https://www.isca-speech.org/archive/interspeech_2009/gakuru09_interspeech.html,"This work provides a method that can be used to build an English TTS for a population who speak a dialect which is not defined and for which no resources exist, by showing how a Text to Speech System (TTS) was developed for the English dialect spoken in Kenya. To begin with, the existence of a unique English dialect which had not previously been defined was confirmed from the need by the English speaking Kenyan population to have a TTS in an accent different from the British accent. This dialect is referred to here and has also been branded as Kenyan English®. Given that building a TTS requires language features to be adequately defined, it was necessary to develop the essential features of the dialect such as the phoneset and the lexicon and then verifying their correctness. The paper shows how it was possible to come up with a systematic approach for defining these features through tracing the evolution of the dialect. It also discusses how the TTS was built and tested.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,2063-2066,ISCA,en,L1,Interspeech 2009
2013,"Ghio, Alain; Gasquet-Cyrus, Médéric; Roquel, Juliette; Giovanni, Antoine",Perceptual interference between regional accent and voice/speech disorders,Interspeech 2013,,10.21437/Interspeech.2013-506,https://www.isca-speech.org/archive/interspeech_2013/ghio13_interspeech.html,"We present a study where we examined the influence of a regional accent in the perception of voice and/or speech disorders. These aspects are most of the time overshadowed in clinical context. This protocol, involving multiple sources of speech variations, is also interesting for perception theories. For the experiment, speakers with or without a Southern French accent and with or without speech/voice disorders were recorded on reading a text. The samples were then randomly played back to two groups of listeners (familiar vs unfamiliar with the regional accent), specialists in speech therapy. The task was the perceptual evaluation of voice quality, articulation disorders and dysprosody. We focused in this paper on the voice dimension. The main results on this part concern the weak influence of regional accent on the perception of moderate or severe dysphonia, where the speech signal is strongly disturbed by the disorder. By contrast, the effect of regional accent is important on normal voices perception: listeners unfamiliar with the regional accent judge speakers with accent without voice disorder as slightly dysphonic. This last result can be interpreted as a form of perceptual interference between different dimensions of speech variations around a central position.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,2138-2142,ISCA,en,L1,Interspeech 2013
2018,"Ghorbani, Shahram; Hansen, John H.L.",Leveraging Native Language Information for Improved Accented Speech Recognition,Interspeech 2018,,10.21437/Interspeech.2018-1378,https://www.isca-speech.org/archive/interspeech_2018/ghorbani18_interspeech.html,"Recognition of accented speech is a long-standing challenge for automatic speech recognition (ASR) systems, given the increasing worldwide population of bi-lingual speakers with English as their second language. If we consider foreign-accented speech as an interpolation of the native language (L1) and English (L2), using a model that can simultaneously address both languages would perform better at the acoustic level for accented speech. In this study, we explore how an end-to-end recurrent neural network (RNN) trained system with English and native languages (Spanish and Indian languages) could leverage data of native languages to improve performance for accented English speech. To this end, we examine pre-training with native languages, as well as multi-task learning (MTL) in which the main task is trained with native English and the secondary task is trained with Spanish or Indian Languages. We show that the proposed MTL model performs better than the pre-training approach and outperforms a baseline model trained simply with English data. We suggest a new setting for MTL in which the secondary task is trained with both English and the native language, using the same output set. This proposed scenario yields better performance with +11.95% and +17.55% character error rate gains over baseline for Hispanic and Indian accents, respectively.",02/09/2018,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,2449-2453,ISCA,en,L2,Interspeech 2018
2006,"Ghorshi, Seyed; Vaseghi, Saeed; Yan, Qin","Comparative analysis of formants of British, american and australian accents",Interspeech 2006,,10.21437/Interspeech.2006-35,https://www.isca-speech.org/archive/interspeech_2006/ghorshi06_interspeech.html,"This paper compares and quantifies the differences between formants of speech across accents. The cross entropy information measure is used to compare the differences between the formants of the vowels of three major English accents namely British, American and Australian. An improved formant estimation method, based on a linear prediction (LP) model feature analysis and a hidden Markov model (HMM) of formants, is employed for estimation of formant trajectories of vowels and diphthongs. Comparative analysis of the formant space of the three accents indicates that these accents are mostly conveyed by the first two formants. The third and fourth formants exhibit some significant differences across accents for only a few phonemes most notably the variants of vowel ‘r’ in the American (rhotic) accent compared to British (non-rhotic accent). The issue of speaker variability versus accent variability is examined by comparing the cross-entropies of speech models trained on different groups of speakers within and across the accents.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,paper 1252-Mon1BuP.9-0,ISCA,en,L1,Interspeech 2006
,"Goel, Nagendra Kumar; Sarma, Mousmita; Kushwah, Tejendra Singh; Agrawal, Dharmesh Kumar; Iqbal, Zikra; Chauhan, Surbhi","Extracting speaker’s gender, accent, age and emotional state from speech",,,,,"We demonstrate a speaker characteristics assessment solution to extract speaker’s information like gender, age, emotion, language and accent from telephone quality speech. The solution has been designed using machine learning algorithms ranging from Gaussian mixture models to deep neural networks and utilize websocket technology for real-time bidirectional interface to provide live updates in a scalable manner. The service is utilized on our demonstration web-page where user can upload or record audio ﬁle and obtain the speaker’s characteristics. Such speaker characteristics information can be used as metadata in many real life applications designed for an emotionally sensitive human to machine interaction and human to human interaction.",,22/02/2023 10:34,22/02/2023 10:34,,,,en,L1-or-L2,
2016,"Goldman, Jean-Philippe; Honnet, Pierre-Edouard; Clark, Rob; Garner, Philip N.; Ivanova, Maria; Lazaridis, Alexandros; Liang, Hui; Macedo, Tiago; Pfister, Beat; Ribeiro, Manuel Sam; Wehrli, Eric; Yamagishi, Junichi",The SIWIS Database: A Multilingual Speech Database with Acted Emphasis,Interspeech 2016,,10.21437/Interspeech.2016-1003,https://www.isca-speech.org/archive/interspeech_2016/goldman16_interspeech.html,"We describe here a collection of speech data of bilingual and trilingual speakers of English, French, German and Italian. In the context of speech to speech translation (S2ST), this database is designed for several purposes and studies: training CLSA systems (cross-language speaker adaptation), conveying emphasis through S2ST systems, and evaluating TTS systems. More precisely, 36 speakers judged as accentless (22 bilingual and 14 trilingual speakers) were recorded for a set of 171 prompts in two or three languages, amounting to a total of 24 hours of speech. These sets of prompts include 100 sentences from news, 25 sentences from Europarl, the same 25 sentences with one acted emphasised word, 20 semantically unpredictable sentences, and ﬁnally a 240-word long text. All in all, it yielded 64 bilingual session pairs of the six possible combinations of the four languages. The database is freely available for non-commercial use and scientiﬁc research purposes.",08/09/2016,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,1532-1535,ISCA,en,prosody,Interspeech 2016
2010,"González-Ferreras, César; Vivaracho-Pascual, Carlos; Escudero-Mancebo, David; Cardeñoso-Payo, Valentín",On the automatic toBI accent type identification from data,Interspeech 2010,,10.21437/Interspeech.2010-70,https://www.isca-speech.org/archive/interspeech_2010/gonzalezferreras10_interspeech.html,"This contribution faces the ToBI accent recognition problem with the goal of multiclass identiﬁcation vs. the more conservative Accent vs. No Accent approach. A neural network and a decision tree are used for automatic recognition of the ToBI accents in the Boston Radio Corpus. Multiclass classiﬁcation results show the difﬁculty of the problem and the impact of imbalanced classes. A study of the confusion/similarity between accent types, based on in-pair recognition rates, shows its impact on the overall performance. More expressive F0 contours parametrization techniques have been used to improve recognition rates.",26/09/2010,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,142-145,ISCA,en,prosody,Interspeech 2010
2013,"Graham, Calbert; Post, Brechtje",Realisation of tonal alignment in the English of Japanese-English late bilinguals,Interspeech 2013,,10.21437/Interspeech.2013-557,https://www.isca-speech.org/archive/interspeech_2013/graham13_interspeech.html,"Several factors have been attested to affect the temporal synchronisation of tonal targets such as syllable duration, segmental structure and proximity to word or intonational boundaries, e.g. [1], [2], [3]. Given the apparent languagespecific nature of tonal alignment [4], it can be expected that late bilinguals who are acquiring a second language will need to learn the alignment implementation rules of that language, in addition to other aspects. This study compared the tonal alignment patterns of Japanese late bilingual English speakers and monolingual English speakers in order to investigate to what extent learners transfer their native implementation strategies to the interlanguage, and whether alignment changes with proficiency. The results show that, although initialaccented words were aligned later than final-accented words for all groups, as expected, the Japanese bilinguals aligned the former significantly later than the monolinguals. Further analyses revealed that their off-target realisations were generally limited to a specific type of syllable structure that we speculate may be linked to peak delay in their L1.These results are taken as evidence of prosodic transfer and suggest that late bilinguals will need to learn the L2 phonetic implementation rules of alignment independently of their acquisition of the phonology.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,2390-2394,ISCA,en,prosody,Interspeech 2013
2006,"Gravano, Agustín; Hirschberg, Julia","Effect of genre, speaker, and word class on the realization of given and new information",Interspeech 2006,,10.21437/Interspeech.2006-208,https://www.isca-speech.org/archive/interspeech_2006/gravano06_interspeech.html,"There is much evidence in the literature that speakers tend to deaccent discourse-given entities, while accenting new ones. However, speakers do not always follow this simple strategy and the causes for such variation are not yet well understood. In this paper, we describe several new forms of variability in the relationship between given/new information and accenting behavior, variation due to individual differences and to word class. We present results indicating that different speakers have different strategies for making new words prominent. We analyze two word-classes – nouns and verbs – in a corpus of spontaneous and read direction-giving monologues, and show that speakers use different combinations of pitch, intensity and inter-word pauses to distinguish between given and new information. Most interestingly, we find that in both genres all speakers tend to produce given verbs with higher intensity than new verbs.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,paper 1747-Mon3A3O.5-0,ISCA,en,prosody,Interspeech 2006
2015,"Grohe, Ann-Kathrin; Poarch, Gregory J.; Hanulíková, Adriana; Weber, Andrea",Production inconsistencies delay adaptation to foreign accents,Interspeech 2015,,10.21437/Interspeech.2015-627,https://www.isca-speech.org/archive/interspeech_2015/grohe15_interspeech.html,"The effects of production inconsistencies and speaker’s accented production preferences on speech comprehension were investigated in an eyetracking experiment. Using the visual world paradigm, native speakers of German with L2 English listened to single English words produced by a German speaker that had their th either pronounced canonically or substituted with an /s/ or a /t/. Looks to the target word were most likely for the canonical pronunciation and did not differ between the substitutes. However, target looks increased for items with th substitutions in the course of the experiment, indicating slow adaptation to inconsistently foreign accented speech.",06/09/2015,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:16,3115-3119,ISCA,en,L2,Interspeech 2015
2004,"Gu, Wentao; Hirose, Keikichi; Fujisaki, Hiroya",Analysis of F0 contours of Cantonese utterances based on the command-response model,Interspeech 2004,,10.21437/Interspeech.2004-295,https://www.isca-speech.org/archive/interspeech_2004/gu04_interspeech.html,"As a major Chinese dialect, Cantonese is well known for its complex tone system. This paper applies the commandresponse model to represent the F0 contours of Cantonese speech. Analysis-by-Synthesis is conducted on both utterances of carrier sentences and utterances with less constrained structures, from which a set of appropriate tone command patterns is derived. By intrinsically incorporating the effects of tone coarticulation, word accentuation and phrase intonation, the model provides a high accuracy of approximation to the F0 contours of Cantonese, and hence serves as a much better method to quantitatively describe the continuous F0 contours than the traditional tone letter scale notation system. The constraints in timing and amplitude of tone commands are also investigated, which can be used for synthesis of F0 contours.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,781-784,ISCA,en,prosody,Interspeech 2004
2011,"Hanani, Abualsoud; Russell, Martin; Carey, Michael J.",Computer and human recognition of regional accents of british English,Interspeech 2011,,10.21437/Interspeech.2011-281,https://www.isca-speech.org/archive/interspeech_2011/hanani11_interspeech.html,"This paper is concerned with classification of the 14 regional accents of British English in the ABI (Accents of the British Isles) speech corpus. Results are reported using a state-of-theart Language Identification system, variants of Huckvale’s ACCDIST system, and human listeners. The best performance, 95.18% accuracy, is obtained using the textdependent ACCDIST measure. The performance of a conventional (text-independent) acoustic Language Identification system is poor, but is improved significantly (89.6% accuracy) by the addition of phone sequence information. Human performance (58.25% accuracy) is much lower than expected.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,729-732,ISCA,en,L1,Interspeech 2011
2012,"Hansakunbuntheung, Chatchawarn; Chotimongkol, Ananlada; Thatphithakkul, Sumonmas; Chootrakool, Patcharika",Model-based duration-difference approach on accent evaluation of L2 learner,Interspeech 2012,,10.21437/Interspeech.2012-224,https://www.isca-speech.org/archive/interspeech_2012/hansakunbuntheung12_interspeech.html,"This paper aims at using a model-based duration-difference approach to analyze L2 learners’ duration-aspect accent, and, segmental duration characteristics. We use the durational differences deviated from native-English speech duration as an objective measure to evaluate the learner’s timing characteristics. The use of model-based approach provides flexible evaluation without the need to collect any additional English reference speech. The proposed evaluation method was tested on English speech data uttered by native English speakers and Thai-native English learners with different English-study experiences. The experimental results show speaker clusters grouped by English accents and L2 learners’ English-study experiences. These results support the effectiveness of the proposed model-based objective evaluation.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,719-722,ISCA,en,L2,Interspeech 2012
2004,"Hansen, John H. L.; Yapanel, Umit; Huang, Rongqing; Ikeno, Ayako",Dialect analysis and modeling for automatic classification,Interspeech 2004,,10.21437/Interspeech.2004-38,https://www.isca-speech.org/archive/interspeech_2004/hansen04_interspeech.html,"In this paper, we present our recent work in the analysis and modeling of speech under dialect. Dialect and accent significantly influence automatic speech recognition performance, and therefore it is critical to detect and classify non-native speech. In this study, we consider three areas that include: (i) prosodic structure (normalized f0, syllable rate, and sentence duration), (ii) phoneme acoustic space modeling and sub-word classification, and (iii) word-level based modeling using large vocabulary data. The corpora used in this study include: the NATO N-4 corpus (2 accents, 2 dialects of English), TIMIT (7 dialect regions), and American and British English versions of the WSJ corpus. These corpora were selected because the contained audio material from specific dialects/accents of English (N-4), were phonetically balanced and organized across U.S. (TIMIT), or contained significant amounts of read audio material from distinct dialects (WSJ). The results show that significant changes occur at the prosodic, phoneme space, and word levels for dialect analysis, and that effective dialect classification can be achieved using processing strategies from each domain.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,1569-1572,ISCA,en,L2,Interspeech 2004
2017,"Hanulíková, Adriana; Ekström, Jenny","Lexical Adaptation to a Novel Accent in German: A Comparison Between German, Swedish, and Finnish Listeners",Interspeech 2017,,10.21437/Interspeech.2017-369,https://www.isca-speech.org/archive/interspeech_2017/hanulikova17_interspeech.html,"Listeners usually adjust rapidly to unfamiliar regional and foreign accents in their native (L1) language. Non-native (L2) listeners, however, usually struggle when confronted with unfamiliar accents in their non-native language. The present study asks how native language background of L2 speakers influences lexical adjustments in a novel accent of German, in which several vowels were systematically lowered. We measured word judgments on a lexical decision task before and after exposure to a 15-min story in the novel dialect, and compared German, Swedish and Finnish listeners’ performance. Swedish is a Germanic language and shares with German a number of lexical roots and a relatively large vowel inventory. Finnish is a Finno-Ugric language and differs substantially from Germanic languages in both lexicon and phonology. The results were as predicted: descriptively, all groups showed a similar pattern of adaptation to the accented speech, but only German and Swedish participants showed a significant effect. Lexical and phonological relatedness between the native and non-native languages may thus positively influence lexical adaptation in an unfamiliar accent.",20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,1784-1788,ISCA,en,L1-or-L2,Interspeech 2017
2006,"Hardison, Debra M.",Effects of familiarity with faces and voices on second-language speech processing: components of memory traces,Interspeech 2006,,10.21437/Interspeech.2006-617,https://www.isca-speech.org/archive/interspeech_2006/hardison06_interspeech.html,"Familiarity with a talker’s voice and face was found to facilitate processing of second-language speech. This advantage is accentuated when visual cues are limited to either the mouth and jaw area, or eyes and upper cheek areas of a talker’s face. Findings are compatible with a multiple-trace model of bimodal speech processing.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,paper 1097-Thu2WeO.3-0,ISCA,en,prosody,Interspeech 2006
2015,"Hautamäki, Ville; Siniscalchi, Sabato Marco; Behravan, Hamid; Salerno, Valerio Mario; Kukanov, Ivan",Boosting universal speech attributes classification with deep neural network for foreign accent characterization,Interspeech 2015,,10.21437/Interspeech.2015-165,https://www.isca-speech.org/archive/interspeech_2015/hautamaki15_interspeech.html,"We have recently proposed a universal acoustic characterisation to foreign accent recognition, in which any spoken foreign accent was described in terms of a common set of fundamental speech attributes. Although experimental evidence demonstrated the feasibility of our approach, we belive that speech attributes, namely manner and place of articulation, can be better modelled by a deep neural network. In this work, we propose the use of deep neural network trained on telephone bandwidth material from different languages to improve the proposed universal acoustic characterisation. We demonstrate that deeper neural architectures enhance the attribute classiﬁcation accuracy. Furthermore, we show that improvements in attribute classiﬁcation carry over to foreign accent recognition by producing a 21% relative improvement over previous baseline on spoken Finnish, and a 5.8% relative improvement on spoken English.",06/09/2015,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,408-412,ISCA,en,L2,Interspeech 2015
2004,"Heggtveit, Per Olav; Natvig, Jon Emil",Automatic prosody labeling of read norwegian,Interspeech 2004,,10.21437/Interspeech.2004-662,https://www.isca-speech.org/archive/interspeech_2004/heggtveit04_interspeech.html,In this paper we present initial work on a method for automatic stress and boundary labelling of read EastNorwegian. The context of this work is automatic corpus annotation for unit selection speech synthesis.,04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,2741-2744,ISCA,en,prosody,Interspeech 2004
,"Hirano, Hiroko; Nakamura, Ibuki; Minematsu, Nobuaki; Suzuki, Masayuki; Nakagawa, Chieko; Nakamura, Noriko; Tagawa, Yukinori; Hirose, Keikichi; Hashimoto, Hiroya",A Free Online Accent and Intonation Dictionary for Teachers and Learners of Japanese.,,,,,"We have developed the very ﬁrst free online and free framework for teaching and learning Japanese prosody with features for word accent and phrase intonation. This framework is called OJAD (Online Japanese Accent Dictionary) [1], which provides three functions. 1) Visual, auditory, systematic, and comprehensive illustration of patterns of accent change (accent sandhi) of verbs and adjectives. Here only the changes resulting from twelve kinds of fundamental conjugation are focused upon. 2) Visual illustration of the accent pattern of a given verbal expression, which is a combination of a verb and its postpositional auxiliary words. 3) Visual illustration of the pitch pattern of an any given sentence and the expected positions of accent nuclei in the sentence. The third function is implemented by using an accent change prediction module that we developed for Japanese text-to-speech (TTS) synthesizers [2]. Subjective assessment by teachers shows very high pedagogical effectiveness of the framework.",,22/02/2023 10:34,22/02/2023 10:34,,,,en,L2,
2005,"Hirose, Keikichi; Furuyama, Yusuke; Minematsu, Nobuaki",Corpus-based extraction of F0 contour generation process model parameters,Interspeech 2005,,10.21437/Interspeech.2005-566,https://www.isca-speech.org/archive/interspeech_2005/hirose05_interspeech.html,"A corpus-based method was developed for automatic extraction of the F0 contour generation process model parameters (phrase and accent commands). The method first smoothes the observed F0 contour by a piecewise 3rd order polynomial function and finds points of inflection. Then several parameters related to the points are used as input parameters for the predictor of the model commands. Finally the predicted commands are tuned to the observed contour by the analysis-by-synthesis. An experiment was conducted using ATR 504 sentence speech corpus, and the performance close to a rule-based method, also developed by the authors, was obtained. An experiment was further conducted by adding linguistic information of the content of the utterance (such as accent type, depth of bunsetsu boundary) to input parameters. The performance was largely improved; the extraction rates reached around 90 % for phrase commands and 84 % for accent commands.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,3257-3260,ISCA,en,prosody,Interspeech 2005
2020,"Hirschi, Kevin; Kang, Okim; Cucchiarini, Catia; Hansen, John H.L.; Evanini, Keelan; Strik, Helmer",Mobile-Assisted Prosody Training for Limited English Proficiency: Learner Background and Speech Learning Pattern,Interspeech 2020,,10.21437/Interspeech.2020-2901,https://www.isca-speech.org/archive/interspeech_2020/hirschi20_interspeech.html,"The use of Mobile-Assisted Pronunciation Training (MAPT) has been increasing drastically due to the personal and interactive nature of mobile devices. However, MAPT applications lack support from empirical evidence as research on MAPT-based acquisition, particularly related to prosody, has been rare. The present study employs a MAPT application with lessons on lexical stress and prominence with Limited English Proficiency (LEP) users (n = 31) of mixed ages and first languages. Then, 16 experienced raters conducted discoursebased prosodic analysis on unconstrained speech collected at the beginning and the end of the intervention. A series of mixedeffect model analyses were conducted on learner effort, improvement and learner background to investigate their relationship with accentedness and comprehensibility. The results indicated that present MAPT prosody interventions were effective for comprehensibility but not accentedness, however, learner effort on lexical stress and prominence exhibit differing patterns. Similar to previous findings, learner age impacts production more than the length of residency or history of language study. Implications include a prosody-based MAPT application; support for the treatment of accentedness and comprehensibility as separate, but related constructs; and a further understanding of the role of learner-related factors in prosody intervention.",25/10/2020,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,4452-4456,ISCA,en,L2,Interspeech 2020
2017,"Hojo, Nobukatsu; Ohsugi, Yasuhito; Ijima, Yusuke; Kameoka, Hirokazu",DNN-SPACE: DNN-HMM-Based Generative Model of Voice F0 Contours for Statistical Phrase/Accent Command Estimation,Interspeech 2017,,10.21437/Interspeech.2017-719,https://www.isca-speech.org/archive/interspeech_2017/hojo17_interspeech.html,"This paper proposes a method to extract prosodic features from a speech signal by leveraging auxiliary linguistic information. A prosodic feature extractor called the statistical phrase/accent command estimation (SPACE) has recently been proposed. This extractor is based on a statistical model formulated as a stochastic counterpart of the Fujisaki model, a wellfounded mathematical model representing the control mechanism of vocal fold vibration. The key idea of this approach is that a phrase/accent command pair sequence is modeled as an output sequence of a path-restricted hidden Markov model (HMM) so that estimating the state transition amounts to estimating the phrase/accent commands. Since the phrase and accent commands are related to linguistic information, we may expect to improve the command estimation accuracy by using them as auxiliary information for the inference. To model the relationship between the phrase/accent commands and linguistic information, we construct a deep neural network (DNN) that maps the linguistic feature vectors to the state posterior probabilities of the HMM. Thus, given a pitch contour and linguistic information, we can estimate phrase/accent commands via state decoding. We call this method “DNN-SPACE.” Experimental results revealed that using linguistic information was effective in improving the command estimation accuracy.",20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,1074-1078,ISCA,en,prosody,Interspeech 2017
2013,"Hou, Luying; Jia, Yuan; Li, Aijun",Phonetic manifestation and influence of zero anaphora in Chinese reading texts,Interspeech 2013,,10.21437/Interspeech.2013-372,https://www.isca-speech.org/archive/interspeech_2013/hou13_interspeech.html,"The present paper conducts a pioneering study on the phonetic manifestation and influence of zero anaphora in Chinese reading texts. The stress degree of the boundary syllable and the duration of the pause at the anaphoric position are examined. The results show: i) the boundary syllable after zero anaphoric form is more accented; for the two types of zero anaphora concerned in this study, the boundary syllable after distant zero anaphoric form is more accented than that after immediate zero anaphoric form; ii) the boundary syllable before immediate anaphoric form is more accented than that before distant anaphoric form; iii) the pause before immediate zero anaphoric form is shorter than that before other types of anaphoric forms. Based on these results, the study further proposes that the syllable weight of the underlying anaphoric form is projected to the following syllable in the surface representation. Moreover, semantic distance and relation can account for the differences between distant and immediate zero anaphora.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,1424-1428,ISCA,en,prosody,Interspeech 2013
2017,"Hou, Luying; Bruyn, Bert Le; Kager, René",Disambiguate or not? — The Role of Prosody in Unambiguous and Potentially Ambiguous Anaphora Production in Strictly Mandarin Parallel Structures,Interspeech 2017,,10.21437/Interspeech.2017-1214,https://www.isca-speech.org/archive/interspeech_2017/hou17_interspeech.html,"It has been observed that the interpretation of pronouns can depend on their accentuation patterns in parallel sentences as “John hit Bill and then George hit him”, in which ‘him’ refers to Bill when unaccented but shifts to John when accented. While accentuation is widely regarded as a means of disambiguation, some studies have noticed that it also extends to unambiguous anaphors [7-10]. From the perspective of production, however, no strong experimental confirmation was found for the ‘shift’ function of accented pronouns, which is due to the fact that production research has mainly focused on corpora [5, 6]. Hence, the nature of the accent on anaphors still remains obscure. By manipulating referential shift and ambiguity, this study explores the role of prosody in anaphora production in strictly Mandarin parallel structures. The results reveal a significantly higher F0 and longer duration for anaphors in referentially shifted conditions, suggesting that anaphoric accentuation signals a referential change in strictly parallel structures in Mandarin. No evidence was found that ambiguity plays a role in anaphoric accentuation. This finding challenges the general view on accented pronouns and will deepen our understanding on semantics-prosody relationship.",20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,1393-1397,ISCA,en,prosody,Interspeech 2017
2007,"House, David",Integrating audio and visual cues for speaker friendliness in multimodal speech synthesis,Interspeech 2007,,10.21437/Interspeech.2007-393,https://www.isca-speech.org/archive/interspeech_2007/house07_interspeech.html,"This paper investigates interactions between audio and visual cues to friendliness in questions in two perception experiments. In the first experiment, manually edited parametric audio-visual synthesis was used to create the stimuli. Results were consistent with earlier findings in that a late, high final focal accent peak was perceived as friendlier than an earlier, lower focal accent peak. Friendliness was also effectively signaled by visual facial parameters such as a smile, head nod and eyebrow raising synchronized with the final accent. Consistent additive effects were found between the audio and visual cues for the subjects as a group and individually showing that subjects integrate the two modalities. The second experiment used data-driven visual synthesis where the database was recorded by an actor instructed to portray anger and happiness. Friendliness was correlated to the happy database, but the effect was not as strong as for the parametric synthesis.",27/08/2007,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,1250-1253,ISCA,en,prosody,Interspeech 2007
2009,"House, David; Karlsson, Anastasia; Svantesson, Jan-Olof; Tayanin, Damrong","The phrase-final accent in kammu: effects of tone, focus and engagement",Interspeech 2009,,10.21437/Interspeech.2009-309,https://www.isca-speech.org/archive/interspeech_2009/house09_interspeech.html,"The phrase-final accent can typically contain a multitude of simultaneous prosodic signals. In this study, aimed at separating the effects of lexical tone from phrase-final intonation, phrase-final accents of two dialects of Kammu were analyzed. Kammu, a Mon-Khmer language spoken primarily in northern Laos, has dialects with lexical tones and dialects with no lexical tones. Both dialects seem to engage the phrase-final accent to simultaneously convey focus, phrase finality, utterance finality, and speaker engagement. Both dialects also show clear evidence of truncation phenomena. These results have implications for our understanding of the interaction between tone, intonation and phrase-finality.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,2439-2442,ISCA,en,prosody,Interspeech 2009
2005,"Huang, Rongqing; Hansen, John H. L.",Advances in word based dialect/accent classification,Interspeech 2005,,10.21437/Interspeech.2005-709,https://www.isca-speech.org/archive/interspeech_2005/huang05f_interspeech.html,"In an earlier study, we proposed a very effective dialect/accent classiﬁcation algorithm, which is named Word based Dialect Classiﬁcation (WDC). The WDC works well for large size corpora and signiﬁcantly outperforms traditional Large Vocabulary Continuous Speech Recognition (LVCSR) based systems, which is claimed to be the best performing system for language identiﬁcation. For a small training corpus, however, it is difﬁcult to obtain a robust statistical model for each word and each dialect. Therefore, a Context Adapted Training (CAT) algorithm is formulated here, which adapts the universal phoneme GMMs to dialect-dependent word HMMs via linear regression. Employing on a 8-dialect British English corpus–IViE, the CAT algorithm trained WDC system obtains a 35.5% relative classiﬁcation error reduction from the baseline LVCSR system, and a 20.2% relative classiﬁcation error reduction from the basic WDC system.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,2241-2244,ISCA,en,L1-or-L2,Interspeech 2005
2014,"Huang, Yan; Yu, Dong; Liu, Chaojun; Gong, Yifan",Multi-accent deep neural network acoustic model with accent-specific top layer using the KLD-regularized model adaptation,Interspeech 2014,,10.21437/Interspeech.2014-497,https://www.isca-speech.org/archive/interspeech_2014/huang14e_interspeech.html,"We propose a multi-accent deep neural network acoustic model with an accent-speciﬁc top layer and shared bottom hidden layers. The accent-speciﬁc top layer is used to model the distinct accent speciﬁc patterns. The shared bottom hidden layers allow maximum knowledge sharing between the native and the accent models. This design is particularly attractive when considering deploying such a system to a live speech service due to its computational efﬁciency. We applied the KL-divergence (KLD) regularized model adaptation to train the accent-speciﬁc top layer. On the mobile short message dictation task (SMD), with 1K, 10K, and 100K British or Indian accent adaptation utterances, the proposed approach achieves 18.1%, 26.0%, and 28.5% or 16.1%, 25.4%, and 30.6% word error rate reduction (WERR) for the British and the Indian accent respectively against a baseline cross entropy (CE) model trained from 400 hour data. On the 100K utterance accent adaptation setup, comparable performance gain can be obtained against a baseline CE model trained with 2000 hour data. We observe smaller yet signiﬁcant WER reduction on a baseline model trained using the MMI sequence-level criterion.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,2977-2981,ISCA,en,L1-or-L2,Interspeech 2014
2004,"Huckvale, Mark",ACCDIST: a metric for comparing speakers' accents,Interspeech 2004,,10.21437/Interspeech.2004-29,https://www.isca-speech.org/archive/interspeech_2004/huckvale04_interspeech.html,"This paper introduces a new metric for the quantitative assessment of the similarity of speakers' accents. The ACCDIST metric is based on the correlation of inter-segment distance tables across speakers or groups. Basing the metric on segment similarity within a speaker ensures that it is sensitive to the speaker’s pronunciation system rather than to his or her voice characteristics. The metric is shown to have an error rate of only 11% on the accent classification of speakers into 14 English regional accents of the British Isles, half the error rate of a metric based on spectral information directly. The metric may also be useful for cluster analysis of accent groups.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,29-32,ISCA,en,L1-or-L2,Interspeech 2004
2016,"Huckvale, Mark",Within-Speaker Features for Native Language Recognition in the Interspeech 2016 Computational Paralinguistics Challenge,Interspeech 2016,,10.21437/Interspeech.2016-1466,https://www.isca-speech.org/archive/interspeech_2016/huckvale16_interspeech.html,"The Interspeech 2016 Native Language recognition challenge was to identify the first language of 867 speakers from their spoken English. Effectively this was an L2 accent recognition task where the L1 was one of eleven languages. The lack of transcripts of the spontaneous speech recordings meant that the currently best performing accent recognition approach (ACCDIST) developed by the author could not be applied. Instead, the objectives of this study were to explore whether within-speaker features found to be effective in ACCDIST would also have value within a contemporary GMM-based accent recognition approach. We show that while Gaussian mean supervectors provide the best performance on this task, small gains may be had by fusing the mean supervector system with a system based on within-speaker Gaussian mixture distances.",08/09/2016,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,2403-2407,ISCA,en,L1,Interspeech 2016
2010,"Hussein, Hussein; Hoffmann, Rüdiger",Signal-based accent and phrase marking using the fujisaki model,Interspeech 2010,,10.21437/Interspeech.2010-368,https://www.isca-speech.org/archive/interspeech_2010/hussein10_interspeech.html,"Automatic prosodic marking is very important in speech signal processing, since its results are required in many subsections, e.g. speech synthesis and speech recognition. The most important prosodic features on the linguistic level are the marking of accents and phrases. In this paper, we develop an automatic algorithm for marking accents and phrases which analyzes the F0 contour by using the quantitative Fujisaki model. The results of automatic extraction of accents and phrases have been compared to the human labeling performance. The success rate of accent and phrase marking amounts to 77.11% and 67.12%, respectively.",26/09/2010,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,1169-1172,ISCA,en,prosody,Interspeech 2010
2006,"Ikeno, Ayako; Hansen, John H. L.",The role of prosody in the perception of US native English accents,Interspeech 2006,,10.21437/Interspeech.2006-141,https://www.isca-speech.org/archive/interspeech_2006/ikeno06_interspeech.html,"A wide range of aspects are contained within the speech signal which provides information concerning a particular speaker’s characteristics. Accent is a linguistic trait of speaker identity. It indicates the speaker’s language and social background. The goal of this study is to provide perceptual assessment of accent variation in US native English. The main issue considered is how different components of prosody affect accent perception. This perceptual study employed an ASHA certified acoustic sound booth using 73 listeners (53 male, 20 female). The results from these perceptual experiments indicate the importance of prosody in combination with availability of utterance content via speech signal or transcripts. The trends also indicate that listeners’ decisions are influenced by conceptual representation of prototypical accent characteristics, such as “people from New York talk fast.” These observations suggest that listeners use both bottom-up processing, based on the acoustic input, and top-town processing, based on their conceptual representation of prototypical accent characteristics. Those processes are multi-dimensional in that listeners use utterance content (e.g., meaning or comprehensibility) as well as accent characteristics in the acoustic input even though our experiment focuses on pronunciation features and does not include word selections that are dialect dependent. These findings contribute to a deeper understanding of the cognitive aspects of accent variation, and its applications for speech technology, such as accent classification for speaker identification or speech recognition.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,paper 1437-Mon2CaP.10-0,ISCA,en,L1,Interspeech 2006
2006,"Iseli, Markus; Shue, Yen-Liang; Epstein, Melissa A.; Keating, Patricia; Kreiman, Jody; Alwan, Abeer",Voice source correlates of prosodic features in american English: a pilot study,Interspeech 2006,,10.21437/Interspeech.2006-318,https://www.isca-speech.org/archive/interspeech_2006/iseli06_interspeech.html,"In this paper, we examine the dependencies of voice source parameters F0(fundamental frequency), Ee(maximal glottal ﬂow change), RK(glottal symmetry/skew), LIN (value related to source spectral tilt) and H1∗ − H2∗(difference of formant-corrected magnitudes of the ﬁrst two source spectral harmonics) on prosodic features such as pitch accents, stress, and sentence type and the interdependencies of some of these measures. A small, carefully designed corpus containing a sentence in different prosodic conﬁgurations was used in this study. Statistical analysis was performed using two-way ANOVAs to test for the voice source parameter dependencies. Results show that F0 is positively correlated with Ee and LIN , and negatively correlated with H1∗−H2∗. Stressed syllables showed lower values of RK and H1∗−H2∗ compared to stressless syllables. The effect of pitch accent can be seen as a combination of its F0, and stress. Phrase-ﬁnal syllables for interrogative sentences yielded a higher F0 and lower RK and H1∗ − H2∗ compared to declarative sentences. It was found that it is important to differentiate between tones when analyzing prosodic features that involve tones, such as pitch accent and probably boundary.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,paper 1933-Thu1A3O.1-0,ISCA,en,prosody,Interspeech 2006
2013,"Ishihara, Tatsuma; Kameoka, Hirokazu; Yoshizato, Kota; Saito, Daisuke; Sagayama, Shigeki",Probabilistic speech F0 contour model incorporating statistical vocabulary model of phrase-accent command sequence,Interspeech 2013,,10.21437/Interspeech.2013-110,https://www.isca-speech.org/archive/interspeech_2013/ishihara13_interspeech.html,"We have previously proposed a generative model of speech F0 contours, based on the discrete-time version of the Fujisaki model (a model of the mechanisim for controlling F0s through laryngeal muscles). One advantage of this model is that it allows us to apply statistical methods to estimate the Fujisakimodel parameters from speech F0 contours. This paper proposes a new generative model of speech F0 contours incorporating a vocabulary model of intonation patterns. A parameter inference algorithm for the present model is derived. We quantitatively evaluated the performance of our parameter inference algorithm.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,1017-1021,ISCA,en,prosody,Interspeech 2013
2011,"Ishimoto, Yuichi; Enomoto, Mika; Iida, Hitoshi",Projectability of transition-relevance places using prosodic features in Japanese spontaneous conversation,Interspeech 2011,,10.21437/Interspeech.2011-541,https://www.isca-speech.org/archive/interspeech_2011/ishimoto11_interspeech.html,"In this paper, to clarify acoustic features for predicting the ends of utterances, we investigated prosodic features that project transition relevance places in Japanese spontaneous conversation. Acoustic parameters used as the prosodic features are the fundamental frequency, power, and mora duration of accentual phrases and words. Results showed that the fundamental frequency and power at the beginning of the ﬁnal accentual phrase indicate whether the utterance includes utterance-ﬁnal elements, which are the syntactic cue for detecting the end-ofutterance. In addition, the mora duration lengthened in the ﬁnal accentual phrase. That is, these prosodic features around the beginning of the ﬁnal accentual phrase showed the characteristic changes that make hearers predict the transition relevance places.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:17,2061-2064,ISCA,en,prosody,Interspeech 2011
2017,"Ishimoto, Yuichi; Teraoka, Takehiro; Enomoto, Mika",End-of-Utterance Prediction by Prosodic Features and Phrase-Dependency Structure in Spontaneous Japanese Speech,Interspeech 2017,,10.21437/Interspeech.2017-837,https://www.isca-speech.org/archive/interspeech_2017/ishimoto17_interspeech.html,"This study is aimed at uncovering a way that participants in conversation predict end-of-utterance for spontaneous Japanese speech. In spontaneous everyday conversation, the participants must predict the ends of utterances of a speaker to perform smooth turn-taking without too much gap. We consider that they utilize not only syntactic factors but also prosodic factors for the end-of-utterance prediction because of the difﬁculty of prediction of a syntactic completion point in spontaneous Japanese. In previous studies, we found that prosodic features changed signiﬁcantly in the ﬁnal accentual phrase. However, it is not clear what prosodic features support the prediction. In this paper, we focused on dependency structure among bunsetsuphrases as the syntactic factor, and investigated the relation between the phrase-dependency and prosodic features. The results showed that the average fundamental frequency and the average intensity for accentual phrases did not decline until the modiﬁed phrase appeared. Next, to predict the end of utterance from the syntactic and prosodic features, we constructed a generalized linear mixed model. The model provided higher accuracy than using the prosodic features only. These suggest the possibility that prosodic changes and phrase-dependency relations inform the hearer that the utterance is approaching its end.",20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,1681-1685,ISCA,en,prosody,Interspeech 2017
2013,"Jacewicz, Ewa; Fox, Robert Allen",Regional accents affect speech intelligibility in a multitalker environment,Interspeech 2013,,10.21437/Interspeech.2013-494,https://www.isca-speech.org/archive/interspeech_2013/jacewicz13_interspeech.html,"The current understanding of listener sensitivity to regional accents comes from examination of speech processing in quiet and in noise. This study had two aims: 1) to examine the intelligibility of regional accents in a multitalker environment, and 2) to explore a methodological question of whether systematic regional features can be detected in the productions of only one representative talker or whether several talkers are necessary to provide the suitable sample. Two American English dialects, General American English and Southern American English, were systematically varied both in the target speech and in the masking babble at three sound-tonoise ratios. The results showed that regional accents did influence listeners’ performance in a multitalker environment. Intelligibility was hampered when the target and the masker shared common dialect features or when listeners’ heard their own dialect in the masking babble. Southern American was a more intelligible variety than General American, which can be attributable to a set of specific acoustic phonetic features. The study found that systematic regional features can be reliably detected in the production of only one representative talker.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,2081-2085,ISCA,en,L1,Interspeech 2013
2021,"Jahchan, Nataly; Barbier, Florentin; Gita, Ariyanidevi Dharma; Khelif, Khaled; Delpech, Estelle",Towards an Accent-Robust Approach for ATC Communications Transcription,Interspeech 2021,,10.21437/Interspeech.2021-333,https://www.isca-speech.org/archive/interspeech_2021/jahchan21_interspeech.html,"Air Traffic Control (ATC) communications are a typical example where Automatic Speech Recognition could face various challenges: audio data are quite noisy due to the characteristics of capturing mechanisms. All speakers involved use a specific English-based phraseology and a significant number of pilots and controllers are non-native English speakers. The aim of this work is to enhance pilot-ATC communications by adding a Speech to Text (STT) capability that will transcribe ATC speech into text on the cockpit interfaces to help the pilot understand ATC speech in a more optimal manner (be able to verify what he/she heard on the radio by looking at the text transcription, be able to decipher non-native English accents from controllers, not lose time asking the ATC to repeat the message several times). In this paper, we first describe an accent analysis study which was carried out both on a theoretical level but also with the help of feedback from several hundred airline pilots. Then, we present the dataset that was set up for this work. Finally, we describe the experiments we have implemented and the impact of the speaker accent on the performance of a speech to text engine.",30/08/2021,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,3281-3285,ISCA,en,L1-or-L2,Interspeech 2021
2018,"Jain, Abhinav; Upreti, Minali; Jyothi, Preethi",Improved Accented Speech Recognition Using Accent Embeddings and Multi-task Learning,Interspeech 2018,,10.21437/Interspeech.2018-1864,https://www.isca-speech.org/archive/interspeech_2018/jain18_interspeech.html,"One of the major remaining challenges in modern automatic speech recognition (ASR) systems for English is to be able to handle speech from users with a diverse set of accents. ASR systems that are trained on speech from multiple English accents still underperform when confronted with a new speech accent. In this work, we explore how to use accent embeddings and multi-task learning to improve speech recognition for accented speech. We propose a multi-task architecture that jointly learns an accent classiﬁer and a multi-accent acoustic model. We also consider augmenting the speech input with accent information in the form of embeddings extracted by a separate network. These techniques together give signiﬁcant relative performance improvements of 15% and 10% over a multi-accent baseline system on test sets containing seen and unseen accents, respectively.",02/09/2018,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,2454-2458,ISCA,en,L1,Interspeech 2018
2019,"Jain, Abhinav; Singh, Vishwanath P.; Rath, Shakti P.",A Multi-Accent Acoustic Model Using Mixture of Experts for Speech Recognition,Interspeech 2019,,10.21437/Interspeech.2019-1667,https://www.isca-speech.org/archive/interspeech_2019/jain19_interspeech.html,"A major challenge in Automatic Speech Recognition(ASR) systems is to handle speech from a diverse set of accents. A model trained using a single accent performs rather poorly when confronted with different accents. One of the solutions is a multicondition model trained on all the accents. However the performance improvement in this approach might be rather limited. Otherwise, accent-speciﬁc models might be trained but they become impractical as number of accents increases. In this paper, we propose a novel acoustic model architecture based on Mixture of Experts (MoE) which works well on multiple accents without having the overhead of training separate models for separate accents. The work is based on our earlier work, termed as MixNet, where we showed performance improvement by separation of phonetic class distributions in the feature space. In this paper, we propose an architecture that helps to compensate phonetic and accent variabilities which helps in even better discrimination among the classes. These variabilities are learned in a joint frame-work, and produce consistent improvements over all the individual accents, amounting to an overall 18% relative improvement in accuracy compared to baseline trained in multi-condition style.",15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,779-783,ISCA,en,L1-or-L2,Interspeech 2019
2009,"Jeon, Je Hun; Liu, Yang",Automatic accent detection: effect of base units and boundary information,Interspeech 2009,,10.21437/Interspeech.2009-70,https://www.isca-speech.org/archive/interspeech_2009/jeon09_interspeech.html,"Automatic prominence or pitch accent detection is important as it can perform automatic prosodic annotation of speech corpora, as well as provide additional features in other tasks such as keyword detection. In this paper, we evaluate how accent detection performance changes according to different base units and what kind of boundary information is available. We compare word, syllable, and vowel-based units when their boundaries are provided. We also automatically estimate syllable boundaries using energy contours when phone-level alignment is available. In addition, we utilize a sliding window with fixed length under the condition of unknown boundaries. Our experiments show that when boundary information is available, using longer base unit achieves better performance. In the case of no boundary information, using a moving window with a fixed size achieves similar performance to using syllable information on word-level evaluation, suggesting that accent detection can be performed without relying on a speech recognizer to generate boundaries.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,180-183,ISCA,en,prosody,Interspeech 2009
2016,"Jiao, Yishan; Tu, Ming; Berisha, Visar; Liss, Julie",Accent Identification by Combining Deep Neural Networks and Recurrent Neural Networks Trained on Long and Short Term Features,Interspeech 2016,,10.21437/Interspeech.2016-1148,https://www.isca-speech.org/archive/interspeech_2016/jiao16_interspeech.html,"Automatic identiﬁcation of foreign accents is valuable for many speech systems, such as speech recognition, speaker identiﬁcation, voice conversion, etc. The INTERSPEECH 2016 Native Language Sub-Challenge is to identify the native languages of non-native English speakers from eleven countries. Since differences in accent are due to both prosodic and articulation characteristics, a combination of long-term and short-term training is proposed in this paper. Each speech sample is processed into multiple speech segments with equal length. For each segment, deep neural networks (DNNs) are used to train on long-term statistical features, while recurrent neural networks (RNNs) are used to train on short-term acoustic features. The result for each speech sample is calculated by linearly fusing the results from the two sets of networks on all segments. The performance of the proposed system greatly surpasses the provided baseline system. Moreover, by fusing the results with the baseline system, the performance can be further improved.",08/09/2016,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,2388-2392,ISCA,en,L2,Interspeech 2016
2005,"Jilka, Matthias",Exploration of different types of intonational deviations in foreign-accented and synthesized speech,Interspeech 2005,,10.21437/Interspeech.2005-44,https://www.isca-speech.org/archive/interspeech_2005/jilka05_interspeech.html,"The study provides an analysis of the basic manifestations of intonational deviations in foreign-accented (American English accent in German) and synthesized speech. It takes into account the crucial influence of the used model of intonation description and makes a major distinction between individual deviations that cause the impression of foreignness or unnaturalness immediately when they occur, and others that do so only when an accumulation of several such deviations does not allow for a meaningful interpretation anymore. It is argued that this is due to the high variability allowed in prosodic contexts. A closer description of the first group of deviations includes the transfer of categories and of the phonetic realizations of categories as well as a discussion of seemingly unmotivated errors and the most likely causes of intonation errors in synthesized speech. Finally, it is shown that in the case of foreign accent the language-specific manifestations of the presented deviations combine to create a characteristic overall impression of foreignness that is recognizable independently of the segmental content of an utterance.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,2393-2396,ISCA,en,L2,Interspeech 2005
2006,"Jilka, Matthias; Möbius, Bernd",Towards a comprehensive investigation of factors relevant to peak alignment using a unit selection corpus,Interspeech 2006,,10.21437/Interspeech.2006-403,https://www.isca-speech.org/archive/interspeech_2006/jilka06_interspeech.html,"This paper aims to demonstrate the use of a unit selection corpus, the IMS German Festival synthesis system [1], in carrying out a comprehensive investigation of factors influencing specific aspects of the phonetic realization of tonal categories. The study restricts itself to the alignment of peaks in H*L pitch accents in German. First results confirm not only well-known effects of syllable structure, e.g., peaks occurring relatively early when there is a sonorant onset or relatively late when there is a sonorant in the coda, but also attest to the special status of the nuclear pitch accent vs. accents occurring earlier in the intonation phrase. Furthermore, instances of H*L in syllables directly at the phrase boundaries (initial or final) are shown to behave significantly differently from those that are located farther away. A similar effect is observed when another pitch accent follows the H*L peak in the very next syllable as opposed to a distance of two or more syllables. In these cases it also matters whether a low or high target is following (the peaks occur relatively later when followed by a L target). The results should have the benefit of both describing the specific characteristics of the voice providing the corpus (allowing a more detailed phonetic realization of tonal categories during the synthesis process) and offering general insights into which factors are relevant to the alignment of H*L peaks in German.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,paper 1565-Wed3BuP.8-0,ISCA,en,prosody,Interspeech 2006
2016,"Jügler, Jeanin; Zimmerer, Frank; Trouvain, Jürgen; Möbius, Bernd",The Perceptual Effect of L1 Prosody Transplantation on L2 Speech: The Case of French Accented German,Interspeech 2016,,10.21437/Interspeech.2016-1268,https://www.isca-speech.org/archive/interspeech_2016/jugler16_interspeech.html,"Research has shown that language learners are not only challenged by segmental differences between their native language (L1) and the second language (L2). They also have problems with the correct production of suprasegmental structures, like phone/syllable duration and the realization of pitch. These difﬁculties often lead to a perceptible foreign accent. This study investigates the inﬂuence of prosody transplantation on foreign accent ratings. Syllable duration and pitch contour were transferred from utterances of a male and female German native speaker to utterances of ten French native speakers speaking German. Acoustic measurements show that French learners spoke with a signiﬁcantly lower speaking rate. As expected, results of a perception experiment judging the accentedness of 1) German native utterances, 2) unmanipulated and 3) manipulated utterances of French learners of German suggest that the transplantation of the prosodic features syllable duration and pitch leads to a decrease in accentedness rating. These ﬁndings conﬁrm results found in similar studies investigating prosody transplantation with different L1 and L2 and provide a beneﬁcial technique for (computer-assisted) pronunciation training.",08/09/2016,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,67-71,ISCA,en,L2,Interspeech 2016
2022,"Jun, Sun-Ah; Zubizarreta, Maria Luisa",Paraguayan Guarani: Tritonal pitch accent and Accentual Phrase,Interspeech 2022,,10.21437/Interspeech.2022-11257,https://www.isca-speech.org/archive/interspeech_2022/jun22_interspeech.html,"This paper investigates the intonation system of Paraguayan Guarani in the Autosegmental-metrical (AM) framework of intonational phonology. Previous work on Guarani intonation stated that Guarani has two types of pitch accent, rising (L*+H or LH) and falling (H+L* or HL), and there is no prosodic unit between a word and an Intonational Phrase. But these findings seem to have resulted from the limitation of the data examined. When longer words/sentences and various syntactic structures are examined, it was found that Guarani has one type of pitch accent, a tritonal HLH*, and has an Accentual Phrase (AP). The tonal pattern of AP is /H HLH* Ha/, i.e., it has one pitch accent and its edges are marked by a H tone. However, because the pitch accent is tritonal, AP edge tones are realized only when there are unstressed syllables before and after the syllables carrying the tritonal pitch accent, suggesting that the function of AP boundary tone is not marking word prominence as in other AP languages. Instead, an important function of Guarani AP seems to mark specific syntactic categories and groupings. These findings are compared with other AP languages and discussed in terms of the typology of word-prominence type.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,5303-5307,ISCA,en,prosody,Interspeech 2022
2011,"Kalaldeh, Raya",Tonal alignment defined: the case of southern irish English,Interspeech 2011,,10.21437/Interspeech.2011-452,https://www.isca-speech.org/archive/interspeech_2011/kalaldeh11_interspeech.html,"This paper proposes to define tonal alignment features as either intrinsic; the default alignment, or extrinsic; the shifts away from the default alignment due to prosodic contextual factors. Intrinsic alignment is different for pre-nuclear (PN) and nuclear (N) accents. This distinction is illustrated for a variety of Irish English (IrE), Drogheda English (DroghE) where the PN and the N peaks of H* accents are intrinsically aligned at a time point 70% ~80% and 60% ~75% into the vowel of the accented syllable, respectively. Extrinsic alignment shifts of PN and N peaks are very small not exceeding the accented vowel boundaries.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,1373-1376,ISCA,en,prosody,Interspeech 2011
2011,"Kamper, Herman; Niesler, Thomas","Multi-accent speech recognition of Afrikaans, black and white varieties of south african English",Interspeech 2011,,10.21437/Interspeech.2011-798,https://www.isca-speech.org/archive/interspeech_2011/kamper11_interspeech.html,"In this paper we investigate speech recognition performance of systems employing several accent-speciﬁc recognisers in parallel for the simultaneous recognition of multiple accents. We compare these systems with oracle systems, in which test utterances are presented to matching accent-speciﬁc recognisers, and with accent-independent systems, in which acoustic and language model training data are pooled. Our investigation is based on Afrikaans (AE), Black (BE) and White (EE) accents of South African English. We ﬁnd that, when accent is classiﬁed on a per-utterance basis, parallel systems outperform oracle systems for the AE+EE accent pair while the opposite is observed for BE+EE. When accent identiﬁcation is carried out on a per-speaker basis, oracle or better performance is obtained for both accent pairs. Furthermore, parallel systems based on multi-accent acoustic modelling, which allows selective crossaccent sharing of acoustic training data, outperform parallel systems using accent-speciﬁc acoustic models. The former also yields better performance than accent-independent recognition, which uses pooled acoustic and language models.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,3189-3192,ISCA,en,L1,Interspeech 2011
2016,"Kapolowicz, Michelle R.; Montazeri, Vahid; Assmann, Peter F.",The Role of Spectral Resolution in Foreign-Accented Speech Perception,Interspeech 2016,,10.21437/Interspeech.2016-1585,https://www.isca-speech.org/archive/interspeech_2016/kapolowicz16_interspeech.html,"Several studies have shown that diminished spectral resolution leads to poorer speech recognition in adverse listening conditions such as competing background noise or in cochlear implants. Although intelligibility is also reduced when the talker has a foreign accent, it is unknown how limited spectral resolution interacts with foreign-accent perception. It is hypothesized that limited spectral resolution will further impair perception of foreign-accented speech. To test this, we assessed the contribution of spectral resolution to the intelligibility of foreign-accented speech by varying the number of spectral channels in a tone vocoder. We also examined listeners’ abilities to discriminate between native and foreign-accented speech in each condition to determine the effect of reduced spectral resolution on accent detection. Results showed that increasing the spectral resolution improves intelligibility for foreign-accented speech while also improving listeners’ ability to detect a foreign accent but not to the level of accuracy for broadband speech. Results also reveal a correlation between intelligibility and accent detection. Overall, results suggest that greater spectral resolution is needed for perception of foreign-accented speech compared to native speech.",08/09/2016,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,3289-3293,ISCA,en,L2,Interspeech 2016
2011,"Karhila, Reima; Wester, Mirjam",Rapid adaptation of foreign-accented HMM-based speech synthesis,Interspeech 2011,,10.21437/Interspeech.2011-701,https://www.isca-speech.org/archive/interspeech_2011/karhila11_interspeech.html,"This paper presents ﬁndings of listeners’ perception of speaker identity in synthetic speech. Speciﬁcally, we investigated what the effect is on the perceived identity of a speaker when using differently accented average voice models and limited amounts (ﬁve and ﬁfteen sentences) of a speaker’s data to create the synthetic stimuli. A speaker discrimination task was used to measure speaker identity. Native English listeners were presented with natural and synthetic speech stimuli in English and were asked to decide whether they thought the sentences were spoken by the same person or not. An accent rating task was also carried out to measure the perceived accents of the synthetic speech stimuli. The results show that listeners, for the most part, perform as well at speaker discrimination when the stimuli have been created using ﬁve or ﬁfteen adaptation sentences as when using 105 sentences. Furthermore, the accent of the average voice model does not affect listeners’ speaker discrimination performance even though the accent rating task shows listeners are perceiving different accents in the synthetic stimuli. Listeners do not base their speaker similarity decisions on perceived accent.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,2801-2804,ISCA,en,L2,Interspeech 2011
2010,"Karlsson, Anastasia; House, David; Svantesson, Jan-Olof; Tayanin, Damrong",Influence of lexical tones on intonation in kammu,Interspeech 2010,,10.21437/Interspeech.2010-499,https://www.isca-speech.org/archive/interspeech_2010/karlsson10_interspeech.html,"The aim of this study is to investigate how the presence of lexical tones influences the realization of focal accent and sentence intonation. The language studied is Kammu, a language particularly well suited for the study as it has both tonal and non-tonal dialects. The main finding is that lexical tone exerts an influence on both sentence and focal accent in the tonal dialect to such a strong degree that we can postulate a hierarchy where lexical tone is strongest followed by sentence accent, with focal accent exerting the weakest influence on the F0 contour.",26/09/2010,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,1740-1743,ISCA,en,prosody,Interspeech 2010
2007,"Kawatsu, Hiromi; Ohno, Sumio",An analysis of individual differences in the f0 contour and the duration of anger utterances at several degrees,Interspeech 2007,,10.21437/Interspeech.2007-602,https://www.isca-speech.org/archive/interspeech_2007/kawatsu07_interspeech.html,"Taking up anger emotion expressed by speech, prosodic features were analyzed in order to ﬁnd out the relationship between the degree of anger and manifestations on the speech signal in terms of individual differences. As a result of analysis, there were some common features among the speakers, although there were some speaker-dependent features. About the baseline frequency and the magnitude of the ﬁrst phrase command, common tendencies were found in all speakers. The amplitude of the accent command increases as the emotional degree increases on the whole. Some speakers emphasized accent commands at all positions within a sentence, some emphasized only near the end of a sentence. Speaking rate at the 1st and 4th phrases were faster than those at the 2nd and 3rd phrases for the utterance with emotion, although there was an individual difference in the effect of the emotional degree. It is very interesting that two aspects in prosody, i.e., an F0 contour and a speaking rate, might be complement each other in order to represent a difference of emotional degrees.",27/08/2007,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,2213-2216,ISCA,en,prosody,Interspeech 2007
2020,"Khandelwal, Kartik; Jyothi, Preethi; Awasthi, Abhijeet; Sarawagi, Sunita",Black-Box Adaptation of ASR for Accented Speech,Interspeech 2020,,10.21437/Interspeech.2020-3162,https://www.isca-speech.org/archive/interspeech_2020/khandelwal20_interspeech.html,"We introduce the problem of adapting a black-box, cloud-based ASR system to speech from a target accent. While leading online ASR services obtain impressive performance on mainstream accents, they perform poorly on sub-populations — we observed that the word error rate (WER) achieved by Google’s ASR API on Indian accents is almost twice the WER on US accents. Existing adaptation methods either require access to model parameters or overlay an error correcting module on output transcripts. We highlight the need for correlating outputs with the original speech to ﬁx accent errors. Accordingly, we propose a novel coupling of an open-source accent-tuned local model with the black-box service where the output from the service guides frame-level inference in the local model. Our ﬁne-grained merging algorithm is better at ﬁxing accent errors than existing word-level combination strategies. Experiments on Indian and Australian accents with three leading ASR models as service, show that we achieve upto 28% relative reduction in WER over both the local and service models.",25/10/2020,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,1281-1285,ISCA,en,L1-or-L2,Interspeech 2020
2019,"Kharaman, Mariya; Xu, Manluolan; Eulitz, Carsten; Braun, Bettina",The Processing of Prosodic Cues to Rhetorical Question Interpretation: Psycholinguistic and Neurolinguistics Evidence,Interspeech 2019,,10.21437/Interspeech.2019-2528,https://www.isca-speech.org/archive/interspeech_2019/kharaman19_interspeech.html,"In many languages, rhetorical questions (RQs) are produced with different prosodic realizations than string-identical information-seeking questions (ISQs). RQs typically have longer constituent durations and breathier voice quality than ISQs and differ in nuclear accent type. This paper reports on an identification experiment (Experiment 1) and an EEG experiment (Experiment 2) on German wh-questions. In the identification experiment, we manipulated nuclear pitch accent type, voice quality and constituent duration and participants indicated whether they judged the realization as ISQ or RQ. The results showed additive effects of the three factors, with pitch accent as strongest predictor. In the EEG experiment, participants heard the stimuli in two contexts, triggering an ISQ or RQ (blocked). We manipulated pitch accent type and voice quality, resulting in RQ-coherent and ISQ-coherent stimuli, based on the outcome of Experiment 1. Results showed a prosodic expectancy positivity (PEP) for prosodic realizations that were incoherent with ISQ-contexts with an onset of ∼120ms after the onset of the word with nuclear accent. This effect might reflect the emotional prosodic aspect of RQs. Taken together, participants use prosody to resolve the ambiguity and event-related potentials (ERPs) react to prosodic realizations that do not match contextually triggered expectations.",15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,1218-1222,ISCA,en,prosody,Interspeech 2019
2004,"Kim, Jong-mi; Flynn, Suzanne",What makes a non-native accent?: a study of Korean English,Interspeech 2004,,10.21437/Interspeech.2004-600,https://www.isca-speech.org/archive/interspeech_2004/kim04n_interspeech.html,,04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,1845-1848,ISCA,en,L2,Interspeech 2004
2021,"Kocour, Martin; Veselý, Karel; Blatt, Alexander; Gomez, Juan Zuluaga; Szöke, Igor; Černocký, Jan; Klakow, Dietrich; Motlicek, Petr",Boosting of Contextual Information in ASR for Air-Traffic Call-Sign Recognition,Interspeech 2021,,10.21437/Interspeech.2021-1619,https://www.isca-speech.org/archive/interspeech_2021/kocour21_interspeech.html,"Contextual adaptation of ASR can be very beneﬁcial for multiaccent and often noisy Air-Trafﬁc Control (ATC) speech. Our focus is call-sign recognition, which can be used to track conversations of ATC operators with individual airplanes. We developed a two-stage boosting strategy, consisting of HCLG boosting and Lattice boosting. Both are implemented as WFST compositions and the contextual information is speciﬁc to each utterance. In HCLG boosting we give score discounts to individual words, while in Lattice boosting the score discounts are given to word sequences. The context data have origin in surveillance database of OpenSky Network. From this, we obtain lists of call-signs that are made more likely to appear in the best hypothesis of ASR. This also improves the accuracy of the NLU module that recognizes the call-signs from the best hypothesis of ASR.",30/08/2021,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,3301-3305,ISCA,en,L1-or-L2,Interspeech 2021
2013,"Kohtz, Lea S.; Niebuhr, Oliver",Eliciting speech with sentence lists — a critical evaluation with special emphasis on segmental anchoring,Interspeech 2013,,10.21437/Interspeech.2013-156,https://www.isca-speech.org/archive/interspeech_2013/kohtz13_interspeech.html,"We show on the basis of German that prosodic patterns change in the course of a traditional sentence-list elicitation. Two frequent methods are analyzed: sentence-frame and syntax-frame elicitations. While only the sentences of the sentence-frame elicitation show an increase in speaking rate, both elicitation methods cause a drastic reduction in the alignment variability of nuclear pitch-accent rises. So, the starting point for the idea of segmental anchoring, i.e. the characteristic stable alignment of L and H targets, could primarily be due to a training effect based on the continuous production of analogously constructed or identical carrier sentences. Detailed pitch-accent analyses also offer alternative interpretations for anchoring patterns. Methodologically, in order to avoid training effects in pitchaccent production, our findings suggest using the syntax-frame method and short sentence lists of 40 items or less.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,563-567,ISCA,en,prosody,Interspeech 2013
2014,"Kolluru, BalaKrishna; Wan, Vincent; Latorre, Javier; Yanagisawa, Kayoko; Gales, Mark J. F.",Generating multiple-accent pronunciations for TTS using joint sequence model interpolation,Interspeech 2014,,10.21437/Interspeech.2014-318,https://www.isca-speech.org/archive/interspeech_2014/kolluru14_interspeech.html,"Standard grapheme-to-phoneme (G2P) systems are trained using a homogeneous lexicon, for example one associated with a particular accent. In practice, a synthesis system may be required to handle multiple accents. Furthermore, a speaker rarely has a pure accent; accents vary continuously within and between regions of a country. Generating phonetic sequences for each accent is possible, but combining them to yield a single synthesis pronunciation is highly challenging. To address this problem, this paper considers a space of accents. The bases for these spaces are deﬁned by statistical G2P models in the form of graphone models. A linear combination of these models deﬁne the accent space. By selecting a point in this continuous space, it is possible to specify the accent for an individual speaker. The performance of this approach is evaluated using an accent space deﬁned by American, Scottish and British English. By moving around the accent space, it is shown that it is possible to synthesize speech from all these accents as well as a range of intermediate points.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,1273-1277,ISCA,en,L1-or-L2,Interspeech 2014
2014,"Kolly, Marie-José; Leemann, Adrian; Dellwo, Volker",Foreign accent recognition based on temporal information contained in lowpass-filtered speech,Interspeech 2014,,10.21437/Interspeech.2014-487,https://www.isca-speech.org/archive/interspeech_2014/kolly14_interspeech.html,"Can the foreign accent of a speaker be recognized based on suprasegmental temporal information? For a perception experiment we created stimuli based on German sentences read by six French and six English speakers. These foreignaccented sentences were manipulated by (1) applying a lowpass filter with a cutoff frequency of 300 Hz and (2) applying the same lowpass filter and monotonizing F0. In a between-subject 2AFC perception experiment we tested the accent recognition ability of 15 Swiss German listeners per signal manipulation condition. The results showed that speakers’ native language could be recognized above chance in both conditions. However, listeners obtained significantly lower recognition scores in the monotonized condition. Furthermore, higher recognition scores were obtained for French-accented speech in the monotonized condition, a result that is discussed in light of research on speech rhythm. We further report an effect for speaker within each accent group. The results suggest that suprasegmental temporal information allows for foreign accent recognition to some degree.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:18,2175-2179,ISCA,en,L2,Interspeech 2014
2004,"Komatsu, Masahiko; Sugawara, Tsutomu; Arai, Takayuki",Perceptual discrimination of prosodic types and their preliminary acoustic analysis,Interspeech 2004,,10.21437/Interspeech.2004-764,https://www.isca-speech.org/archive/interspeech_2004/komatsu04_interspeech.html,"A perceptual discrimination test was conducted to investigate whether humans can discriminate prosodic types solely based on suprasegmental acoustic cues. Excerpts from Chinese, English, Spanish, and Japanese, differing in lexical accent types and rhythm types, were used. From these excerpts, “source” signals of the source-filter model, differing in F0, intensity, and HNR, were created and used in a perceptual experiment. In general, the results indicated that humans can discriminate these prosodic types and that the discrimination is easier if more acoustic information is available. Further, the results showed that languages with similar rhythm types are difficult to discriminate (i.e., Chinese-English, EnglishSpanish, and Spanish-Japanese). As to accent types, tonal/nontonal contrast was easy to detect. We also conducted a preliminary acoustic analysis of the experimental stimuli and found that quick F0 fluctuations in Chinese contribute to the perceptual discrimination of tonal/non-tonal accents.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,3045-3048,ISCA,en,prosody,Interspeech 2004
2004,"Kong, Eunjong",The role of pitch range variation in the discourse structure and intonation structure of Korean,Interspeech 2004,,10.21437/Interspeech.2004-757,https://www.isca-speech.org/archive/interspeech_2004/kong04_interspeech.html,"This study explores pitch range variation in Korean spontaneous narratives and read transcripts of the same narratives. There are two research goals. One is to examine whether pitch range variation helps mark discourse segment boundaries and signal the hierarchy of discourse segment purposes. Another is to see whether categorical differences in pitch range encode the contrast between the two intonationally marked units in the Korean prosodic hierarchy. The narratives were prosodically annotated for Accentual and Intonational Phrase boundaries and the F0 maximum was measured in each Accentual Phrase. Comparing F0 maxima across adjacent phrases shows that pitch range is reset at discourse segment boundaries in spontaneous speech, and also that size of the pitch range reset reflects the hierarchy of discourse segment levels. By contrast, there is no systematic difference in pitch range resetting values between higher Intonational Phrases as compared to lower Accentual Phrase boundaries.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,3017-3020,ISCA,en,prosody,Interspeech 2004
2014,"Koriyama, Tomoki; Suzuki, Hiroshi; Nose, Takashi; Shinozaki, Takahiro; Kobayashi, Takao",Accent type and phrase boundary estimation using acoustic and language models for automatic prosodic labeling,Interspeech 2014,,10.21437/Interspeech.2014-193,https://www.isca-speech.org/archive/interspeech_2014/koriyama14_interspeech.html,"This paper proposes an automatic prosodic labeling technique for constructing speech database used for speech synthesis. In the corpus-based Japanese speech synthesis, it is essential to use annotated speech data with prosodic information such as phrase boundaries and accent types. However, manual annotation is generally time-consuming and expensive. To overcome this problem, we propose an estimation technique of accent types and phrase boundaries from speech waveform and its transcribed text using both language and acoustic models. We use conditional random ﬁeld (CRF) for the language model, and HMM for the acoustic model which has shown to be effective in prosody modeling in speech synthesis. By introducing HMM, continuously changing features of F0 contours are modeled well and this results in higher estimation accuracy than conventional techniques that use simple polygonal line approximation of F0 contours.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,2337-2341,ISCA,en,prosody,Interspeech 2014
2019,"Koriyama, Tomoki; Kobayashi, Takao",Semi-Supervised Prosody Modeling Using Deep Gaussian Process Latent Variable Model,Interspeech 2019,,10.21437/Interspeech.2019-2497,https://www.isca-speech.org/archive/interspeech_2019/koriyama19_interspeech.html,"This paper proposes a semi-supervised speech synthesis framework in which prosodic labels of training data are partially annotated. When we construct a text-to-speech (TTS) system, it is crucial to use appropriately annotated prosodic labels. For this purpose, manually annotated ones would provide a good result, but it generally costs much time and patience. Although recent studies report that end-to-end TTS framework can generate natural-sounding prosody without using prosodic labels, this does not always appear in arbitrary languages such as pitch accent ones. Alternatively, we propose an approach to utilizing a latent variable representation of prosodic information. In the latent variable representation, we employ deep Gaussian process (DGP), a deep Bayesian generative model. In the proposed semi-supervised learning framework, the posterior distributions of latent variables are inferred from linguistic and acoustic features, and the inferred latent variables are utilized to train a DGP-based regression model of acoustic features. Experimental results show that the proposed framework can give a comparable performance with the case using fully-annotated speech data in subjective evaluation even if the prosodic information of pitch accent is limited.",15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,4450-4454,ISCA,en,prosody,Interspeech 2019
2022,"Kukk, Kunnar; Alumäe, Tanel",Improving Language Identification of Accented Speech,Interspeech 2022,,10.21437/Interspeech.2022-10455,https://www.isca-speech.org/archive/interspeech_2022/kukk22_interspeech.html,"Language identification from speech is a common preprocessing step in many spoken language processing systems. In recent years, this field has seen fast progress, mostly due to the use of self-supervised models pretrained on multilingual data and the use of large training corpora. This paper shows that for speech with a non-native or regional accent, the accuracy of spoken language identification systems drops dramatically, and that the accuracy of identifying the language is inversely correlated with the strength of the accent. We also show that using the output of a lexicon-free speech recognition system of the particular language helps to improve language identification performance on accented speech by a large margin, without sacrificing accuracy on native speech. We obtain relative error rate reductions ranging from to 35 to 63% over the state-of-the-art model across several non-native speech datasets.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,1288-1292,ISCA,en,L1-or-L2,Interspeech 2022
2020,"Kyriakopoulos, Konstantinos; Knill, Kate M.; Gales, Mark J.F.",Automatic Detection of Accent and Lexical Pronunciation Errors in Spontaneous Non-Native English Speech,Interspeech 2020,,10.21437/Interspeech.2020-2881,https://www.isca-speech.org/archive/interspeech_2020/kyriakopoulos20_interspeech.html,"Detecting individual pronunciation errors and diagnosing pronunciation error tendencies in a language learner based on their speech are important components of computer-aided language learning (CALL). The tasks of error detection and error tendency diagnosis become particularly challenging when the speech in question is spontaneous and particularly given the challenges posed by the inconsistency of human annotation of pronunciation errors. This paper presents an approach to these tasks by distinguishing between lexical errors, wherein the speaker does not know how a particular word is pronounced, and accent errors, wherein the candidate’s speech exhibits consistent patterns of phone substitution, deletion and insertion. Three annotated corpora of non-native English speech by speakers of multiple L1s are analysed, the consistency of human annotation investigated and a method presented for detecting individual accent and lexical errors and diagnosing accent error tendencies at the speaker level.",25/10/2020,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,3052-3056,ISCA,en,L2,Interspeech 2020
2015,"Langarani, Mahsa Sadat Elyasi; Santen, Jan van; Mohammadi, Seyed Hamidreza; Kain, Alexander",Data-driven foot-based intonation generator for text-to-speech synthesis,Interspeech 2015,,10.21437/Interspeech.2015-370,https://www.isca-speech.org/archive/interspeech_2015/langarani15_interspeech.html,"We propose a method for generating F0 contours for text-tospeech synthesis. Training speech is automatically annotated in terms of feet, with features indicating start and end times of syllables, foot position, and foot length. During training, we ﬁt a foot-based superpositional intonation model comprising accent curves and phrase curves. During synthesis, the method searches for stored, ﬁtted accent curves associated with feet that optimally match to-be-synthesized feet in the feature space, while minimizing differences between successive accent curve heights. We tested the proposed method against the HMMbased Speech Synthesis System (HTS) by imposing contours generated by these two methods onto natural speech, and obtaining quality ratings. Test sets varied in how well they were covered by the training data. Contours generated by the proposed method were preferred over HTS-generated contours, especially for poorly-covered test items. To test the new method’s usefulness for processing marked-up text input, we compared its ability to convey contrastive stress with that of natural speech recordings, and found no difference. We conclude that the new method holds promise for generating comparatively highquality F0 contours, especially when training data are sparse and when mark-up is required.",06/09/2015,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,1596-1600,ISCA,en,prosody,Interspeech 2015
2014,"Lecumberri, María Luisa García; Barra-Chicote, Roberto; Ramón, Rubén Pérez; Yamagishi, Junichi; Cooke, Martin",Generating segmental foreign accent,Interspeech 2014,,10.21437/Interspeech.2014-324,https://www.isca-speech.org/archive/interspeech_2014/lecumberri14_interspeech.html,"For most of us, speaking in a non-native language involves deviating to some extent from native pronunciation norms. However, the detailed basis for foreign accent (FA) remains elusive, in part due to methodological challenges in isolating segmental from suprasegmental factors. The current study examines the role of segmental features in conveying FA through the use of a generative approach in which accent is localised to single consonantal segments. Three techniques are evaluated: the ﬁrst requires a highly-proﬁciency bilingual to produce words with isolated accented segments; the second uses cross-splicing of context-dependent consonants from the non-native language into native words; the third employs hidden Markov model synthesis to blend voice models for both languages. Using English and Spanish as the native/non-native languages respectively, listener cohorts from both languages identiﬁed words and rated their degree of FA. All techniques were capable of generating accented words, but to differing degrees. Naturally-produced speech led to the strongest FA ratings and synthetic speech the weakest, which we interpret as the outcome of over-smoothing. Nevertheless, the ﬂexibility offered by synthesising localised accent encourages further development of the method.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,1302-1306,ISCA,en,L2,Interspeech 2014
2013,"Lee, Albert; Xu, Yi; Prom-on, Santitham",Mora-based pre-low raising in Japanese pitch accent,Interspeech 2013,,10.21437/Interspeech.2013-760,https://www.isca-speech.org/archive/interspeech_2013/lee13e_interspeech.html,"This study is an attempt to understand the phonetic properties of pitch accent conditions in Japanese as related to the two observed versions of H tones. We tested the hypothesis that the higher version (accented H) results from pre-low raising (PLR) rather than being inherently higher. Correlation analysis reveals an inverse relation between accent peak and the following low tone, and that the strength of such correlations is affected by both peak-to-word-end distance (categorical effect) and within-mora time pressure (gradient), but the two effects work in opposite directions. We take this as evidence that the former effect is due to mora-level pre-planning while the latter is mechanical. These results suggest that in Japanese a low pitch target raises the preceding high target through anticipatory dissimilation. The findings of this study extend our previous understanding of the mechanisms of pitch production.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,3532-3536,ISCA,en,prosody,Interspeech 2013
2015,"Leemann, Adrian; Bernardasci, Camilla; Nolan, Francis",The effect of speakers' regional varieties on listeners' decision-making,Interspeech 2015,,10.21437/Interspeech.2015-385,https://www.isca-speech.org/archive/interspeech_2015/leemann15_interspeech.html,"It has been widely reported that speech provides cues to a speaker’s regional background. Little is known about how such cues influence human behavior, however. In the present study we used a matched-guise design to test how speakers’ regional accents affect listeners’ decision-making. In three scenarios, 72 subjects from three regions in Switzerland were asked to choose either the Standard German, Bern, or Zurich German speaker when asked to select a secretary, surgeon, or travel companion. Results revealed that preferences differed depending on the scenario. We further report two results that have not been described before: (1) the Standard accent was least preferred in all scenarios; (2) in-group favoritism seems to apply only partially to the Swiss context: the Zurich variety was the most preferred variety for all listener groups. We discuss implications from the point of view of accent prestige and social identity theory.",06/09/2015,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,1670-1674,ISCA,en,L1,Interspeech 2015
2022,"Lesnichaia, Mariia; Mikhailava, Veranika; Bogach, Natalia; Lezhenin, Iurii; Blake, John; Pyshkin, Evgeny",Classification of Accented English Using CNN Model Trained on Amplitude Mel-Spectrograms,Interspeech 2022,,10.21437/Interspeech.2022-462,https://www.isca-speech.org/archive/interspeech_2022/lesnichaia22_interspeech.html,"Automatic speech recognition is hindered by the linguistic differences occurring in accented speech. This paper advances a classification method for accented speech using a CNN-based model trained and tested on English with Germanic, Romance and Slavic accents. The input feature set was examined to find the optimal combination of time-frequency and energy characteristics of speech fed into the machine learning model. We also tuned model hyperparameters and the dimensionality of input features. We argue that mel-scale amplitude spectrograms on a liner scale appear more powerful in accent classification tasks compared to conventional feature sets based on MFCCs and raw spectrograms. Our models used only sparse data from the Speech Accent Archive, yet produced state-of-the-art classification results for English with Germanic, Romance and Slavic accents. The accuracy of our models trained on linear scale amplitude mel-spectrograms ranged from 0.964 to 0.987, outperforming existing models classifying accents using the same dataset.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,3669-3673,ISCA,en,L1-or-L2,Interspeech 2022
2005,"Levow, Gina-Anne",Context in multi-lingual tone and pitch accent recognition,Interspeech 2005,,10.21437/Interspeech.2005-552,https://www.isca-speech.org/archive/interspeech_2005/levow05_interspeech.html,"Tone and intonation play a crucial role across many languages. However, the use and structure of tone varies widely, ranging from lexical tone which determines word identity to pitch accent signalling information status. In this paper, we employ a uniform representation of acoustic features for recognition of both Mandarin tone and English pitch accent. The representation captures both local tone height and shape as well as contextual coarticulatory and phrasal inﬂuences. By exploiting multiclass Support Vector Machines as a discriminative classiﬁer, we achieve competitive rates of tone and pitch accent recognition. We further demonstrate the greater importance of modeling preceding local context, which yields up to 24% reduction in error over modeling the following context.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,1809-1812,ISCA,en,prosody,Interspeech 2005
2006,"Li, Aijun; Fang, Qiang; Xiong, Ziyu","Phonetic research on accented Chinese in three dialectal regions: Shanghai, Wuhan and Xiamen",Interspeech 2006,,10.21437/Interspeech.2006-245,https://www.isca-speech.org/archive/interspeech_2006/li06e_interspeech.html,"There are 10 major dialects in China. Most people in dialectal regions are bilingual speakers, i.e. native dialect and Mandarin. Although lots of people can speak Mandarin, they speak it with different accents (called regional accented Chinese in this paper) depending on how well they grasp the language. In this study, we categorize the regional accented Chinese into 3 levels of accents according to phonetic annotation and subjective evaluation on a regional accented speech corpus of three regions: Shanghai, Wuhan and Xiamen. Three accent evaluation methods, namely segmental annotation, clustering on phonetic annotation and subjective evaluation, are compared based on phonetic error rates. The results show that objective evaluation score based on segmental pronunciation is higher than subjective evaluation for the same speaker. This implies that supra-segmental features play an important role in rating accent degree and segmental features alone are not enough for objective evaluation. In accent level criterion, the errors from prosodic and segmental aspects are not equal and the percentage of these two parts are various for different regional speakers. The result is helpful for machine evaluation, L2 teaching and acquisition.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,paper 1143-Mon3FoP.4-0,ISCA,en,L1,Interspeech 2006
2011,"Li, Kun; Zhang, Shuang; Li, Mingxing; Lo, Wai-Kit; Meng, Helen",Prominence model for prosodic features in automatic lexical stress and pitch accent detection,Interspeech 2011,,10.21437/Interspeech.2011-528,https://www.isca-speech.org/archive/interspeech_2011/li11h_interspeech.html,"A prominence model is proposed for enhancing prosodic features in automatic lexical stress and pitch accent detection. We make use of a loudness model and incorporate differential pitch values to improve conventional features. Experiments show that these new prosodic features can improve the detection of lexical stress and pitch accent by about 6%. We further employ a prominence model to take into account of effects from neighboring syllables. For pitch accent detection, we achieve a further performance improvement from 80.61% to 83.30%. For lexical stress detection, we achieve performance improvements in (i) classification of primary, secondary and unstressed syllables (from 76.92% to 78.64%), as well as (ii) determining the presence or absence of primary stress (from 86.99% to 89.80%).",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,2009-2012,ISCA,en,prosody,Interspeech 2011
2020,"Li, Yanping; Best, Catherine T.; Tyler, Michael D.; Burnham, Denis",Tone Variations in Regionally Accented Mandarin,Interspeech 2020,,10.21437/Interspeech.2020-1235,https://www.isca-speech.org/archive/interspeech_2020/li20ja_interspeech.html,"The present study investigated tone variations in regionally accented Mandarin (i.e., Standard Mandarin [SM] spoken by dialectal Chinese speakers) as influenced by the varying tone systems of their native dialects. 12 female speakers, four each from Guangzhou, Shanghai and Yantai, were recruited to produce monosyllabic words in SM that included minimal contrasts among the four Mandarin lexical tones. Since SM developed from the Beijing dialect, their pronunciations were compared to the same Mandarin words produced by four Beijing female speakers. Regional Mandarin speakers successfully produced the four Mandarin lexical tones, but their productions varied from SM. Two crucial acoustic measures for Mandarin lexical tones, F0 (fundamental frequency) and duration values, were fitted into linear mixed-effects models on differences between regional and Beijing accents. Regional speakers had longer word duration and different F0 height when producing SM, resulting in variations in Mandarin lexical tones across the regional accents. These findings shed light on regional accent variations in Mandarin lexical tones and lay a foundation for deeper understanding of their impact on perception of accented Mandarin lexical tones by native (Beijing) Mandarin listeners.",25/10/2020,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,4158-4162,ISCA,en,L1,Interspeech 2020
2005,"Lintfert, Britta; Wokurek, Wolfgang",Voice quality dimensions of pitch accents,Interspeech 2005,,10.21437/Interspeech.2005-48,https://www.isca-speech.org/archive/interspeech_2005/lintfert05_interspeech.html,,04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,2409-2412,ISCA,en,prosody,Interspeech 2005
2005,"Liu, Yi; Fung, Pascale",Acoustic and phonetic confusions in accented speech recognition,Interspeech 2005,,10.21437/Interspeech.2005-147,https://www.isca-speech.org/archive/interspeech_2005/liu05_interspeech.html,"Accented speech recognition is more challenging than standard speech recognition due to the effects of phonetic and acoustic confusions. Phonetic confusion in accented speech occurs when an expected phone is pronounced as a different one, which leads to erroneous recognition. Acoustic confusion occurs when the pronounced phone is found to lie acoustically between two baseform models and can be equally recognized as either one. We propose that it is necessary to analyze and model these confusions separately in order to improve accented speech recognition without degrading standard speech recognition. We propose using likelihood ratio test to measure phonetic confusion, and asymmetric acoustic distance to measure acoustic confusion. Only accent-specific phonetic units with low acoustic confusion are used in an augmented pronunciation dictionary, while phonetic models with high acoustic confusion are reconstructed using decision tree merging. Experimental results show that our approach is effective and superior to methods modeling phonetic confusion or acoustic confusion alone in accented speech, with a significant 5.7% absolute WER reduction, without degrading standard speech recognition.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,3033-3036,ISCA,en,L1-or-L2,Interspeech 2005
2006,"Liu, Yi; Fung, Pascale",Multi-accent Chinese speech recognition,Interspeech 2006,,10.21437/Interspeech.2006-34,https://www.isca-speech.org/archive/interspeech_2006/liu06_interspeech.html,"Multiple accents are often present in spontaneous Chinese Mandarin speech as most Chinese have learned Mandarin as a second language. We propose a method to handle multiple accents as well as standard speech in a speaker-independent system by merging auxiliary accent decision trees with standard trees and reconstruct the acoustic model. In our proposed method, tree structures and shape are modified according to accent-specific data while the parameter set of the baseline model remains the same. The effectiveness of this approach is evaluated on Cantonese and Wu accented, as well as standard Mandarin speech. Our method yields a significant 4.4% and 3.3% absolute word error rate reduction without sacrificing the performance on standard Mandarin speech.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,paper 1887-Mon1BuP.8-0,ISCA,en,L1,Interspeech 2006
2020,"Liu, Ruolan; Wen, Xue; Lu, Chunhui; Chen, Xiao",Tone Learning in Low-Resource Bilingual TTS,Interspeech 2020,,10.21437/Interspeech.2020-2180,https://www.isca-speech.org/archive/interspeech_2020/liu20n_interspeech.html,"We present a system for low-resource multi-speaker crosslingual text-to-speech synthesis. In particular, we train with monolingual English and Mandarin speakers and synthesize every speaker in both languages. The Mandarin training data is limited to 15 minutes of speech by a female Mandarin speaker. We identify accent carry-over and mispronunciation in lowresource language as two major challenges in this scenario, and address these issues by tone preservation mechanisms and data augmentation, respectively. We apply these techniques to a recent strong multi-lingual baseline and achieve higher ratings in intelligibility and target accent, but slightly lower ratings in cross-lingual speaker similarity.",25/10/2020,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,2952-2956,ISCA,en,L1-or-L2,Interspeech 2020
2009,"Loots, Linsen; Niesler, Thomas","Data-driven phonetic comparison and conversion between south african, british and american English pronunciations",Interspeech 2009,,10.21437/Interspeech.2009-74,https://www.isca-speech.org/archive/interspeech_2009/loots09_interspeech.html,"We analyse pronunciations in American, British and South African English pronunciation dictionaries. Three analyses are perfomed. First the accuracy is determined with which decision tree based grapheme-to-phoneme (G2P) conversion can be applied to each accent. It is found that there is little difference between the accents in this regard. Secondly, pronunciations are compared by performing pairwise alignments between the accents. Here we ﬁnd that South African English pronunciation most closely matches British English. Finally, we apply decision trees to the conversion of pronunciations from one accent to another. We ﬁnd that pronunciations of unknown words can be more accurately determined from a known pronunciation in a different accent than by means of G2P methods. This has important implications for the development of pronunciation dictionaries in less-resourced varieties of English, and hence also for the development of ASR systems.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,196-199,ISCA,en,L1,Interspeech 2009
2012,"Ludusan, Bogdan; Ziegler, Stefan; Gravier, Guillaume",Integrating stress information in large vocabulary continuous speech recognition,Interspeech 2012,,10.21437/Interspeech.2012-507,https://www.isca-speech.org/archive/interspeech_2012/ludusan12_interspeech.html,"In this paper we propose a novel method for integrating stress information in the decoding step of a speech recognizer. A multiscale rhythm model was used to determine the stress scores for each syllable, which are further used to reinforce paths during search. Two strategies for integrating the stress were employed: the ﬁrst one reinforces paths through all the syllables with a value proportional to the their stress score, while the second one enhances paths passing only through stressed syllables, but with a constant value. The former strategy slightly outperforms the later, bringing a relative improvement of more than 2% over the baseline. Furthermore, the stress information proved to be a robust feature, by performing well even for foreign-accented speech.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,2642-2645,ISCA,en,prosody,Interspeech 2012
2017,"Lundmark, Malin Svensson; Ambrazaitis, Gilbert; Ewald, Otto",Exploring Multidimensionality: Acoustic and Articulatory Correlates of Swedish Word Accents,Interspeech 2017,,10.21437/Interspeech.2017-1502,https://www.isca-speech.org/archive/interspeech_2017/lundmark17_interspeech.html,This study investigates acoustic and articulatory correlates of South Swedish word accents (Accent 1 vs. 2) – a tonal distinction traditionally associated with F0 timing. The study is motivated by previous findings on (i) the acoustic complexity of tonal prosody and (ii) tonal-articulatory interplay in other languages.,20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,3236-3240,ISCA,en,prosody,Interspeech 2017
2017,"Luo, Dean; Luo, Ruxin; Wang, Lixin",Prosody Analysis of L2 English for Naturalness Evaluation Through Speech Modification,Interspeech 2017,,10.21437/Interspeech.2017-332,https://www.isca-speech.org/archive/interspeech_2017/luo17b_interspeech.html,"This study investigates how different prosodic features affect native speakers' naturalness judgement of L2 English speech by Chinese students. Through subjective judgment by native speakers and objectively measured prosodic features, timing and pitch related prosodic features, as well as segmental goodness of pronunciation have been found to play key roles in native speakers' perception of naturalness. In order to eliminate segmental factors, we used accent conversion techniques that modify native reference speech with learners' erroneous prosodic cues without altering segmental properties. Experimental results show that without interference of segmental factors, both timing and pitch features affect naturalness of L2 speech. Timing plays a more crucial role in naturalness than pitch. Accent modification that corrects timing or pitch errors can improve naturalness of the speech.",20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:19,1775-1778,ISCA,en,prosody,Interspeech 2017
2018,"Luong, Hieu-Thi; Wang, Xin; Yamagishi, Junichi; Nishizawa, Nobuyuki",Investigating Accuracy of Pitch-accent Annotations in Neural Network-based Speech Synthesis and Denoising Effects,Interspeech 2018,,10.21437/Interspeech.2018-1227,https://www.isca-speech.org/archive/interspeech_2018/luong18_interspeech.html,"We investigated the impact of noisy linguistic features on the performance of a Japanese speech synthesis system based on neural network that uses WaveNet vocoder. We compared an ideal system that uses manually corrected linguistic features including phoneme and prosodic information in training and test sets against a few other systems that use corrupted linguistic features. Both subjective and objective results demonstrate that corrupted linguistic features, especially those in the test set, affected the ideal system’s performance signiﬁcantly in a statistical sense due to a mismatched condition between the training and test sets. Interestingly, while an utterance-level Turing test showed that listeners had a difﬁcult time differentiating synthetic speech from natural speech, it further indicated that adding noise to the linguistic features in the training set can partially reduce the effect of the mismatch, regularize the model, and help the system perform better when linguistic features of the test set are noisy.",02/09/2018,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,37-41,ISCA,en,prosody,Interspeech 2018
2017,"Maastricht, Lieke van; Zee, Tim; Krahmer, Emiel; Swerts, Marc","L1 Perceptions of L2 Prosody: The Interplay Between Intonation, Rhythm, and Speech Rate and Their Contribution to Accentedness and Comprehensibility",Interspeech 2017,,10.21437/Interspeech.2017-1150,https://www.isca-speech.org/archive/interspeech_2017/maastricht17_interspeech.html,"This study investigates the cumulative effect of (non-)native intonation, rhythm, and speech rate in utterances produced by Spanish learners of Dutch on Dutch native listeners’ perceptions. In order to assess the relative contribution of these language-specific properties to perceived accentedness and comprehensibility, speech produced by Spanish learners of Dutch was manipulated using transplantation and resynthesis techniques. Thus, eight manipulation conditions reflecting all possible combinations of L1 and L2 intonation, rhythm, and speech rate were created, resulting in 320 utterances that were rated by 50 Dutch natives on their degree of foreign accent and ease of comprehensibility.",20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,364-368,ISCA,en,prosody,Interspeech 2017
2015,"Mády, Katalin","Prosodic (non-)realisation of broad, narrow and contrastive focus in Hungarian: a production and a perception study",Interspeech 2015,,10.21437/Interspeech.2015-18,https://www.isca-speech.org/archive/interspeech_2015/mady15_interspeech.html,"In languages with variable focus positions, prominent elements tend to be emphasised by prosodic cues (e.g. English). If a language prefers a given prosodic pattern, i.e. sentence-ﬁnal nuclear accents, like Spanish, the prosodic realisation of broad focus might not differ from that of narrow and contrastive focus. The relevance of prosodic focus marking was tested in Hungarian were focus typically appears in front of the ﬁnite verb. Prosodic cues such as f0 maximum, f0 peak alignment, segment duration and post-verbal deaccentuation were tested in an experiment with read question and answer sequences. While narrow and contrastive focus triggered post-verbal deaccentuation, none of the gradual measures distinguished focus types consistently from each other. A subsequent perception experiment was conducted in which the same sentences without postverbal units were to be judged for their naturalness. F0 maximum, f0 peak alignment and accent duration were manipulated. Naturalness scores revealed a sequence narrow > contrastive > broad focus, i.e. a preference for narrow focus contexts compared to contrastive and broad focus ones, while the manipulated prosodic parameters had no effect on the scores. It is concluded that prosodic focus marking in Hungarian is optional and pragmatic rather than grammatical and syntax-related.",06/09/2015,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,948-952,ISCA,en,prosody,Interspeech 2015
2017,"Maekawa, Kikuo",A New Model of Final Lowering in Spontaneous Monologue,Interspeech 2017,,10.21437/Interspeech.2017-175,https://www.isca-speech.org/archive/interspeech_2017/maekawa17_interspeech.html,"F0 downtrend observed in spontaneous monologues in the Corpus of Spontaneous Japanese was analyzed with special attention to the modeling of final lowering. In addition to the previous finding that the domain of final lowering covers all tones in the final accentual phrase, it turned out that the last L tone in the penultimate accentual phrase played important role in the control of final lowering. It is this tone that first reached the bottom of the speaker’s pitch range in the time course of utterance; it also turned out that the phonetic realization of this tone is the most stable of all tones in terms of the F0 variability. Regression model of F0 downtrends is generated by generalized linear mixed-effect modeling and evaluated by cross-validation. The mean prediction error of z-normalized F0 values in the best model was 0.25 standard deviation.",20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,1233-1237,ISCA,en,prosody,Interspeech 2017
2007,"Martinović, Miroslav; Vesić, Srdjan; Rakić, Goran",Building an information retrieval system for serbian - challenges and solutions,Interspeech 2007,,10.21437/Interspeech.2007-437,https://www.isca-speech.org/archive/interspeech_2007/martinovic07_interspeech.html,"We describe challenges encountered while building an information retrieval system for Serbian language. Approaches designed and adopted to handle them are depicted and illuminated in this paper. As a backbone of our system, we used SMART retrieval system which we augmented with features necessary to deal with specificities of the Serbian alphabet. In addition, morphological richness of the language accentuated implications of the text preprocessing phase. During this phase, we devised two algorithms which increased retrieval precision by 14% and 27%, respectively. Testing was conducted using two gigabyte EBART collection of Serbian newspaper articles.",27/08/2007,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,1513-1516,ISCA,en,not-accent,Interspeech 2007
2012,"Mehrabani, Mahnoosh; Tepperman, Joseph; Nava, Emily",Nativeness classification with suprasegmental features on the accent group level,Interspeech 2012,,10.21437/Interspeech.2012-553,https://www.isca-speech.org/archive/interspeech_2012/mehrabani12_interspeech.html,"We present a novel approach to discriminating native and nonnative utterances based on suprasegmental features extracted at the Accent Group (AG) level. Past studies have shown modeling a set of shared intonation patterns across AGs to be effective in predicting local f0 contour shapes. Here we demonstrate that AG level prosodic features are also effective in nativeness classiﬁcation. The proposed suprasegmental feature set is very low dimensional, and is derived from f0 and energy contours across the AG, as well as normalized duration of the syllables within each AG. A Random Forest back end classiﬁer is used to combine AG level scores from GMM and Decision Tree models, producing nativeness scores at the utterance level. The proposed prosodic nativeness classiﬁer achieves 83.3% accuracy for 2-AG utterances and 89.1% accuracy for 3-AG utterances, exceeding a baseline Gaussian Supervector system’s performance by more than 10% absolute. The vastly lower dimensionality of the proposed feature set relative to the baseline method suggests the importance of suprasegmental features over traditional spectral cues in contributing to the perceived nativeness of a learner’s language.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,2073-2076,ISCA,en,L2,Interspeech 2012
2019,"Mendes, Carlos; Abad, Alberto; Neto, João Paulo; Trancoso, Isabel",Recognition of Latin American Spanish Using Multi-Task Learning,Interspeech 2019,,10.21437/Interspeech.2019-2772,https://www.isca-speech.org/archive/interspeech_2019/mendes19_interspeech.html,"In the broadcast news domain, national wide newscasters typically interact with communities with a diverse set of accents. One of the challenges in speech recognition is the performance degradation in the presence of these diverse conditions. Performance further aggravates when the accents are from other countries that share the same language. Extensive work has been conducted in this topic for languages such as English and Mandarin. Recently, TDNN based multi-task learning has received some attention in this area, with interesting results, typically using models trained with a variety of different accented corpora from a particular language. In this work, we look at the case of LATAM (Latin American) Spanish for its unique and distinctive accent variations. Because LATAM Spanish has historically been inﬂuenced by non-Spanish European migrations, we anticipated that LATAM based speech recognition performance can be further improved by including these inﬂuential languages, during a TDNN based multi-task training. Experiments show that including such languages in the training setup outperforms the single task acoustic model baseline. We also propose an automatic per-language weight selection strategy to regularize each language contribution during multi-task training.",15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,2135-2139,ISCA,en,L1,Interspeech 2019
2011,"Michelas, Amandine; Nguyen, Noël",Uncovering the effect of imitation on tonal patterns of French accentual phrases,Interspeech 2011,,10.21437/Interspeech.2011-396,https://www.isca-speech.org/archive/interspeech_2011/michelas11_interspeech.html,"French accentual phrases (APs) are characterized by the presence of a typical final fo rise (LH*) and an optional/additional initial fo rise (LHi). This study tested whether between-speaker speech imitation influenced the realization of APs tonal patterns. The experiment was based on APs containing a function word plus a bisyllabic content word, whose tonal patterns differed in the potential placement of an optional/initial high tone (Hi). In two shadowing tasks (without/with explicit instructions to imitate the speaker’s way of pronouncing the stimuli), participants produced more initial high tones when they heard a stimulus including both initial and final high tones relative to stimuli which only a final high tone was present. Thus, imitation influences the realization of APs tonal patterns in French.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,973-976,ISCA,en,prosody,Interspeech 2011
2013,"Michelas, Amandine; Portes, Cristel; Champagne-Lavau, Maud",Intonational contrasts encode speaker's certainty in neutral vs. incredulity declarative questions in French,Interspeech 2013,,10.21437/Interspeech.2013-227,https://www.isca-speech.org/archive/interspeech_2013/michelas13_interspeech.html,"While recent crosslinguistic studies have shown that the degree of speaker’s commitment or certainty is encoded intonationally either in a gradient or categorical fashion, our understanding of how French speakers use Intonational-Phrase (IP) final contours to signal their degree of certainty is limited. This paper investigates the contribution of a penultimate peak contour in French to convey speakers’ uncertainty. Participants read target sentences in a neutral vs. incredulity declarative question context. Prosodic annotation revealed that incredulity declarative questions consistently exhibited the presence of an additional f0 peak in the penultimate syllable of the IP which was unaccented. The acoustic analyses showed that the H tone of the unaccented penultimate peak was not downstepped and thus approximately scaled to the same height of the last pitch accent. The findings of this study provide the first quantitative description of a phonological contrast between H*H% and H+ H*H% to signal speakers’ certainty in declarative questions in French.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,783-787,ISCA,en,prosody,Interspeech 2013
2020,"Michelas, Amandine; Dufour, Sophie",Does French Listeners’ Ability to Use Accentual Information at the Word Level Depend on the Ear of Presentation?,Interspeech 2020,,10.21437/Interspeech.2020-1263,https://www.isca-speech.org/archive/interspeech_2020/michelas20_interspeech.html,"In two long-term repetition priming experiments, we investigated how accentual information is processed and represented in the French listeners’ mind. Repeated prime and target words either matched (/b 'do/ - / b 'do/ ‘headband’) or mismatched in their accentual patterns (/b do/ - /b 'do/). In experiment 1, the target words were presented in the left ear only, and attenuation in the repetition priming effect was observed when the primes and the targets mismatched in their accentual pattern. The differential priming effect between match and mismatch primes was no longer observed in Experiment 2 when the targets were presented in the right ear only. Together, these results showed that accentual variation at the word level in French is treated as related-talker variation, and only influences word recognition under specific circumstances, in particular, when we push word processing in the right hemisphere.",25/10/2020,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,1615-1619,ISCA,en,prosody,Interspeech 2020
2011,"Minematsu, Nobuaki; Okabe, Koji; Ogaki, Keisuke; Hirose, Keikichi",Measurement of objective intelligibility of Japanese accented English using ERJ (English read by Japanese) database,Interspeech 2011,,10.21437/Interspeech.2011-310,https://www.isca-speech.org/archive/interspeech_2011/minematsu11_interspeech.html,"In many schools, English is taught as international communication tool and the goal of English pronunciation training is generally to acquire intelligible enough pronunciation, which is not always native-sounding pronunciation. However, the deﬁnition of the intelligible pronunciation is not easy because it depends on the speaking skill of a speaker, the predictability of a content, and the language background of a listener. One kind of accented pronunciation, which is intelligible enough for some listeners, is often less intelligible for others. This paper focuses on objective intelligibility of Japanese English through the ears of American English speakers with little exposure to Japanese English. A large listening test was conducted using ERJ (English Read by Japanese) database. A balanced subset of this database were presented over a telephone line to the American listeners who were asked to repeat what they heard. Totally, 17,416 repetitive responses were collected and they were transcribed manually. This paper describes the design of this experiment and some results of analyzing the results of transcription.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,1481-1484,ISCA,en,L2,Interspeech 2011
2012,"Minematsu, Nobuaki; Kobayashi, Shumpei; Shimizu, Shinya; Hirose, Keikichi",Improved prediction of Japanese word accent sandhi using CRF,Interspeech 2012,,10.21437/Interspeech.2012-663,https://www.isca-speech.org/archive/interspeech_2012/minematsu12_interspeech.html,"In Japanese, every content word has its own mora-based H/L pitch pattern when it is uttered in isolation, called accent type. When reading out a written sentence, however, this lexical H/L pattern is often changed according to the context, known as word accent sandhi. In our previous work, an accent sandhi predictor was developed using CRF [1], and in this paper, the predictor is improved through feature engineering especially focusing on phrases including numerals and those including loanwords. This is because our previous work showed that the prediction performance was relatively low for those phrases. To optimize the features used for CRF, it is critical to take into account the mechanism of word accent sandhi. We review linguistic and technical literature that attempted to characterize accent sandhi in the phrases including numerals and loanwords and, by reﬂecting these characteristics, the features are re-designed. Experiments show that the proposed predictor improved the performance relatively by 37% and 41%, respectively.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,2562-2565,ISCA,en,prosody,Interspeech 2012
2009,"Mixdorff, Hansjörg; Pfitzinger, Hartmut R.",A quantitative study of F0 peak alignment and sentence modality,Interspeech 2009,,10.21437/Interspeech.2009-297,https://www.isca-speech.org/archive/interspeech_2009/mixdorff09_interspeech.html,"The current study examines the relationship between prosodic accent labels assigned in the Kiel Corpus of Spontaneous Speech IV, Isačenko’s intoneme classes of the underlying accents and the associated parameters of the Fujisaki model. Among other findings, there is a close connection between early peaks and information intonemes, as well as late peaks and non-terminal intonemes. The majority of tokens within both intoneme classes, however, are associated with medial peaks. Precise analysis of alignment shows that accent command offset times for information intonemes are significantly earlier than for non-terminal intonemes. This suggests that the anchoring of the relevant tonal transition could be more important for separating different intonational categories than that of the F0 peak.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,1003-1006,ISCA,en,prosody,Interspeech 2009
2009,"Mixdorff, Hansjörg; Ingram, John",Prosodic analysis of foreign-accented English,Interspeech 2009,,10.21437/Interspeech.2009-666,https://www.isca-speech.org/archive/interspeech_2009/mixdorff09b_interspeech.html,"This study compares utterances by Vietnamese learners of Australian English with those of native subjects. In a previous study the utterances had been rated for foreign accent and intelligibility. We aim to find measurable prosodic differences accounting for the perceptual results. Our outcomes indicate, inter alia, that unaccented syllables are relatively longer compared with accented ones in the Vietnamese corpus than those in the Australian English corpus. Furthermore, the correlations of syllabic durations in utterances of one and the same sentence are much higher for Australian English subjects than for Vietnamese learners of English. Vietnamese speakers use a larger range of f0 and produce more pitch-accents than Australian speakers.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,2527-2530,ISCA,en,L2,Interspeech 2009
2013,"Mixdorff, Hansjörg; Niebuhr, Oliver",The influence of F0 contour continuity on prominence perception,Interspeech 2013,,10.21437/Interspeech.2013-73,https://www.isca-speech.org/archive/interspeech_2013/mixdorff13_interspeech.html,"The presented study concerns the influence of the syllabic structure on perceived prominence. We examined how gaps in the F0 contour due to unvoiced consonants affect prominence perception, given that such gaps can either be filled or blinded out by listeners. For this purpose we created a stimulus set of real disyllabic words which differed in the quantity of the vowel of the accented syllable nucleus and the types of subsequent intervocalic consonant(s). Results include, inter alia, that stimuli with unvoiced gaps in the F0 contour are indeed perceived as less prominent. The prominence reduction is smaller for monotonous stimuli than for stimuli with F0 excursions across the accented syllable. Moreover, in combination with F0 excursions, it also mattered whether F0 had to be interpolated or extrapolated, and whether or not the gap included a fricative sound. The results support both the filling-in and blinding-out of F0 gaps, which fits in well with earlier experiments on the production and perception of pitch.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,230-234,ISCA,en,prosody,Interspeech 2013
2015,"Montacié, Claude; Caraty, Marie-José",Phrase accentuation verification and phonetic variation measurement for the degree of nativeness sub-challenge,Interspeech 2015,,10.21437/Interspeech.2015-180,https://www.isca-speech.org/archive/interspeech_2015/montacie15_interspeech.html,"The Degree of Nativeness Sub-Challenge consists in the automatic grading of the pronunciation quality of non-native English utterances. In this paper, we investigate the phrase accentuation and the phonetic acoustic variability for the prediction of the grades. Two prediction systems have been developed: the Extended Baseline System (EBS) and the Pronunciation Feature based System (PFS). The EBS system was designed to take into account the cross-corpus specificities such as recording conditions and the sentence variability. The speech files were segmented using Automatic Speech Recognition methods (ASR). Audio features were selected on both the training and development sets using the Regressional ReliefF method. New audio features were developed for the PFS system to take into account the mispronunciations: unusual prosody and/or phonetic variation. These systems have been assessed using the Spearman’s correlation coefficient with expert annotations. The PFS system has significantly improved of 0.05 the Official Baseline performance.",06/09/2015,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,483-487,ISCA,en,prosody,Interspeech 2015
2005,"Mori, Laura; Barkat-Defradas, Melissa",Acoustic properties of foreign accent: VOT variations in Moroccan-accented Italian,Interspeech 2005,,10.21437/Interspeech.2005-768,https://www.isca-speech.org/archive/interspeech_2005/mori05b_interspeech.html,"The present study investigates the temporal parameter of VOT from a cross-language perspective, as far as native Moroccan, native Italian and Moroccanaccented Italian are concerned. The comparative analysis carried out underlines a language effect on the VOT duration across the three language varieties.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,2909-2912,ISCA,en,L2,Interspeech 2005
2014,"Motlicek, Petr; Imseng, David; Cernak, Milos; Kim, Namhoon",Development of bilingual ASR system for MediaParl corpus,Interspeech 2014,,10.21437/Interspeech.2014-342,https://www.isca-speech.org/archive/interspeech_2014/motlicek14_interspeech.html,"The development of an Automatic Speech Recognition (ASR) system for the bilingual MediaParl corpus is challenging for several reasons: (1) reverberant recordings, (2) accented speech, and (3) no prior information about the language. In that context, we employ frequency domain linear prediction-based (FDLP) features to reduce the effect of reverberation, exploit bilingual deep neural networks applied in Tandem and hybrid acoustic modeling approaches to signiﬁcantly improve ASR for accented speech and develop a fully bilingual ASR system using entropy-based decoding-graph selection. Our experiments indicate that the proposed bilingual ASR system performs similar to a language-speciﬁc ASR system if approximately ﬁve seconds of speech are available.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,1391-1394,ISCA,en,L2,Interspeech 2014
2019,"Mücke, Doris; Hermes, Anne; Tilsen, Sam",Strength and Structure: Coupling Tones with Oral Constriction Gestures,Interspeech 2019,,10.21437/Interspeech.2019-2650,https://www.isca-speech.org/archive/interspeech_2019/mucke19_interspeech.html,"According to the segmental anchor hypothesis within the Autosegmental-Metrical approach, tones are aligned with segmental boundaries of consonant and vowels in the acoustic domain. In prenuclear rising pitch accents (LH*), the rise is assumed to occur in the vicinity of the accented syllable it is phonologically associated with. However, there are differences in the alignment patterns within and across languages that cannot be captured within the AM approach. In the present study, we investigate the coordination of tonal and oral constriction gestures within Articulatory Phonology. Therefore, we model the coordination of prenuclear LH* pitch accents in Catalan, Northern and Southern German with respect to syllable production on the basis of recordings with a 2D electromagnetic articulography. We provide an extended coupled oscillators model that allows for balanced and imbalanced coupling strengths. Based on examples, we show that the observed differences in alignment patterns for prenuclear rising pitch accents can be modelled with the same underlying coordinative structures/coupling modes for vocalic and tonal gestures and that surface differences arise from gradient variation in coupling strengths.",15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,914-918,ISCA,en,prosody,Interspeech 2019
2018,"Müller, Markus; Stüker, Sebastian; Waibel, Alex",Neural Language Codes for Multilingual Acoustic Models,Interspeech 2018,,10.21437/Interspeech.2018-1241,https://www.isca-speech.org/archive/interspeech_2018/muller18_interspeech.html,"Multilingual Speech Recognition is one of the most costly AI problems, because each language (7,000+) and even different accents require their own acoustic models to obtain best recognition performance. Even though they all use the same phoneme symbols, each language and accent imposes its own coloring or “twang”. Many adaptive approaches have been proposed, but they require further training, additional data and generally are inferior to monolingually trained models. In this paper, we propose a different approach that uses a large multilingual model that is modulated by the codes generated by an ancillary network that learns to code useful differences between the “twangs” or human language.",02/09/2018,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,2419-2423,ISCA,en,L1-or-L2,Interspeech 2018
2021,"Mumtaz, Benazir; Canzi, Massimiliano; Butt, Miriam",Prosody of Case Markers in Urdu,Interspeech 2021,,10.21437/Interspeech.2021-1776,https://www.isca-speech.org/archive/interspeech_2021/mumtaz21_interspeech.html,"This paper studies the prosody of case clitics in Urdu, for which various different claims exist in the literature. We conducted a production experiment and controlled for effects potentially arising from the phonetics of the case clitics, the syntactic function they express and clausal position. We ﬁnd that case clitics are incorporated into the prosodic phrase of the noun and that they become part of the overall LH contour found on accentual phrases in Urdu/Hindi. We also ﬁnd some differences across case type and position which we tie to information structural effects.",30/08/2021,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,2661-2665,ISCA,en,prosody,Interspeech 2021
2018,"Murphy, Andy; Yanushevskaya, Irena; Ní Chasaide, Ailbhe; Gobl, Christer",Voice Source Contribution to Prominence Perception: Rd Implementation,Interspeech 2018,,10.21437/Interspeech.2018-2352,https://www.isca-speech.org/archive/interspeech_2018/murphy18_interspeech.html,"This paper explores the contribution of voice source modulation to the perception of prominence, following on previous analyses of accentuation, focus and deaccentuation. A listening test was carried out on a sentence of Irish with three accented, prominent syllables (P1, P2, P3). Using inverse filtering and resynthesis, a ‘flattened’ version was generated, with only slight declination of f0 and other voice source parameters. The global waveshape parameter Rd was modulated to provide (i) source boosting (tenser phonation) on either P1 or P2, and/or (ii) source attenuation (laxer phonation) following (Post-attenuation) or preceding (Pre-attenuation) P1 or P2. Rd variation was achieved in two different ways to generate two series of stimuli. f0 was not varied in either series. Twenty-nine listeners rated the prominence level of all syllables in the utterance. Results show that the phrasal position (P1 vs. P2) makes a large difference to prominence judgements. P1 emerged as overall more prominent and more readily ‘enhanced’ by the source modifications. Post-attenuation was particularly important for P1, with effects equal to or greater than local P-boosting. In the case of P2, Pre-attenuation was much more important than Postattenuation.",02/09/2018,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,217-221,ISCA,en,prosody,Interspeech 2018
2005,"Nagano, Tohru; Mori, Shinsuke; Nishimura, Masafumi",A stochastic approach to phoneme and accent estimation,Interspeech 2005,,10.21437/Interspeech.2005-575,https://www.isca-speech.org/archive/interspeech_2005/nagano05_interspeech.html,"We present a new stochastic approach to estimate accurately phonemes and accents for Japanese TTS (Text-to-Speech) systems. Front-end process of TTS system assigns phonemes and accents to an input plain text, which is critical for creating intelligible and natural speech. Rule-based approaches that build hierarchical structures are widely used for this purpose. However, considering scalability and the ease of domain adaptation, rule-based approaches have well-known limitations. In this paper, we present a stochastic method based on an n-gram model for phonemes and accents estimation. The proposed method estimates not only phonemes and accents but word segmentation and part-of-speech (POS) simultaneously. We implemented a system for Japanese which solves tokenization, linguistic annotation, text-to-phonemes conversion, homograph disambiguation, and accents generation at the same time, and observed promising results.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:20,3293-3296,ISCA,en,prosody,Interspeech 2005
2014,"Najafian, Maryam; DeMarco, Andrea; Cox, Stephen; Russell, Martin",Unsupervised model selection for recognition of regional accented speech,Interspeech 2014,,10.21437/Interspeech.2014-495,https://www.isca-speech.org/archive/interspeech_2014/najafian14_interspeech.html,"This paper is concerned with automatic speech recognition (ASR) for accented speech. Given a small amount of speech from a new speaker, is it better to apply speaker adaptation to the baseline, or to use accent identiﬁcation (AID) to identify the speaker’s accent and select an accent-dependent acoustic model? Three accent-based model selection methods are investigated: using the ‘true’ accent model, and unsupervised model selection using i-Vector and phonotactic-based AID. All three methods outperform the unadapted baseline. Most signiﬁcantly, AID-based model selection using 43s of speech performs better than unsupervised speaker adaptation, even if the latter uses ﬁve times more adaptation data. Combining unsupervised AIDbased model selection and speaker adaptation gives an average relative reduction in ASR error rate of up to 47%.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,2967-2971,ISCA,en,L1,Interspeech 2014
2013,"Nakamura, Ibuki; Minematsu, Nobuaki; Suzuki, Masayuki; Hirano, Hiroko; Nakagawa, Chieko; Nakamura, Noriko; Tagawa, Yukinori; Hirose, Keikichi; Hashimoto, Hiroya",Development of a web framework for teaching and learning Japanese prosody: OJAD (online Japanese accent dictionary),Interspeech 2013,,10.21437/Interspeech.2013-575,https://www.isca-speech.org/archive/interspeech_2013/nakamura13_interspeech.html,"This paper introduces the ﬁrst online and free framework for teaching and learning Japanese prosody including word accent and phrase intonation. This framework is called OJAD (Online Japanese Accent Dictionary) [1] and it provides three functions. 1) Visual, auditory, systematic, and comprehensive illustration of patterns of accent change (accent sandhi) of verbs and adjectives. Here only the changes caused by twelve kinds of fundamental conjugation are focused upon. 2) Visual illustration of the accent pattern of a given verbal expression, which is a combination of a verb and its postpositional auxiliary words. 3) Visual illustration of the pitch pattern of an any given sentence and the expected positions of accent nuclei in the sentence. The third function is implemented by using an accent change prediction module that we developed for Japanese text-to-speech (TTS) synthesizers [2, 3]. Experiments show that accent nucleus assignment to given texts by the proposed framework is much more accurate than that by native speakers. Subjective assessment and objective assessment by teachers and learners show very high pedagogical effectiveness of the framework.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,2554-2558,ISCA,en,prosody,Interspeech 2013
2012,"Nallasamy, Udhyakumar; Metze, Florian; Schultz, Tanja",Enhanced polyphone decision tree adaptation for accented speech recognition,Interspeech 2012,,10.21437/Interspeech.2012-516,https://www.isca-speech.org/archive/interspeech_2012/nallasamy12_interspeech.html,"State-of-the-art Automatic Speech Recognition (ASR) systems struggle to handle accented speech, particularly if the target accent is under-represented in the training data. The acoustic variations presented by an unfamiliar accent render the ASR polyphone decision tree (PDT) and its associated Gaussian mixture models (GMM) misﬁt to the test data. In this paper, we improve on the previous work of adapting the polyphone decision tree, using a semi-continuous model based approach to address the problem of data sparsity. We extend the existing PDT to introduce additional states with shared parameters, corresponding to the new contextual variations identiﬁed in the adaptation data, while still robustly estimating the state-speciﬁc parameters on a relatively small dataset. We conduct ASR experiments on Arabic and English accents and show that our technique performs better than Maximum A-Posteriori (MAP) adaptation and a previous implementation of polyphone decision tree specialization (PDTS). Compared to MAP adapted system, we obtain 7% relative improvement in Word Error Rate (WER) for Arabic and 13.7% relative improvement for English accent adaptation.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,1902-1905,ISCA,en,L1,Interspeech 2012
2012,"Nariai, Tomoko; Tanaka, Kazuyo; Kawahara, Tatsuya",Comparative analysis of intensity between native speakers and Japanese speakers of English,Interspeech 2012,,10.21437/Interspeech.2012-270,https://www.isca-speech.org/archive/interspeech_2012/nariai12_interspeech.html,"Intensity has been reported as a reliable acoustical correlate of stress accent for English language, but not of pitch accent for Japanese language. This difference between English and Japanese languages is presumed to shape the characteristics of intensity in English spoken by Japanese (Japanese English, henceforth). Based on this presumption, the intensity of words in sentence utterances for Japanese English is compared to that for native speakers’ English (native English, henceforth). Statistical analysis shows that nouns for Japanese English are produced with less intensity, whereas most function words are with more intensity than those for native English. A correlation is recognized between the above results and the proﬁciency in Japanese English.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,895-898,ISCA,en,prosody,Interspeech 2012
2022,"Nguyen, Tuan Nam; Pham, Ngoc-Quan; Waibel, Alexander",Accent Conversion using Pre-trained Model and Synthesized Data from Voice Conversion,Interspeech 2022,,10.21437/Interspeech.2022-10729,https://www.isca-speech.org/archive/interspeech_2022/nguyen22d_interspeech.html,"Accent conversion (AC) aims to generate synthetic audios by changing the pronunciation pattern and prosody of source speakers (in source audios) while preserving voice quality and linguistic content. There has not been a parallel corpus that contains pairs of audios having the same contents yet coming from the same speakers in different accents, the authors hence work on a solution to synthesize one as training input. The training pipeline is conducted via two steps. First, a voice conversion (VC) model is constructed to synthesize a training data set, containing pairs of audios in the same voice but two different accents. Second, an AC model is trained with the synthesized data to convert a source accented speech to a target accented speech. Given the recognized success of self-supervised learning speech representation (wav2vec 2.0) on certain speech problems such as VC, speech recognition, speech translation, and speech-tospeech translation, we adopt this architecture with some customization to train the AC model in the second step. With just 9-hour synthesized training data, the encoder initialized by the weight of the pre-trained wav2vec 2.0 model outperforms the LSTM-based encoder.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,2583-2587,ISCA,en,L1-or-L2,Interspeech 2022
2007,"Ni, Xinqiang; Chen, Yining; Soong, Frank K.; Chu, Min; Zhang, Ping",An unsupervised approach to automatic prosodic annotation,Interspeech 2007,,10.21437/Interspeech.2007-225,https://www.isca-speech.org/archive/interspeech_2007/ni07_interspeech.html,"Accent is probably the most prominent part in prosodic events. Automatic accent labeling is important for both speech synthesis and automatic speech understanding. However, manually labeling data for traditional supervised learning is expensive and time consuming. In this paper, we propose an unsupervised learning algorithm to label accent automatically. First, we assume all content words are accented. We build an initial acoustic model with accented vowels in content words and high confidence unaccented vowels in function words. Then an iterative progress is executed to convergence. Experimental results show that this unsupervised learning algorithm achieves about 90% agreement on accent labeling. Compared with 84.3%, the accuracy of a typical linguistic classifier, a 30% relative error reduction is obtained.",27/08/2007,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,486-489,ISCA,en,prosody,Interspeech 2007
2011,"Ni, Chong-Jia; Liu, Wenju; Xu, Bo","Automatic prosodic events detection by using syllable-based acoustic, lexical and syntactic features",Interspeech 2011,,10.21437/Interspeech.2011-530,https://www.isca-speech.org/archive/interspeech_2011/ni11_interspeech.html,"Automatic prosodic events detection and annotation are important for both speech understanding and natural speech synthesis. In this paper, the complementary model method is proposed to detect prosodic events. This method discards the independent assumption between the acoustic features and the lexical and syntactic features, models not only the features of the current syllable but also the contextual features of the current syllable at the model level, and realizes the complementarities by taking the advantages of each model. The experiments on Boston University Radio News Corpus show that the complementary model can yield 91.40% pitch accent detection accuracy rate, 95.19% intonational phrase boundaries (IPB) detection accuracy rate and 93.96% break index detection accuracy rate. When compared with the previous work, the results for pitch accent, IPB and break index detection are significantly better.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,2017-2020,ISCA,en,prosody,Interspeech 2011
2013,"Ni, Jinfu; Shiga, Yoshinori; Hori, Chiori; Kidawara, Yutaka",A targets-based superpositional model of fundamental frequency contours applied to HMM-based speech synthesis,Interspeech 2013,,10.21437/Interspeech.2013-117,https://www.isca-speech.org/archive/interspeech_2013/ni13_interspeech.html,,25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,1052-1056,ISCA,en,prosody,Interspeech 2013
2013,"Ní Chasaide, Ailbhe; Yanushevskaya, Irena; Kane, John; Gobl, Christer",The voice prominence hypothesis: the interplay of F0 and voice source features in accentuation,Interspeech 2013,,10.21437/Interspeech.2013-759,https://www.isca-speech.org/archive/interspeech_2013/nichasaide13_interspeech.html,"This paper explores the interplay of source correlates of accentuation, examining a hypothesis (the Voice Prominence Hypothesis) that different source parameters are involved and may serve as equivalent. It predicts that where accentuation is not marked by pitch salience there will be more extensive changes in other source parameters. This follows our assumption that prosodic entities such as accentuation, focus, declination, etc. involve adjustments to the entire voice source and not simply to F0. Twelve 3-accent sentences of Connemara Irish (declaratives, WH questions and Yes/No questions) were analysed. These are typically produced and transcribed as H* H* H*L. Of particular interest were the second accents: although they are heard as accented, there are no particular pitch excursions that would account for their salience. Inverse filtering and subsequent source parameterisation was carried out to yield measures for a range of source parameters. Results support the voice prominence hypothesis: as predicted, the most striking source adjustments were found in the second accent. Even where there is substantial pitch movement (final accent), parameters other than F0 appear to be contributing to the salience of the accented syllable. The precise source changes associated with accentuation varied across sentence types and within the prosodic phrase.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,3527-3531,ISCA,en,prosody,Interspeech 2013
2004,"Oh, Mira; Kim, Kee-Ho",Phonetic realization of the suffix-suppressed accentual phrase in Korean,Interspeech 2004,,10.21437/Interspeech.2004-80,https://www.isca-speech.org/archive/interspeech_2004/oh04_interspeech.html,"Suffixes can surface or can be suppressed depending on context in Korean. Shin (1982) argues that the case markermarked phrases deliver new information, while the case marker-suppressed phrases given information. The tonal pattern of the Accentual Phrase in Korean, LHLH, is not specific to morphological constituents within the phrase but is a property of the phrase (Jun 1993). Given that prosody often distinguishes pragmatic meanings, this study aims to find the phonetic characteristics of the suffix-suppressed Accentual Phrase through a phonetic experiment. The results indicate that the case marker-marked and -suppressed phrases are realized differently with respect to the degree of AP-final rising and AP-final tone realization. Different phonetic realizations reflect that the suffix-suppressed AP functions differently from the suffix-marked AP in discourse.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,1309-1312,ISCA,en,prosody,Interspeech 2004
2022,"Oh, Miran; Lee, Yoonjeong",Dynamic Vertical Larynx Actions Under Prosodic Focus,Interspeech 2022,,10.21437/Interspeech.2022-10661,https://www.isca-speech.org/archive/interspeech_2022/oh22_interspeech.html,"It is well known that there is a positive correlation between fundamental frequency and vertical larynx position. Recently, Lee (2018) observes that one vertical larynx movement (VLM) is associated with an Accentual Phrase (AP) in Seoul Korean. The current study builds on these findings by investigating the effect of prosodic focus on vertical larynx actions. Target sentences were designed to produce four APs (e.g., Joohyun sold six yards of shabby garden field; AP[Joohyun-SUBJ] AP[shabby garden field] AP[six yards-OBJ] AP[sold-DECL], presented in Korean) and were used to elicit focus on the initial word of the object phrase (e.g., six). Articulatory data on VLM is obtained from five Seoul Korean speakers using real-time MRI. Results indicate that quantifiable VLMs observed for each sentence range from 3 to 6 movements, with 4 movements per sentence being the most frequent. Sentences with focus have more instances of VLM per sentence than those without. Focused sentences exhibit significantly greater vertical larynx displacement around the region of focus than the control. Our findings have implications for prosodic planning and pitch resetting, and ongoing analyses examine how VLMs align with Accentual Phrases in Seoul Korean and correlate with fundamental frequency.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,96-100,ISCA,en,prosody,Interspeech 2022
2005,"Oliver, Dominika; Clark, Robert A. J.",Modelling pitch accent types for Polish speech synthesis,Interspeech 2005,,10.21437/Interspeech.2005-613,https://www.isca-speech.org/archive/interspeech_2005/oliver05_interspeech.html,"We describe a Polish prosody modelling module for the Festival speech synthesis system. The module uses classiﬁcation and regression trees for accent type prediction and a linear regression technique for F0 contour generation for these contours. The techniques used to attempt to overcome problems with the only available data are shown. We demonstrate how improvements were achieved by the use of a modiﬁed F0 stylisation, accent type clustering and language speciﬁc features. Results of a formal perception study show a signiﬁcant preference for the new intonation model over the original one.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,1965-1968,ISCA,en,prosody,Interspeech 2005
2011,"Orr, Rosemary; Quené, Hugo; Beek, Roeland van; Diefenbach, Thari; Leeuwen, David A. van; Huijbregts, Marijn",An international English speech corpus for longitudinal study of accent development,Interspeech 2011,,10.21437/Interspeech.2011-513,https://www.isca-speech.org/archive/interspeech_2011/orr11_interspeech.html,"If English is used intensively as a lingua franca in a multilanguage community, do speakers then converge towards a single common accent? This speech corpus allows for longitudinal study to investigate the question of convergence by means of repeated speech recordings of students at an English-language college over a period of 5 years. We describe the content and collection of the corpus and the type of research that is envisaged, as well as tools used to manage and analyze the recordings, including automatic phone recognition for prosodic analyses; and intelligibility experiments using the SRT method.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,1889-1892,ISCA,en,L2,Interspeech 2011
2008,"Otake, Takashi; Higuchi, Marii",The role of Japanese pitch accent in spoken-word recognition: evidence from middle-aged accentless dialect listeners,Interspeech 2008,,10.21437/Interspeech.2008-337,https://www.isca-speech.org/archive/interspeech_2008/otake08_interspeech.html,"This paper investigates the role of pitch accent information in spoken-word recognition in listeners in Fukushima, Japan, whose dialect is accentless. Previous research revealed that accentless listeners were less sensitive to pitch accent than Tokyo Japanese listeners. The present study asked whether middle-aged listeners’ use of accent information would differ from that of young listeners. 40 middle-aged Fukushima listeners were presented with Tokyo Japanese materials used in the earlier study, employing a gating task. Results show that middle-aged Fukushima accentless listeners are even less sensitive to the pitch accent information than the younger accentless listeners. The findings suggest that the exploitation of pitch information by younger listeners reflects adaptation to the standard Tokyo Japanese dialect, e.g., via the media, whereas the older listeners are less influenced by the standard.",22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,1097-1100,ISCA,en,prosody,Interspeech 2008
2022,"Park, Byeongseon; Yamamoto, Ryuichi; Tachibana, Kentaro",A Unified Accent Estimation Method Based on Multi-Task Learning for Japanese Text-to-Speech,Interspeech 2022,,10.21437/Interspeech.2022-334,https://www.isca-speech.org/archive/interspeech_2022/park22b_interspeech.html,"We propose a unified accent estimation method for Japanese text-to-speech (TTS). Unlike the conventional two-stage methods, which separately train two models for predicting accent phrase boundaries and accent nucleus positions, our method merges the two models and jointly optimizes the entire model in a multi-task learning framework. Furthermore, considering the hierarchical linguistic structure of intonation phrases (IPs), accent phrases, and accent nuclei, we generalize the proposed approach to simultaneously model the IP boundaries with accent information. Objective evaluation results reveal that the proposed method achieves an accent estimation accuracy of 80.4%, which is 6.67% higher than the conventional two-stage method. When the proposed method is incorporated into a neural TTS framework, the system achieves a 4.29 mean opinion score with respect to prosody naturalness.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,1931-1935,ISCA,en,L1-or-L2,Interspeech 2022
2009,"Patil, Vaishali; Joshi, Shrikant; Rao, Preeti",Improving the robustness of phonetic segmentation to accent and style variation with a two-staged approach,Interspeech 2009,,10.21437/Interspeech.2009-670,https://www.isca-speech.org/archive/interspeech_2009/patil09_interspeech.html,Correct and temporally accurate phonetic segmentation of speech utterances is important in applications ranging from transcription alignment to pronunciation error detection. Automatic speech recognizers used in these tasks provide insufficient temporal alignment accuracy apart from a recognition performance that is sensitive to accent and style variations from the training data. A two-staged approach combining HMM broad-class recognition with acousticphonetic knowledge based refinement is evaluated for phonetic segmentation accuracy in the context of accent and style mismatches with training data.,06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,2543-2546,ISCA,en,L1-or-L2,Interspeech 2009
2019,"Pellegrini, Thomas; Farinas, Jérôme; Delpech, Estelle; Lancelot, François",The Airbus Air Traffic Control Speech Recognition 2018 Challenge: Towards ATC Automatic Transcription and Call Sign Detection,Interspeech 2019,,10.21437/Interspeech.2019-1962,https://www.isca-speech.org/archive/interspeech_2019/pellegrini19_interspeech.html,"In this paper, we describe the outcomes of the challenge organized and run by Airbus and partners in 2018 on Air Trafﬁc Control (ATC) speech recognition. The challenge consisted of two tasks applied to English ATC speech: 1) automatic speechto-text transcription, 2) call sign detection (CSD). The registered participants were provided with 40 hours of speech along with manual transcriptions. Twenty-two teams submitted predictions on a ﬁve hour evaluation set. ATC speech processing is challenging for several reasons: high speech rate, foreignaccented speech with a great diversity of accents, noisy communication channels. The best ranked team achieved a 7.62% Word Error Rate and a 82.41% CSD F1-score. Transcribing pilots’ speech was found to be twice as harder as controllers’ speech. Remaining issues towards solving ATC ASR are also discussed in the paper.",15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,2993-2997,ISCA,en,L1-or-L2,Interspeech 2019
2020,"Pérez-Ramón, Rubén; Lecumberri, María Luisa García; Cooke, Martin",The Effect of Language Proficiency on the Perception of Segmental Foreign Accent,Interspeech 2020,,10.21437/Interspeech.2020-1023,https://www.isca-speech.org/archive/interspeech_2020/perezramon20_interspeech.html,"Foreign accent has different effects on speech intelligibility for native and non-native listeners. However, not much is known about the impact of individual foreign-accented segments on listeners with different levels of proﬁciency in the language. Using a technique developed to generate degrees of segmental foreign accent, this study investigates how native and non-native listeners differing in language proﬁciency categorise and discriminate degrees of accentedness at the segmental level. Listeners responded to continua ranging from Spanish-accented tokens to English tokens, constructed by inserting accented segments into words. Six continua were chosen, based on known problems faced by Spanish speakers of English. Whether foreign accent categorisation performance differed across native and nonnative listeners was found to depend on the status of the segment in the listeners’ ﬁrst language. For certain sounds both high and low proﬁciency non-native groups resembled native listener responses. For other sounds, categorisation revealed a clear effect of proﬁciency, with the high-proﬁciency group closer to native performance than the low proﬁciency cohort. This behaviour indicates an ongoing process of new second language phonemic category creation by the more proﬁcient learners.",25/10/2020,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,2362-2366,ISCA,en,prosody,Interspeech 2020
2022,"Pérez Ramón, Rubén; Cooke, Martin; Garcia Lecumberri, Maria Luisa",Generating iso-accented stimuli for second language research: methodology and a dataset for Spanish-accented English,Interspeech 2022,,10.21437/Interspeech.2022-850,https://www.isca-speech.org/archive/interspeech_2022/perezramon22_interspeech.html,"A non-native accent can be conveyed at both the segmental and suprasegmental level. Previous studies have developed techniques to isolate the effect of segmental foreign accent by splicing accented segments from a bilingual speaker into nonaccented words produced by the same speaker. The current work addresses the issue of between-segment variability by developing a technique to convert from acoustically-equal accent gradations to perceptually-equal steps. The procedure is used to derive the ﬁrst corpus of Spanish-accented English composed of lexical tokens each generated with one of ﬁve degrees of nonnative accent. As an example application, corpus tokens are used to elicit accentedness judgements from four listener cohorts with ﬁrst languages which differ as to whether they share the native language, the non-native (accented) language of the corpus or have a closer phonological inventory to one or the other. Findings highlight the importance of the relationship between listeners’ phonological systems and those of the native and non-native languages of the corpus, especially for vowels, with respect to sensitivity to foreign accent.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,1846-1850,ISCA,en,L1-or-L2,Interspeech 2022
2008,"Piat, Marina; Fohr, Dominique; Illina, Irina",Foreign accent identification based on prosodic parameters,Interspeech 2008,,10.21437/Interspeech.2008-235,https://www.isca-speech.org/archive/interspeech_2008/piat08_interspeech.html,"In this paper we propose an automatic approach for foreign accent identiﬁcation. Knowledge of the speaker’s origin allows to adapt acoustic models for non-native speech recognition. In this study, we use a statistical approach based on prosodic parameters. This approach relies on the fact that prosody is different between languages, and has been done within the framework of the HIWIRE (Human Input that Works In Real Environments) European project. The corpus is composed of English sentences pronounced by French, Italian, Greek and Spanish speakers. Results obtained with duration and energy are promising for foreign accent identiﬁcation: 67.1% correct L1 identiﬁcation with duration and 68.6% with energy. These two parameters combined with MFCC achieve a 87.1% correct foreign accent identiﬁcation rate.",22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,759-762,ISCA,en,L2,Interspeech 2008
2005,"Psutka, Josef; Ircing, Pavel; Psutka, J. V.; Hajic, Jan; Byrne, William J.; Mírovský, Jirí","Automatic transcription of Czech, Russian, and Slovak spontaneous speech in the MALACH project",Interspeech 2005,,10.21437/Interspeech.2005-489,https://www.isca-speech.org/archive/interspeech_2005/psutka05_interspeech.html,"This paper describes the 3.5-years effort put into building LVCSR systems for recognition of spontaneous speech of Czech, Russian, and Slovak witnesses of the Holocaust in the MALACH project. For processing of colloquial, highly emotional and heavily accented speech of elderly people containing many non-speech events we have developed techniques that very effectively handle both non-speech events and colloquial and accented variants of uttered words. Manual transcripts as one of the main sources for language modeling were automatically „normalized” using standardized lexicon, which brought about 2 to 3% reduction of the word error rate (WER). The subsequent interpolation of such LMs with models built from an additional collection (consisting of topically selected sentences from general text corpora) resulted into an additional improvement of performance of up to 3 % .",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,1349-1352,ISCA,en,L1; def,Interspeech 2005
2022,"Quamer, Waris; Das, Anurag; Levis, John; Chukharev-Hudilainen, Evgeny; Gutierrez-Osuna, Ricardo",Zero-Shot Foreign Accent Conversion without a Native Reference,Interspeech 2022,,10.21437/Interspeech.2022-10664,https://www.isca-speech.org/archive/interspeech_2022/quamer22_interspeech.html,"Previous approaches for foreign accent conversion (FAC) either need a reference utterance from a native speaker (L1) during synthesis, or are dedicated one-to-one systems that must be trained separately for each non-native (L2) speaker. To address both issues, we propose a new FAC system that can transform L2 speech directly from previously unseen speakers. The system consists of two independent modules: a translator and a synthesizer, which operate on bottleneck features derived from phonetic posteriorgrams. The translator is trained to map bottleneck features in L2 utterances into those from a parallel L1 utterance. The synthesizer is a many-to-many system that maps input bottleneck features into the corresponding Mel-spectrograms, conditioned on an embedding from the L2 speaker. During inference, both modules operate in sequence to take an unseen L2 utterance and generate a native-accented Mel-spectrogram. Perceptual experiments show that our system achieves a large reduction (67%) in non-native accentedness compared to a state-of-the-art reference-free system (28.9%) that builds a dedicated model for each L2 speaker. Moreover, 80% of the listeners rated the synthesized utterances to have the same voice identity as the L2 speaker.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:21,4920-4924,ISCA,en,,Interspeech 2022
2015,"Rasipuram, Ramya; Cernak, Milos; Nachen, Alexandre; Magimai-Doss, Mathew",Automatic accentedness evaluation of non-native speech using phonetic and sub-phonetic posterior probabilities,Interspeech 2015,,10.21437/Interspeech.2015-233,https://www.isca-speech.org/archive/interspeech_2015/rasipuram15_interspeech.html,"Automatic evaluation of non-native speech accentedness has potential implications for not only language learning and accent identiﬁcation systems but also for speaker and speech recognition systems. From the perspective of speech production, the two primary factors inﬂuencing the accentedness are the phonetic and prosodic structure. In this paper, we propose an approach for automatic accentedness evaluation based on comparison of instances of native and non-native speakers at the acoustic-phonetic level. Speciﬁcally, the proposed approach measures accentedness by comparing phone class conditional probability sequences corresponding to the instances of native and non-native speakers, respectively. We evaluate the proposed approach on the EMIME bilingual and EMIME Mandarin bilingual corpora, which contains English speech from native English speakers and various non-native English speakers, namely Finnish, German and Mandarin. We also investigate the inﬂuence of the granularity of the phonetic unit representation on the performance of the proposed accentedness measure. Our results indicate that the accentedness ratings by the proposed approach correlate consistently with the human ratings of accentedness. In addition, our studies show that the granularity of the phonetic unit representation that yields the best correlation with the human accentedness ratings varies with respect to the native language of the non-native speakers.",06/09/2015,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,648-652,ISCA,en,L2,Interspeech 2015
2016,"Rasipuram, Ramya; Cernak, Milos; Magimai-Doss, Mathew",HMM-Based Non-Native Accent Assessment Using Posterior Features,Interspeech 2016,,10.21437/Interspeech.2016-750,https://www.isca-speech.org/archive/interspeech_2016/rasipuram16_interspeech.html,"Automatic non-native accent assessment has potential beneﬁts in language learning and speech technologies. The three fundamental challenges in automatic accent assessment are to characterize, model and assess individual variation in speech of the non-native speaker. In our recent work, accentedness score was automatically obtained by comparing two phone probability sequences obtained through instances of non-native and native speech. Although automatic accentedness ratings of the approach correlated well with human accent ratings, the approach is critically constrained because of the requirement of native speech instance. In this paper, we build on the previous work and obtain the native latent symbol probability sequence through the word hypothesis modeled as a hidden Markov model (HMM). The latent symbols are either context-independent phonemes or clustered context-dependent phonemes. The advantage of the proposed approach is that it requires just reference text transcription instead of native speech recordings. Using the HMMs trained on an auxiliary native speech corpus, the proposed approach achieves a correlation of 0.68 with human accent ratings on the ISLE corpus. This is further interesting considering that the approach does not use any non-native data and human accent ratings at any stage of the system development.",08/09/2016,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,3137-3141,ISCA,en,L2,Interspeech 2016
2007,"Read, Ian; Cox, Stephen",Automatic pitch accent prediction for text-to-speech synthesis,Interspeech 2007,,10.21437/Interspeech.2007-224,https://www.isca-speech.org/archive/interspeech_2007/read07_interspeech.html,"Determining pitch accents in a sentence is a key task for a textto-speech (TTS) system. We describe some methods for pitch accent assignment which make use of features that contain information about a complete phrase or sentence, in contrast to most previous work which has focused on using features local to a syllable or word. Pitch accent prediction is performed using three different techniques: N -gram models of syllable sequences, dynamic programming to match sequences of features, and decision trees. Using a C4.5 decision tree trained on a wide range of features, most notably each word’s orthographic form and information extracted from the syntactic parse of the sentence, our feature set achieved a balanced error rate of 46.6%. This compares with the feature set used in [11] which had a balanced error rate of 55.55%.",27/08/2007,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,482-485,ISCA,en,prosody,Interspeech 2007
2017,"Rietmolen, Noémie te; Yagoubi, Radouane El; Ghio, Alain; Astésano, Corine",The Phonological Status of the French Initial Accent and its Role in Semantic Processing: An Event-Related Potentials Study,Interspeech 2017,,10.21437/Interspeech.2017-934,https://www.isca-speech.org/archive/interspeech_2017/rietmolen17_interspeech.html,"French accentuation is held to belong to the level of the phrase. Consequently French is considered ‘a language without accent’ with speakers that are ‘deaf to stress’. Recent ERP-studies investigating the French initial accent (IA) however demonstrate listeners not only discriminate between different stress patterns, but also prefer words to be marked with IA early in the process of speech comprehension. Still, as words were presented in isolation, it remains unclear whether the preference applied to the lexical or to the phrasal level. In the current ERP-study, we address this ambiguity and manipulate IA on words embedded in a sentence. Furthermore, we orthogonally manipulate semantic congruity to investigate the interplay between accentuation and later speech processing stages. Preliminary results on 14 participants reveal a signiﬁcant interaction effect: the centro-frontally located N400 was larger for words without IA, with a bigger effect for semantically incongruent sentences. This indicates that IA is encoded at a lexical level and facilitates semantic processing. Furthermore, as participants attended to the semantic content of the sentences, the ﬁnding underlines the automaticity of stress processing. In sum, we demonstrate accentuation plays an important role in French speech comprehension and call for the traditional view to be reconsidered.",20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,2436-2440,ISCA,en,prosody,Interspeech 2017
2019,"Roessig, Simon; Mücke, Doris; Pagel, Lena",Dimensions of Prosodic Prominence in an Attractor Model,Interspeech 2019,,10.21437/Interspeech.2019-2227,https://www.isca-speech.org/archive/interspeech_2019/roessig19_interspeech.html,"Speakers of intonation languages use bundles of cues to express prosodic prominence. This work contributes further evidence for the multi-dimensionality of prosodic prominence in German reporting articulatory (3D EMA) and acoustic recordings from 27 speakers. In particular, we show that speakers use speciﬁc categorical and continuous modiﬁcations of the laryngeal system (tonal onglide) as well as continuous modiﬁcations of the supra-laryngeal system (lip aperture and tongue body position) to mark focus structure prosodically. These modiﬁcations are found between unaccented and accented but also within the group of accented words, revealing that speakers use prosodic modulations to directly encode prominence. On the basis of these ﬁndings we develop a dynamical model of prosodic patterns that is able to capture the manipulations as the modulation of an attractor landscape that is shaped by the different prosodic dimensions involved.",15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,2533-2537,ISCA,en,prosody,Interspeech 2019
2017,"Rognoni, Luca; Bishop, Judith; Corris, Miriam",Pashto Intonation Patterns,Interspeech 2017,,10.21437/Interspeech.2017-1353,https://www.isca-speech.org/archive/interspeech_2017/rognoni17_interspeech.html,"A hand-labelled Pashto speech data set containing spontaneous conversations is analysed in order to propose an intonational inventory of Pashto. Basic intonation patterns observed in the language are summarised. The relationship between pitch accent and part of speech (PoS), which was also annotated for each word in the data set, is briefly addressed.",20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,1228-1232,ISCA,en,prosody,Interspeech 2017
2006,"Rosenberg, Andrew; Hirschberg, Julia",On the correlation between energy and pitch accent in read English speech,Interspeech 2006,,10.21437/Interspeech.2006-107,https://www.isca-speech.org/archive/interspeech_2006/rosenberg06_interspeech.html,,17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,paper 1294-Mon2A3O.2-0,ISCA,en,prosody,Interspeech 2006
2007,"Rosenberg, Andrew; Hirschberg, Julia",Detecting pitch accent using pitch-corrected energy-based predictors,Interspeech 2007,,10.21437/Interspeech.2007-466,https://www.isca-speech.org/archive/interspeech_2007/rosenberg07_interspeech.html,"Previous work has shown that the energy components of frequency subbands with a variety of frequencies and bandwidths predict pitch accent with various degrees of accuracy, and produce correct predictions for distinct subsets of data points. In this paper, we describe a series of experiments exploring techniques to leverage the predictive power of these energy components by including pitch and duration features – other known correlates to pitch accent. We perform these experiments on Standard American English read, spontaneous and broadcast news speech, each corpus containing at least four speakers. Using an approach by which we correct energy-based predictions using pitch and duration information prior to using a majority voting classiﬁer, we were able to detect pitch accent in read, spontaneous and broadcast news speech at 84.0%, 88.3% and 88.5% accuracy, respectively. Human performance at pitch accent detection is generally taken to be between 85% and 90%.",27/08/2007,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,2777-2780,ISCA,en,prosody,Interspeech 2007
2012,"Rosenberg, Andrew",Using prominence and phrasing predictions to improve weighted dictionary pronunciation models,Interspeech 2012,,10.21437/Interspeech.2012-631,https://www.isca-speech.org/archive/interspeech_2012/rosenberg12c_interspeech.html,"Prosody impacts the pronunciation variation of lexical items in a number of ways. Accented syllables tend to be pronounced with their canonical (dictionary) vowel. Deaccented vowels are more likely to be reduced. Coarticulatory inﬂuences rarely span intonational phrase boundaries. In this work, we investigate the use of automatically generated prosodic hypotheses to improve a weighted dictionary pronunciation model. We use the phonemically transcribed, Buckeye Corpus for this investigation. We ﬁnd that predictions of pitch accent and intonational phrase boundaries can be used to lower pronunciation model perplexity.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,2410-2413,ISCA,en,prosody,Interspeech 2012
2008,"Ruiter, Laura E. de",How useful are polynomials for analyzing intonation?,Interspeech 2008,,10.21437/Interspeech.2008-241,https://www.isca-speech.org/archive/interspeech_2008/ruiter08_interspeech.html,"This paper presents the first application of polynomial modeling as a means for validating phonological pitch accent labels to German data. It is compared to traditional phonetic analysis (measuring minima, maxima, alignment). The traditional method fares better in classification, but results are comparable in statistical accent pair testing. Robustness tests show that pitch correction is necessary in both cases. The approaches are discussed in terms of their practicability, applicability to other domains of research and interpretability of their results.",22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,785-788,ISCA,en,prosody,Interspeech 2008
2013,"Sahkai, Heete; Kalvik, Mari-Liis; Mihkla, Meelis",Prosody of contrastive focus in estonian,Interspeech 2013,,10.21437/Interspeech.2013-91,https://www.isca-speech.org/archive/interspeech_2013/sahkai13_interspeech.html,"The study contributes to the cross-linguistic discussion on the prosodic correlates and categorial status of contrastive focus. It brings in data from Estonian, a flexible word order language where the prosodic expression of Information Structure has been very little studied. The study compares narrow contrastive focus with narrow and broad information focus in semi-spontaneous production data, examining word order, pitch accent types and distribution, word duration changes, and F0 values. Interestingly, neither contrastive nor information focus induces the expected word order changes. The examined phonological features, i.e. accent types and distribution, show some correlation with contrastive focus, but the strongest determinant of accent type is the position of focus (final vs. non-final). An interesting finding is that in parallel constructions with symmetric foci, the two foci tend to bear different accents. Duration changes distinguish between all three focus categories; interestingly, a three-way distinction between categories is obtained by way of different distributions of binary durational distinctions. F0 differences between conditions are significant only within certain informants and distinguish between contrastive and information focus only in non-final position; clause-finally, F0 distinguishes between broad and narrow information focus.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,315-319,ISCA,en,prosody,Interspeech 2013
2017,"Sahkai, Heete; Mihkla, Meelis",Intonation of Contrastive Topic in Estonian,Interspeech 2017,,10.21437/Interspeech.2017-840,https://www.isca-speech.org/archive/interspeech_2017/sahkai17_interspeech.html,"Contrastive topic is an information structural category that is usually associated with a specific intonation, which tends to be similar across languages (a rising pitch accent). The aim of the present study is to examine whether this also true of Estonian. Three potential prosodic correlates of contrastive topics are examined: marking with a particular pitch accent type, an emphatic realization of the pitch accent, and a following prosodic boundary. With respect to pitch accent types, it is found that only two subjects out of eight distinguish sentences with a contrastive topic from other types of information structure; the contour bears resemblance to contrastive topic intonation in other languages (consisting of an H* accent on the contrastive topic and an HL* accent on the focus), but is not restricted to sentences with contrastive topics. A more consistent correlate turns out to be an emphatic realization of the pitch accent carried by the contrastive topic constituent. No evidence is found of a tendency to produce contrastive topics as separate prosodic phrases.",20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,3181-3185,ISCA,en,prosody,Interspeech 2017
2012,"Saikachi, Yoko; Kitahara, Mafuyu; Nishikawa, Ken'ya; Kanato, Ai; Mazuka, Reiko",The F0 fall delay of lexical pitch accent in Japanese infant-directed speech,Interspeech 2012,,10.21437/Interspeech.2012-644,https://www.isca-speech.org/archive/interspeech_2012/saikachi12_interspeech.html,"The current study examined the acoustic modifications of the lexical pitch accent in Tokyo Japanese infant-directed speech (IDS), with the focus on the F0 fall delay, where the alignment of the F0 turning points associated with pitch accents were delayed with respect to the accented mora. The RIKEN MotherInfant Conversation Corpus (R-JMICC) [1] produced by 21 mothers from Tokyo area, was used to investigate the alignment of the F0 turning points. Two-piece linear regression was used to locate the turning points and the frequency of F0 fall delay was computed in IDS and in adult-directed speech (ADS). The results revealed that the frequency of F0 fall delay depended on the syllable structures of the accented syllable as well as the prosodic conditions (the presence of the boundary pitch movements and non-lexical lengthening) typically observed in Japanese IDS. We found significantly more frequent F0 fall delay in IDS compared to ADS, when the prosodic conditions were taken into account. The results indicate that the languagespecific prosodic structure should be considered in order to characterize the F0 fall delay of lexical pitch accents in IDS.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,2486-2489,ISCA,en,prosody,Interspeech 2012
2006,"Sakti, Sakriani; Markov, Konstantin; Nakamura, Satoshi","The use of Bayesian network for incorporating accent, gender and wide-context dependency information",Interspeech 2006,,10.21437/Interspeech.2006-438,https://www.isca-speech.org/archive/interspeech_2006/sakti06_interspeech.html,"We propose a new method of incorporating the additional knowledge of accent, gender, and wide-context dependency information into ASR systems by utilizing the advantages of Bayesian networks. First, we only incorporate pentaphone-context dependency information. After that, accent and gender information are also integrated. In this method, we can easily extend conventional triphone HMMs to cover various sources of knowledge. The probabilistic dependencies between a triphone context unit and additional knowledge are learned through a BN. Another advantage is that during recognition, additional knowledge variables are assumed to be hidden, so that the existing standard triphone-based decoding system can be used without modiﬁcation. The performance of the proposed model was evaluated on an LVCSR task using two different types of accented English speech data. Experimental results show that this proposed method improves word accuracy with respect to standard triphone models.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,paper 1812-Wed1BuP.4-0,ISCA,en,L1-or-L2,Interspeech 2006
2005,"Salvi, Giampiero",Advances in regional accent clustering in Swedish,Interspeech 2005,,10.21437/Interspeech.2005-719,https://www.isca-speech.org/archive/interspeech_2005/salvi05b_interspeech.html,"The regional pronunciation variation in Swedish is analysed on a large database. Statistics over each phoneme and for each region of Sweden are computed using the EM algorithm in a hidden Markov model framework to overcome the difﬁculties of transcribing the whole set of data at the phonetic level. The model representations obtained this way are compared using a distance measure in the space spanned by the model parameters, and hierarchical clustering. The regional variants of each phoneme may group with those of any other phoneme, on the basis of their acoustic properties. The log likelihood of the data given the model is shown to display interesting properties regarding the choice of number of clusters, given a particular level of details. Discriminative analysis is used to ﬁnd the parameters that most contribute to the separation between groups, adding an interpretative value to the discussion. Finally a number of examples are given on some of the phenomena that are revealed by examining the clustering tree.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,2841-2844,ISCA,en,L1; def,Interspeech 2005
2011,"Sam, Sethserey; Xiao, Xiong; Besacier, Laurent; Castelli, Eric; Li, Haizhou; Chng, Eng Siong",Speech modulation features for robust nonnative speech accent detection,Interspeech 2011,,10.21437/Interspeech.2011-629,https://www.isca-speech.org/archive/interspeech_2011/sam11_interspeech.html,"In this paper, we propose to use speech modulation features for robust nonnative accent detection. Modulation spectrum carries long term temporal information of speech and may discriminate accents of native and nonnative speakers. For each speech segment to be tested, we extract a 10 dimension feature vector from modulation spectrum and use it for model training and testing. The proposed modulation features are compared with other popular features such as pitch and formant on a nonnative French accent detection task. Results show that the modulation features produce good detection performance and are quite robust to channel distortions. In addition, when combine test scores of modulation features and pitch features, performance is further significantly reduced. The best equal error rate is 13.1% by fusing pitch and modulation-based systems.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,2417-2420,ISCA,en,L2,Interspeech 2011
2009,"Sangwan, Abhijeet; Hansen, John H. L.",On the use of phonological features for automatic accent analysis,Interspeech 2009,,10.21437/Interspeech.2009-68,https://www.isca-speech.org/archive/interspeech_2009/sangwan09_interspeech.html,"In this paper, we present an automatic accent analysis system that is based on phonological features (PFs). The proposed system exploits the knowledge of articulation embedded in phonology by rapidly build Markov models (MMs) of PFs extracted from accented speech. The Markov models capture information in the PF space along two dimensions of articulation: PF state-transitions and state-durations. Furthermore, by utilizing MMs of native and non-native accents a new statistical measure of “accentedness” is developed which rates the articulation of a word on a scale of native-like (−1) to non-native like (+1. The proposed methodology is then used to perform an automatic cross-sectional study of accented English spoken by native speakers of Mandarin Chinese (N-MC). The experimental results demonstrate the capability of the proposed system to rapidly perform quantitative as well as qualitative analysis of foreign accents. The work developed in this paper is easily assimilated into language learning systems, and has impact in the areas of speaker and speech recognition.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,172-175,ISCA,en,L2,Interspeech 2009
2009,"Savino, Michelina",Intonational features for identifying regional accents of Italian,Interspeech 2009,,10.21437/Interspeech.2009-305,https://www.isca-speech.org/archive/interspeech_2009/savino09_interspeech.html,"Aim of this paper is providing a preliminary account of some intonational features useful for identifying a large number of Italian accents, estimated as representative of Italian regional variation, by analysing a corpus of comparable speech materials consisting of Map Task dialogues. Analysis concentrates on the intonational characteristics of yes-no questions, which can be realised very differently across varieties, whereas statements are generally characterised by a (low) falling final movement. Results of this preliminary investigation indicate that intonational features useful for identifying Italian regional accents are the tune type (risingfalling vs falling-rising vs rising), and the nuclear peak alignment in rising-falling contours (mid vs late).",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,2423-2426,ISCA,en,L1,Interspeech 2009
2012,"Scharenborg, Odette; Witteman, Marijt; Weber, Andrea",Computational modelling of the recognition of foreign-accented speech,Interspeech 2012,,10.21437/Interspeech.2012-267,https://www.isca-speech.org/archive/interspeech_2012/scharenborg12b_interspeech.html,"In foreign-accented speech, pronunciation typically deviates from the canonical form to some degree. For native listeners, it has been shown that word recognition is more difficult for strongly-accented words than for less strongly-accented words. Furthermore recognition of strongly-accented words becomes easier with additional exposure to the foreign accent. In this paper, listeners’ behaviour was simulated with Fine-tracker, a computational model of word recognition that uses real speech as input. The simulations showed that, in line with human listeners, 1) Fine-Tracker’s recognition outcome is modulated by the degree of accentedness and 2) it improves slightly after brief exposure with the accent. On the level of individual words, however, Fine-tracker failed to correctly simulate listeners’ behaviour, possibly due to differences in overall familiarity with the chosen accent (German-accented Dutch) between human listeners and Fine-Tracker.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,883-886,ISCA,en,L2,Interspeech 2012
2016,"Scharenborg, Odette; Kolkman, Elea; Kakouros, Sofoklis; Post, Brechtje",The Effect of Sentence Accent on Non-Native Speech Perception in Noise,Interspeech 2016,,10.21437/Interspeech.2016-19,https://www.isca-speech.org/archive/interspeech_2016/scharenborg16b_interspeech.html,"This paper investigates the uptake and use of prosodic information signalling sentence accent during native and nonnative speech perception in the presence of background noise. A phoneme monitoring experiment was carried out in which English, Dutch, and Finnish listeners were presented with target phonemes in semantically unpredictable yet meaningful English sentences. Sentences were presented in different levels of speech-shaped noise and, crucially, in two prosodic contexts in which the target-bearing word was either deaccented or accented. Results showed that overall performance was high for both the native and the non-native listeners; however, where native listeners seemed able to partially overcome the problems at the acoustic level in degraded listening conditions by using prosodic information signalling upcoming sentence accent, non-native listeners could not do so to the same extent. These results support the hypothesis that the performance difference between native and non-native listeners in the presence of background noise is, at least partially, caused by a reduced exploitation of contextual information during speech processing by non-native listeners.",08/09/2016,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,863-867,ISCA,en,L2,Interspeech 2016
2015,"Schauffler, Nadja; Schweitzer, Katrin",Rhythm influences the tonal realisation of focus,Interspeech 2015,,10.21437/Interspeech.2015-21,https://www.isca-speech.org/archive/interspeech_2015/schauffler15_interspeech.html,"Several studies suggest that rhythm affects different aspects in speech production and perception. For example, in German, discourse structure is normally marked by pitch accent placement and pitch accent type, however, there is variation that cannot be explained by purely semantic or syntactic factors. Prosody-inherent factors, like rhythm, can contribute to this variation. This becomes evident in prosodically more complex environments: while the prosody of utterances containing one focused constituent is well investigated and rather clear-cut, the prosodic organisation of multiple contrastive foci is less clear. In double-focus constructions, for example, two focused constituents demand prominence, possibly resulting in the realisation of two pitch accents. If these pitch accents are required on adjacent syllables they conﬂict with rhythmic preferences. We present a sentence reading experiment investigating the tonal realisation of two focused constituents and how their contours affect each other in different rhythmic environments. Speciﬁcally, we tested whether a potential pitch accent clash in a sentence with two corrective foci inﬂuences the pitch excursion and the absolute peak height of the accented syllables. The results demonstrate that rhythmic constraints affect the organisation of the tonal marking of corrective focus.",06/09/2015,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:22,963-967,ISCA,en,prosody,Interspeech 2015
2009,"Schweitzer, Katrin; Riester, Arndt; Walsh, Michael; Dogil, Grzegorz",Pitch accents and information status in a German radio news corpus,Interspeech 2009,,10.21437/Interspeech.2009-303,https://www.isca-speech.org/archive/interspeech_2009/schweitzer09_interspeech.html,"This paper presents a corpus analysis of prosodic realisations of information status categories in terms of pitch accent types. The annotations base on a recent annotation scheme for information status [1] that is based on semantic criteria applied to written text. For each information status category, typical pitch accent realisations are identiﬁed. Moreover, the relevance of the strict semantic information status labelling scheme on the prosodic realisation is examined. It can be shown that the semantic criteria are reﬂected in prosody, i.e. the prosodic ﬁndings corroborate the theoretical assumptions made in the framework.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,2415-2418,ISCA,en,prosody,Interspeech 2009
2009,"Schweitzer, Antje; Möbius, Bernd",Experiments on automatic prosodic labeling,Interspeech 2009,,10.21437/Interspeech.2009-663,https://www.isca-speech.org/archive/interspeech_2009/schweitzer09b_interspeech.html,"This paper presents results from experiments on automatic prosodic labeling. Using the WEKA machine learning software [1], classiﬁers were trained to determine for each syllable in a speech database of a male speaker its pitch accent and its boundary tone. Pitch accents and boundaries are according to the GToBI(S) dialect, with slight modiﬁcations. Classiﬁcation was based on 35 attributes involving PaIntE F0 parametrization [2] and normalized phone durations, but also some phonological information as well as higher-linguistic information. Several classiﬁcation algorithms yield results of approx. 78% accuracy on the word level for pitch accents, and approx. 88% accuracy on the word level for phrase boundaries, which compare very well to results of other studies. The classiﬁers generalize to similar data of a female speaker in that they perform equally well as classiﬁers trained directly on the female data.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,2515-2518,ISCA,en,prosody,Interspeech 2009
2010,"Schweitzer, Katrin; Walsh, Michael; Möbius, Bernd; Schütze, Hinrich",Frequency of occurrence effects on pitch accent realisation,Interspeech 2010,,10.21437/Interspeech.2010-69,https://www.isca-speech.org/archive/interspeech_2010/schweitzer10_interspeech.html,"This paper presents the results of a corpus study which examines the impact of frequency of occurrence of accented words on the realisation of pitch accents. In particular, statistical analyses explore this inﬂuence on pitch accent range and alignment. The results indicate a signiﬁcant effect of frequency of occurrence on the relative height of L*H and H*L pitch accents and an also signiﬁcant but more subtle effect on the alignment of L*H accents.",26/09/2010,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,138-141,ISCA,en,prosody,Interspeech 2010
2017,"Schweitzer, Katrin; Walsh, Michael; Schweitzer, Antje",To See or not to See: Interlocutor Visibility and Likeability Influence Convergence in Intonation,Interspeech 2017,,10.21437/Interspeech.2017-1248,https://www.isca-speech.org/archive/interspeech_2017/schweitzer17_interspeech.html,"In this paper we look at convergence and divergence in intonation in the context of social qualities. Speciﬁcally we examine pitch accent realisations in the GECO corpus of German conversations. Pitch accents are represented as 6-dimensional vectors where each dimension corresponds to a characteristic of the accent’s shape. Convergence/divergence is then measured by calculating the distance between pitch accent realisations of conversational partners. A decrease of distance values over time indicates convergence, an increase divergence. The corpus comprises dialogue sessions in two modalities: partners either saw each other during the conversation or not. Linear mixed model analyses show convergence as well as divergence effects in the realisations of H*L accents. This convergence/divergence is strongly related to the modality and to how much speakers like their partners: generally, seeing the partner comes with divergence, whereas when the dialogue partners cannot see each other, there is convergence. The effect varies, however, depending on the extent to which a speaker likes their partner. Less liking entails a greater change in the realisations over time –stronger divergence when partners could see each other, and stronger convergence when they could not.",20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,919-923,ISCA,en,prosody,Interspeech 2017
2011,"Sečujski, Milan; Pekar, Darko; Jakovljević, Nikša",Automatic prosody generation for serbo-croatian speech synthesis based on regression trees,Interspeech 2011,,10.21437/Interspeech.2011-790,https://www.isca-speech.org/archive/interspeech_2011/secujski11_interspeech.html,"The paper presents the module for automatic generation of prosodic features of synthesized speech, namely, f0 targets and phonetic segment durations, within the speech synthesizer AlfaNumTTS, the most sophisticated speech synthesis system for Serbo-Croatian language to date. The module is based on regression trees trained on a studio recorded single speaker database of Serbo-Croatian. The database has been annotated for phonemic identity as well as a number of prosodic events such as pitch accents, phrase breaks and prosodic prominence. Besides the traditional description of the intonational phonology of Serbo-Croatian through four distinct accent types, within this study we have examined the possibility of representing them as tonal sequences, which has been suggested in recent linguistic literature. The results obtained confirm that the four accents can indeed be reduced to sequences of high and low tones without loss of quality, provided that phonemic length contrast is preserved.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,3157-3160,ISCA,en,prosody,Interspeech 2011
2008,"Shaikh, Mostafa Al Masum; Molla, Md. Khademul Islam; Hirose, Keikichi",Assigning suitable phrasal tones and pitch accents by sensing affective information from text to synthesize human-like speech,Interspeech 2008,,10.21437/Interspeech.2008-97,https://www.isca-speech.org/archive/interspeech_2008/shaikh08_interspeech.html,"We have carried out several perceptual and objective experiments that show that the present Text-To-Speech (TTS) systems are weak in the relevance of prosody and segmental spectrum in the characterization and expression of emotions. Since it is known that the emotional state of a speaker usually alters the way s/he speaks, the TTS systems need to be improved to generate human-like pitch accents to express the subtle features of emotions. This paper describes a pitch accent assignment technique which places appropriate pitch accents on elements of the utterance that require particular emphasis or stress. Our pitch accenting technique utilizes commonsense knowledge-base and a linguistic tool to recognize emotion conveyed though the text itself. From these it determines whether the content of the utterance has a connotation to a particular emotion (e.g., happy, sad, surprise etc.), good or bad concepts, praiseworthy or blameworthy actions, common or vital information. It can then assign an appropriate pitch accent to one word in each prosodic phrase. The TTS component then determines the appropriate syllable to be accented in the word. Our approach can well support a TTS system’s synthesis, allowing the system to generate affective version of the spoken text.",22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,326-329,ISCA,en,prosody,Interspeech 2008
2021,"Shang, Zengqiang; Huang, Zhihua; Zhang, Haozhe; Zhang, Pengyuan; Yan, Yonghong",Incorporating Cross-Speaker Style Transfer for Multi-Language Text-to-Speech,Interspeech 2021,,10.21437/Interspeech.2021-1265,https://www.isca-speech.org/archive/interspeech_2021/shang21_interspeech.html,"Recently multilingual TTS systems using only monolingual datasets have obtained signiﬁcant improvement. However, the quality of cross-language speech synthesis is not comparable to the speaker’s own language and often comes with a heavy foreign accent. This paper proposed a multi-speaker multi-style multi-language speech synthesis system (M3), which improves the speech quality by introducing a ﬁne-grained style encoder and overcomes the non-authentic accent problem through crossspeaker style transfer. To avoid leaking timbre information into style encoder, we utilized a speaker conditional variational encoder and conducted adversarial speaker training using the gradient reversal layer. Then, we built a Mixture Density Network (MDN) for mapping text to extracted style vectors for each speaker. At the inference stage, cross-language style transfer could be achieved by assigning any speaker’s style type in the target language. Our system uses existing speaker style and genuinely avoids foreign accents. In the MOS-speech-naturalness, the proposed method generally achieves 4.0 and signiﬁcantly outperform the baseline system.",30/08/2021,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,1619-1623,ISCA,en,L1-or-L2,Interspeech 2021
2022,"Shao, Qijie; Yan, Jinghao; Kang, Jian; Guo, Pengcheng; Shi, Xian; Hu, Pengfei; Xie, Lei",Linguistic-Acoustic Similarity Based Accent Shift for Accent Recognition,Interspeech 2022,,10.21437/Interspeech.2022-10444,https://www.isca-speech.org/archive/interspeech_2022/shao22b_interspeech.html,"General accent recognition (AR) models tend to directly extract low-level information from spectrums, which always significantly overfit on speakers or channels. Considering accent can be regarded as a series of shifts relative to native pronunciation, distinguishing accents will be an easier task with accent shift as input. But due to the lack of native utterance as an anchor, estimating the accent shift is difficult. In this paper, we propose linguistic-acoustic similarity based accent shift (LASAS) for AR tasks. For an accent speech utterance, after mapping the corresponding text vector to multiple accent-associated spaces as anchors, its accent shift could be estimated by the similarities between the acoustic embedding and those anchors. Then, we concatenate the accent shift with a dimension-reduced text vector to obtain a linguistic-acoustic bimodal representation. Compared with pure acoustic embedding, the bimodal representation is richer and more clear by taking full advantage of both linguistic and acoustic information, which can effectively improve AR performance. Experiments on Accented English Speech Recognition Challenge (AESRC) dataset show that our method achieves 77.42% accuracy on Test set, obtaining a 6.94% relative improvement over a competitive system in the challenge.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,3719-3723,ISCA,en,,Interspeech 2022
2020,"Shirahata, Yuma; Saito, Daisuke; Minematsu, Nobuaki",Discriminative Method to Extract Coarse Prosodic Structure and its Application for Statistical Phrase/Accent Command Estimation,Interspeech 2020,,10.21437/Interspeech.2020-2566,https://www.isca-speech.org/archive/interspeech_2020/shirahata20_interspeech.html,"This paper introduces a method of extracting coarse prosodic structure from fundamental frequency (F0) contours by using a discriminative approach such as deep neural networks (DNN), and applies the method for the parameter estimation of the Fujisaki model. In the conventional methods for the parameter estimation of the Fujisaki model, generative approaches, in which the estimation is treated as an inverse problem of the generation process, have been adopted. On the other hand, recent development of the discriminative approaches would enable us to treat the problem in a direct manner. To introduce a discriminative approach to the parameter estimation of the Fujisaki model in which the precise labels for the parameter are expensive, this study focuses on the similarities between the acoustic realization of the prosodic structure in F0 contours and the sentence structure of the read text. In the proposed method, the sentence structure obtained from the text is utilized as the labels for the discriminative model, and the model estimates the coarse prosodic structure. Finally this structure is reﬁned by using a conventional method for the parameter estimation. Experimental results demonstrate that the proposed method improves the estimation accuracy by 18% in terms of detection rate without using any auxiliary features at inference.",25/10/2020,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,4427-4431,ISCA,en,prosody,Interspeech 2020
2019,"Shor, Joel; Emanuel, Dotan; Lang, Oran; Tuval, Omry; Brenner, Michael; Cattiau, Julie; Vieira, Fernando; McNally, Maeve; Charbonneau, Taylor; Nollstadt, Melissa; Hassidim, Avinatan; Matias, Yossi",Personalizing ASR for Dysarthric and Accented Speech with Limited Data,Interspeech 2019,,10.21437/Interspeech.2019-1427,https://www.isca-speech.org/archive/interspeech_2019/shor19_interspeech.html,"Automatic speech recognition (ASR) systems have dramatically improved over the last few years. ASR systems are most often trained from ‘typical’ speech, which means that underrepresented groups don’t experience the same level of improvement. In this paper, we present and evaluate ﬁnetuning techniques to improve ASR for users with non-standard speech. We focus on two types of non-standard speech: speech from people with amyotrophic lateral sclerosis (ALS) and accented speech. We train personalized models that achieve 62% and 35% relative WER improvement on these two groups, bringing the absolute WER for ALS speakers, on a test set of message bank phrases, down to 10% for mild dysarthria and 20% for more serious dysarthria. We show that 71% of the improvement comes from only 5 minutes of training data. Finetuning a particular subset of layers (with many fewer parameters) often gives better results than ﬁnetuning the entire model. This is the ﬁrst step towards building state of the art ASR models for dysarthric speech.",15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,784-788,ISCA,en,L1-or-L2,Interspeech 2019
2007,"Shue, Yen-Liang; Iseli, Markus; Veilleux, Nanette; Alwan, Abeer",Pitch accent versus lexical stress: quantifying acoustic measures related to the voice source,Interspeech 2007,,10.21437/Interspeech.2007-690,https://www.isca-speech.org/archive/interspeech_2007/shue07_interspeech.html,"In this paper, we explore acoustic correlates of pitch accent and main lexical stress in American English, and the interaction of these cues with other factors that affect prosody. In a controlled study, we varied presence or absence and type of pitch accent (L∗ vs H∗), boundary-related tone sequence (L-L% vs. HH%) and gender of the talker, for the sentence “Dagada gave Bobby doodads”. The measures were duration, F0 (fundamental frequency), H1∗−H2∗ (related to open quotient), and H1∗−A∗3 (related to spectral tilt). Contour approximations were used to analyze time-course movements of these measures. For “Dagada” we found that, consistent with earlier literature, a) H∗ and L∗ pitch accents showed different F0 contours, b) pitchaccented syllables were longer than unaccented ones, c) stressed “ga” syllables had lower H1∗ − H2∗ values than surrounding unstressed syllables, and for male talkers, lower H1∗ − A∗3 values, indicating lesser spectral tilt. Unexpectedly, F0 maxima associated with an H∗ accent occurred most of the time later in the accented syllable than F0 minima associated with L∗. The cues to lexical stress were consistent with or without pitch accent (e.g. lower H1∗ − H2∗), but they sometimes interacted with gender and/or boundary tones: for example, lower H1∗ − A∗3 in stressed “ga” syllables was only found for female talkers in unaccented cases, and some cues of both accent and stress were less pronounced in the ﬁnal word “doodads”, which also carried boundary-related tones.",27/08/2007,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,2625-2628,ISCA,en,prosody,Interspeech 2007
2008,"Shue, Yen-Liang; Shattuck-Hufnagel, Stefanie; Iseli, Markus; Jun, Sun-Ah; Veilleux, Nanette; Alwan, Abeer",Effects of intonational phrase boundaries on pitch-accented syllables in american English,Interspeech 2008,,10.21437/Interspeech.2008-279,https://www.isca-speech.org/archive/interspeech_2008/shue08_interspeech.html,"Recent studies of the acoustic correlates of various prosodic elements in American English, such as prominence (in the form of phrase-level pitch accents and word-level lexical stress) and boundaries (in the form of boundary-marking tones), have begun to clarify the nature of the acoustic cues to different types and levels of these prosodic markers. This study focuses on the importance of controlling for context in such investigations, illustrating the effects of adjacent context by examining the cues to H* and L* pitch accent in early and late position in the Intonational Phrase, and how these cues vary when the accented syllable is followed immediately by boundary tones. Results show that F0 peaks for H* accents occur significantly earlier in words that also carry boundary tones, and that energy patterns are also affected; some effects on voice quality measures were also noted. Such findings highlight the caveat that the context of a particular prosodic target may significantly influence its acoustic correlates.",22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,873-876,ISCA,en,prosody,Interspeech 2008
2013,"Siddins, Jessica; Harrington, Jonathan; Kleber, Felicitas; Reubold, Ulrich",The influence of accentuation and polysyllabicity on compensatory shortening in German,Interspeech 2013,,10.21437/Interspeech.2013-177,https://www.isca-speech.org/archive/interspeech_2013/siddins13_interspeech.html,"The aim of this study was to investigate the relationship between compensatory shortening and coarticulation in German tense and lax vowels in trochees and iambs and to determine whether this relationship was inﬂuenced by prosodic accentuation. Speakers produced near minimal pairs differing in vowel tensity in monosyllabic and disyllabic words (both trochees and iambs) in accented and deaccented contexts. We found signiﬁcant effects of polysyllabic shortening, but only in tense vowels of nuclear-accented target words. Both stress patterns (trochaic and iambic) showed equal effects of polysyllabic shortening. Thus, while the duration of tense vowels in this study depended on accentuation and syllabicity, perhaps in order to provide perceptual cues for the listener, lax vowels were immune from lengthening and shortening phenomena. As a result, the durational difference between tense and lax vowels appears to lessen in prosodically weak contexts. The greater overlap of acoustic duration in deaccented contexts may contribute to the origin of the diachronic merger of tense and lax vowels in some languages.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,1002-1006,ISCA,en,prosody,Interspeech 2013
2017,"Sivaraman, Ganesh; Espy-Wilson, Carol; Wieling, Martijn",Analysis of Acoustic-to-Articulatory Speech Inversion Across Different Accents and Languages,Interspeech 2017,,10.21437/Interspeech.2017-260,https://www.isca-speech.org/archive/interspeech_2017/sivaraman17_interspeech.html,"The focus of this paper is estimating articulatory movements of the tongue and lips from acoustic speech data. While there are several potential applications of such a method in speech therapy and pronunciation training, performance of such acoustic-to-articulatory inversion systems is not very high due to limited availability of simultaneous acoustic and articulatory data, substantial speaker variability, and variable methods of data collection. This paper therefore evaluates the impact of speaker, language and accent variability on the performance of an acoustic-to-articulatory speech inversion system. The articulatory dataset used in this study consists of 21 Dutch speakers reading Dutch and English words and sentences, and 22 UK English speakers reading English words and sentences. We trained several acoustic-to-articulatory speech inversion systems both based on deep and shallow neural network architectures in order to estimate electromagnetic articulography (EMA) sensor positions, as well as vocal tract variables (TVs). Our results show that with appropriate feature and target normalization, a speaker-independent speech inversion system trained on data from one language is able to estimate sensor positions (or TVs) for the same language correlating at about r = 0.53 with the actual sensor positions (or TVs). Cross-language results show a reduced performance of r = 0.47.",20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,974-978,ISCA,en,L2,Interspeech 2017
2006,"Speyer, Augustin",Pauses as a tool to ensure rhythmic wellformedness,Interspeech 2006,,10.21437/Interspeech.2006-256,https://www.isca-speech.org/archive/interspeech_2006/speyer06_interspeech.html,"Rhythmic wellformedness on the level of syllables and words and the mechanisms which are employed to ensure it are well known and researched on. The level of sentential accent is less often in the focus of such studies. In this paper I argue that rhythmic wellformedness plays an equally important role on the sentential level and that the preferred strategy to ensure it is the insertion of a pause (or lengthening of an already present pause), rather than the classical strategies of stress shift and destressing. This has to do with the role that focal accent plays for the semantic interpretation of an utterance. A reading experiment showed clearly that in clash cases the distance between the words in clash is increased by a pause; as we get the same effect in words in which a number of unstressed syllables intervenes between the clashing focal accents, it is clear that it is not simply stress clash resolution but resolution of a clash on a higher level of representation.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,paper 1406-Tue3A3O.2-0,ISCA,en,prosody,Interspeech 2006
2020,"Spinu, Laura; Hwang, Jiwon; Pincus, Nadya; Vasilita, Mariana",Exploring the Use of an Artificial Accent of English to Assess Phonetic Learning in Monolingual and Bilingual Speakers,Interspeech 2020,,10.21437/Interspeech.2020-2783,https://www.isca-speech.org/archive/interspeech_2020/spinu20_interspeech.html,"We designed a production experiment to explore the relatively controversial phenomenon of the bilingual advantage. Our focus is on an understudied aspect of bilingual cognition, speciﬁcally phonetic learning. We presented 36 participants (17 monolinguals and 19 early bilinguals) living in New York City with an artiﬁcially constructed accent of English, differing in four ways from Standard American English. More precisely, the novel accent included a vocalic change (diphthongization of the open-mid front unrounded vowel), consonantal change (tapping of intervocalic liquids), syllable structure change (epenthesis in voiceless s-clusters) and suprasegmental change (a novel intonation pattern in tag questions). After recording their baseline accents, the participants ﬁrst completed a training task, in which they listened to and then directly imitated sentences heard in the novel accent, and then a testing task, in which they were asked to read the baseline sentences in the accent they had just learned in the absence of any audio prompts. In this paper, we present acoustic results with diphthongization and tag question intonation. Our ﬁndings replicate the previously observed bilingual advantage in phonetic learning across the board and extend it to novel learning circumstances.",25/10/2020,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,2377-2381,ISCA,en,L1-or-L2,Interspeech 2020
2008,"Sridhar, Vivek Kumar Rangarajan; Bangalore, Srinivas; Narayanan, Shrikanth S.",Factored translation models for enriching spoken language translation with prosody,Interspeech 2008,,10.21437/Interspeech.2008-675,https://www.isca-speech.org/archive/interspeech_2008/sridhar08_interspeech.html,"Key contextual information such as word prominence, emphasis, and contrast is typically ignored in speech-to-speech (S2S) translation due to the compartmentalized nature of the translation process. Conventional S2S systems rely on extracting prosody dependent cues from hypothesized (possibly erroneous) translation output using only words and syntax. In contrast, we propose the use of factored translation models to integrate the assignment and transfer of pitch accents (tonal prominence) during translation. We report experiments on 2 parallel corpora (Farsi-English and Japanese-English). The proposed factored translation models provide a relative improvement of 8.4% and 16.8% in pitch accent labeling accuracy over the postprocessing approach for the two corpora respectively.",22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,2723-2726,ISCA,en,prosody,Interspeech 2008
2016,"Stehwien, Sabrina; Vu, Ngoc Thang",Exploring the Correlation of Pitch Accents and Semantic Slots for Spoken Language Understanding,Interspeech 2016,,10.21437/Interspeech.2016-511,https://www.isca-speech.org/archive/interspeech_2016/stehwien16_interspeech.html,"We investigate the correlation between pitch accents and semantic slots in human-machine speech. Using an automatic pitch accent detector on the ATIS corpus, we ﬁnd that most words labelled with semantic slots also carry a pitch accent. Most of the pitch accented words that are not associated with a semantic label are still meaningful, pointing towards the speaker’s intention. Our ﬁndings show that prosody constitutes a relevant and useful resource for spoken language understanding, especially considering the fact that our pitch accent detector does not require any kind of manual transcriptions during testing time.",08/09/2016,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,730-734,ISCA,en,prosody,Interspeech 2016
2014,"Stringer, Louise; Iverson, Paul",The effect of regional and non-native accents on word recognition processes: a comparison of EEG responses in quiet to speech recognition in noise,Interspeech 2014,,10.21437/Interspeech.2014-555,https://www.isca-speech.org/archive/interspeech_2014/stringer14_interspeech.html,"Previous work has shown that both the speed and accuracy of word recognition can be reduced if a talker has a regional or non-native accent, particularly under noisy conditions. This study investigated whether the reduced intelligibility of some accents in noise are related to aspects of speech processing in quiet. Our goal was to see if difficulties processing accented speech under adverse listening conditions can be revealed in quiet using electrophysiological methods. Participants heard English sentences in a standard, regional or non-native accent. Behavioural measures found listeners had a strong intelligibility advantage for the standard accent when mixed with noise, replicating previous work. However, differences in processing the accents were less clear using the EEG measures. We found a significant Phonological Mapping Negativity (PMN) elicited by phonological anomalies, as well as an N400 effect, which is related to semantic anomalies, but although both responses were somewhat larger for the standard accent, there was more overlap in the EEG responses for different accents than for speech-in-noise recognition. More work is needed, but it is plausible that some of the difficulty that listeners have with accents under noise may be related to the same accent processing difficulties that occur in quiet.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,2590-2594,ISCA,en,L1-or-L2,Interspeech 2014
2007,"Strom, Volker; Nenkova, Ani; Clark, Robert; Vazquez-Alvarez, Yolanda; Brenier, Jason; King, Simon; Jurafsky, Dan",Modelling prominence and emphasis improves unit-selection synthesis,Interspeech 2007,,10.21437/Interspeech.2007-230,https://www.isca-speech.org/archive/interspeech_2007/strom07_interspeech.html,"We describe the results of large scale perception experiments showing improvements in synthesising two distinct kinds of prominence: standard pitch-accent and strong emphatic accents. Previously prominence assignment has been mainly evaluated by computing accuracy on a prominence-labelled test set. By contrast we integrated an automatic pitch-accent classiﬁer into the unit selection target cost and showed that listeners preferred these synthesised sentences. We also describe an improved recording script for collecting emphatic accents, and show that generating emphatic accents leads to further improvements in the ﬁction genre over incorporating pitch accent only. Finally, we show differences in the effects of prominence between child-directed speech and news and ﬁction genres.",27/08/2007,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:23,1282-1285,ISCA,en,prosody,Interspeech 2007
2022,"Suzuki, Yu; Kato, Tsuneo; Tamura, Akihiro",Automatic Prosody Evaluation of L2 English Read Speech in Reference to Accent Dictionary with Transformer Encoder,Interspeech 2022,,10.21437/Interspeech.2022-10344,https://www.isca-speech.org/archive/interspeech_2022/suzuki22b_interspeech.html,"Automatic prosody evaluation models for second language (L2) read speech are classiﬁed into two categories: reference-based and reference-free. Reference-based models refer to native speakers’ speech of the uttered text while reference-free models do not. Conventional reference-free models do not even take the uttered text into account. We propose an automatic prosody evaluation model that takes the uttered text into account by estimating native speakers’ prosodic patterns using a Transformer encoder. The Transformer encoder used in FastSpeech 2 estimates a sequence of native speakers’ prosodic features in a phoneme-segment level, and a subsequent neural network module evaluates an L2 learner’s utterance by comparing the sequence of prosodic features with the estimated sequence of native speakers’ utterances. We evaluated the model by Spearman’s correlation between the objective and subjective scores on L2 English sentence speech read by Japanese university students. The experimental results indicated that our model achieved a higher subjective-objective score correlation than that with a reference-free model and even higher than an inter-rater score correlation.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,4466-4470,ISCA,en,L2,Interspeech 2022
2022,"Szalay, Tuende; Shahin, Mostafa; Ahmed, Beena; Ballard, Kirrie",Knowledge of accent differences can be used to predict speech recognition,Interspeech 2022,,10.21437/Interspeech.2022-10162,https://www.isca-speech.org/archive/interspeech_2022/szalay22_interspeech.html,"If accent differences can predict the type of speech recognition errors, a smaller dataset systematically representing accent differences might be sufficient and less resource intensive for adapting an automatic speech recognition (ASR) to a novel variety compared to training the ASR on a large, unsystematic dataset. However, it is not known whether ASR errors pattern according to accent differences. Therefore, we tested the performance of Google’s General American (GenAm) and Standard Australian English (SAusE) ASR on both dialects using words systematically representing accent differences. Accent differences were quantified using the different number of vowel phonemes, the different phonetic quality of vowels, and differences in rhoticity (i.e., presence/absence of postvocalic /ô/). Our results confirm that word recognition is significantly more accurate when ASR dialect matches the speaker dialect compared to the mismatched condition. Our results reveal that GenAm ASR is less accurate on SAusE speakers due to the higher number of vowel phonemes and the lack of postvocalic /ô/ in SAusE. Thus, the data need of adapting ASR from GenAm to SAusE might be reduced by using a small dataset focusing on differences in the size of vowel inventory and in rhoticity.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,1372-1376,ISCA,en,L1-or-L2,Interspeech 2022
,"Tabain, Marija; Rickard, Kristine; Breen, Gavan; Dobson, Veronica",Central vowels in Arrernte: metrical prominence and pitch accent,,,,,"This paper presents duration and formant data for the central vowels /@/ (schwa) and /a/ in Arrernte, a central Australian language. Results show that /@/ has a shorter duration and higher position in the vowel space in metrically prominent syllables, whereas /a/ has a longer duration and no change in formant structure. By contrast, effects of pitch accent are minimal for both vowels.",,22/02/2023 10:34,22/02/2023 10:34,,,,en,prosody,
2007,"Tamburini, Fabio; Wagner, Petra",On automatic prominence detection for German,Interspeech 2007,,10.21437/Interspeech.2007-505,https://www.isca-speech.org/archive/interspeech_2007/tamburini07_interspeech.html,"Perceptual prominence is an important indicator of a word’s and syllable’s lexical, syntactic, semantic and pragmatic status in a discourse. Its automatic annotation would be a valuable enrichment of large databases used in unit selection speech synthesis and speech recognition. While much research has been carried out on the interaction between prominence and acoustic factors, little progress has been made in its automatic annotation. Previous approaches to German relied on linguistic features in prominence detection, but a purely acoustic method would be advantageous. We applied an algorithm to German data that had been previously used for English and Italian. Both the algorithm and the data annotation encode prominence as a continuous rather than a categorical parameter. First results are encouraging, but again show that prominence perception relies on linguistic expectancies as well as acoustic patterns. Also, our results further strengthen the view that force accents are a more reliable cue to prominence than pitch accents in German.",27/08/2007,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,1809-1812,ISCA,en,prosody,Interspeech 2007
2007,"Tamm, Anne; Abari, Kálmán; Olaszy, Gábor","Accent assignment algorithm in Hungarian, based on syntactic analysis",Interspeech 2007,,10.21437/Interspeech.2007-220,https://www.isca-speech.org/archive/interspeech_2007/tamm07_interspeech.html,"This article presents the results of the research aimed at developing an accent assignment system for Hungarian. Two methods are compared. The shallow method targets local and short-distance factors that determine accent; the deep (syntactic) method targets long-distance influences (such as focus). Neither of the methods alone results in absolutely satisfactory output; frequently, however, mistakes are complementary. The article presents the problems and solutions of both methods.",27/08/2007,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,466-469,ISCA,en,prosody,Interspeech 2007
2010,"Tanida, Yuuki; Ueno, Taiji; Saito, Satoru; Ralph, Matthew A. Lambon",Effects of accent typicality and phonotactic frequency on nonword immediate serial recall performance in Japanese,Interspeech 2010,,10.21437/Interspeech.2010-455,https://www.isca-speech.org/archive/interspeech_2010/tanida10_interspeech.html,"In a nonword serial recall experiment we found following results: (1) Phonotactically high frequent nonwords were recalled better than low ones in terms of phoneme accuracy; (2) but this phonotactic frequency effect was not observed in accent accuracy. (3) Accent typicality did not have an expected effect on phoneme recall accuracy; (4) but it had an effect on accent accuracy. These results suggest that both long-term knowledge about phoneme sequences and accent patterns have strong influences on verbal short-term memory performance, but those influences might be limited to each particular domain.",26/09/2010,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,1565-1567,ISCA,en,prosody,Interspeech 2010
2005,"Teixeira, João Paulo; Freitas, Diamantino; Fujisaki, Hiroya",Evaluation of a system for F0 contour prediction for european Portuguese,Interspeech 2005,,10.21437/Interspeech.2005-564,https://www.isca-speech.org/archive/interspeech_2005/teixeira05_interspeech.html,"This paper presents the evaluation of a system for speech F0 contour prediction for European Portuguese using the Fujisaki model. It is composed of two command-generating subsystems, the phrase command sub-system and the accent command sub-system. The parameters for evaluating the ability of each sub-system are described. A comparison is made between original and predicted F0 contours. Finally, the results of a perceptual test are discussed.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,3249-3252,ISCA,en,prosody,Interspeech 2005
2013,"Telaar, Dominic; Fuhs, Mark C.",Accent- and speaker-specific polyphone decision trees for non-native speech recognition,Interspeech 2013,,10.21437/Interspeech.2013-733,https://www.isca-speech.org/archive/interspeech_2013/telaar13_interspeech.html,"Acoustic models in state-of-the-art LVCSR systems are typically trained on data from thousands of speakers and then adapted to a speaker using, e.g., various combinations of CMLLR, MLLR and MAP. This adaptation step is particularly important for speakers with accents that are not well represented in the training set. The present study explores how to improve performance on South-Asian-accented speakers (SoA-accented) with the availability of thousands of US-accented, hundreds of SoA-accented, and tens of hours of speaker-speciﬁc training data. We employ a decision tree similarity measure to analyze how varying co-articulations across accents and people manifest themselves in the decision tree. Modeling these variations in addition to adapting the GMMs of an existing baseline system to a speaker improved WER for small systems (1k GMMs), but improvement for systems with larger trees (2k, 3k GMMs) was modest. Overall, GMM adaptation/retraining yields significant performance beneﬁts, and training a SoA-accent-speciﬁc system is particularly worthwhile when lacking speaker adaptation data.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,3313-3316,ISCA,en,L2,Interspeech 2013
2011,"Tepperman, Joseph; Nava, Emily",Where should pitch accents and phrase breaks go? a syntax tree transducer solution,Interspeech 2011,,10.21437/Interspeech.2011-447,https://www.isca-speech.org/archive/interspeech_2011/tepperman11b_interspeech.html,"Motivated by a desire to assess the prosody of foreign language learners, this study demonstrates the beneﬁt of highlevel syntactic information in automatically deciding where phrase breaks and pitch accents should go in text. The connection between syntax and prosody is well-established, and naturally lends itself to tree-based probabilistic models. With automatically-derived parse trees paired to tree transducer models, we found that categorical prosody tags for unseen text can be determined with signiﬁcantly higher accuracy than they can with a baseline method that uses n-gram models of part-ofspeech tags. On the Boston University Radio News Corpus, the tree transducer outperformed the baseline by 14% overall for accents, and by 3% overall for breaks. These automatic results fell within this corpus’s range of inter-speaker agreement in assigning accents and breaks to text.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,1353-1356,ISCA,en,prosody,Interspeech 2011
2010,"Teutenberg, Jonathan; Watson, Catherine I.",The effect of audience familiarity on the perception of modified accent,Interspeech 2010,,10.21437/Interspeech.2010-559,https://www.isca-speech.org/archive/interspeech_2010/teutenberg10_interspeech.html,"Evaluating the efﬁcacy of accent transformation is important when localising speech-enabled software. However, perceived accent is an attribute assigned by a listener, and the apparent success of accent transformation will vary with the audience. Here we show the extent to which evaluations can be affected by audience familiarity with an accent. A perceptual study comparing two approaches to accent transformation is presented to two audiences with differing familiarity with the target accents. For mean opinion score style evaluations, we quantify the approximate change in perception, and show that this can be sufﬁcient to alter relative successfulness of such systems.",26/09/2010,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,1970-1973,ISCA,en,L1,Interspeech 2010
2005,"Tjalve, Michael; Huckvale, Mark",Pronunciation variation modelling using accent features,Interspeech 2005,,10.21437/Interspeech.2005-487,https://www.isca-speech.org/archive/interspeech_2005/tjalve05_interspeech.html,"In this paper, we propose a novel method for modelling native accented speech. As an alternative to the notion of dialect, we work with the lower level phonological components of accents, which we term accent features. This provides us with a better understanding of how pronunciation varies and it allows us to give a much more detailed picture of a person’s speech.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,1341-1344,ISCA,en,L1; no def,Interspeech 2005
2015,"Toman, Markus; Pucher, Michael",Evaluation of state mapping based foreign accent conversion,Interspeech 2015,,10.21437/Interspeech.2015-122,https://www.isca-speech.org/archive/interspeech_2015/toman15_interspeech.html,We present an evaluation of the perception of foreign-accented natural and synthetic speech in comparison to accent-reduced synthetic speech. Our method for foreign accent conversion is based on mapping of Hidden Semi-Markov Model states between accented and non-accented voice models and does not need an average voice model of accented speech. We employ the method on recorded data of speakers with ﬁrst language (L1) from different European countries and second language (L2) being Austrian German. Results from a subjective evaluation show that the proposed method is able to signiﬁcantly reduce the perceived accent. It also retains speaker similarity when an average voice model of the same gender is used. Accentedness of synthetic speech was rated signiﬁcantly lower than natural speech by the participants and listeners were unable to identify accents correctly for 81% of the natural and 85% of the synthesized samples. Our evaluation shows the feasibility of accent conversion with a limited amount of speech resources.,06/09/2015,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,304-308,ISCA,en,L2,Interspeech 2015
2005,"Tomokiyo, Laura Mayfield; Black, Alan W.; Lenzo, Kevin A.",Foreign accents in synthetic speech: development and evaluation,Interspeech 2005,,10.21437/Interspeech.2005-519,https://www.isca-speech.org/archive/interspeech_2005/tomokiyo05_interspeech.html,"This paper addresses the generation and evaluation of foreign-accented speech in concatenative text-to-speech (TTS) synthesis. We describe three possible methods of building a Spanish-accented English voice, and evaluate and compare them with respect to preference, intelligibility, and smoothness. Effects of speaking rate and content are also examined.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,1469-1472,ISCA,en,L2,Interspeech 2005
2010,"Torres, Humberto M.; Mixdorff, Hansjörg; Gurlekian, Jorge A.; Pfitzinger, Hartmut R.",Two new estimation methods for a superpositional intonation model,Interspeech 2010,,10.21437/Interspeech.2010-9,https://www.isca-speech.org/archive/interspeech_2010/torres10_interspeech.html,"This work presents two new approaches for parameter estimation of the superpositional intonation model for German. These approaches introduce linguistic and paralinguistic assumptions allowing the initialization of a previous standard method. Additionally, all restrictions on the conﬁguration of accents were eliminated. The proposed linguistic hypotheses can be based on either tonal or lexical accent, which gives rise to two different estimation methods. These two kind of hypotheses were validated by comparison of the estimation performance relative to two standard methods, one manual and one automatic. The results show that the proposed methods far exceed the performance of the automatic method and are slightly beyond the manual method of reference.",26/09/2010,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,50-53,ISCA,en,prosody,Interspeech 2010
2008,"Torres-Carrasquillo, Pedro A.; Sturim, Douglas E.; Reynolds, Douglas A.; McCree, Alan",Eigen-channel compensation and discriminatively trained Gaussian mixture models for dialect and accent recognition,Interspeech 2008,,10.21437/Interspeech.2008-226,https://www.isca-speech.org/archive/interspeech_2008/torrescarrasquillo08b_interspeech.html,"This paper presents a series of dialect/accent identification results for three sets of dialects with discriminatively trained Gaussian mixture models and feature compensation using eigen-channel decomposition. The classification tasks evaluated in the paper include: 1) the Chinese language classes, 2) American and Indian accented English and 3) discrimination between three Arabic dialects. The first two tasks were evaluated on the 2007 NIST LRE corpus. The Arabic discrimination task was evaluated using data derived from the LDC Arabic set collected by Appen. Analysis is performed for the English accent problem studied and an approach to open set dialect scoring is introduced. The system resulted in equal error rates at or below 10% for each of the tasks studied.",22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,723-726,ISCA,en,L1-or-L2,Interspeech 2008
2010,"Tsurutani, Chiharu",Foreign accent matters most when timing is wrong,Interspeech 2010,,10.21437/Interspeech.2010-536,https://www.isca-speech.org/archive/interspeech_2010/tsurutani10_interspeech.html,"This study aims to investigate native speakers’ perception of prosodic variation of Japanese utterances. The pitch contour above the word level is hard to determine due to individual variation or pragmatic and para-linguistic factors. Nevertheless, native speakers’ intonation is relatively consistent as long as the context and intention of the utterance is predetermined. On the other hand, L2 speakers’ intonation contains some prosodic deviation from the native speakers’ model, and yet some deviations are treated as non-native production and some are not. By identifying the prosodic deviations that are tolerated by native listeners, we will have better understanding of crucial points necessary for the improvement of Japanese pronunciation and the reference for computer-based assessment tools. The study suggests that pitch errors affect the performance score, but not as significantly as do timing errors.",26/09/2010,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,1854-1857,ISCA,en,L2,Interspeech 2010
2018,"Tu, Ming; Grabek, Anna; Liss, Julie; Berisha, Visar",Investigating the Role of L1 in Automatic Pronunciation Evaluation of L2 Speech,Interspeech 2018,,10.21437/Interspeech.2018-1350,https://www.isca-speech.org/archive/interspeech_2018/tu18_interspeech.html,"Automatic pronunciation evaluation plays an important role in pronunciation training and second language education. This ﬁeld draws heavily on concepts from automatic speech recognition (ASR) to quantify how close the pronunciation of nonnative speech is to native-like pronunciation. However, it is known that the formation of accent is related to pronunciation patterns of both the target language (L2) and the speaker’s ﬁrst language (L1). In this paper, we propose to use two native speech acoustic models, one trained on L2 speech and the other trained on L1 speech. We develop two sets of measurements that can be extracted from two acoustic models given accented speech. A new utterance-level feature extraction scheme is used to convert these measurements into a ﬁxed-dimension vector which is used as an input to a statistical model to predict the accentedness of a speaker. On a data set consisting of speakers from 4 different L1 backgrounds, we show that the proposed system yields improved correlation with human evaluators compared to systems only using the L2 acoustic model.",02/09/2018,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,1636-1640,ISCA,en,L2,Interspeech 2018
2020,"Turan, M.A. Tuğtekin; Vincent, Emmanuel; Jouvet, Denis",Achieving Multi-Accent ASR via Unsupervised Acoustic Model Adaptation,Interspeech 2020,,10.21437/Interspeech.2020-2742,https://www.isca-speech.org/archive/interspeech_2020/turan20_interspeech.html,"Current automatic speech recognition (ASR) systems trained on native speech often perform poorly when applied to non-native or accented speech. In this work, we propose to compute xvector-like accent embeddings and use them as auxiliary inputs to an acoustic model trained on native data only in order to improve the recognition of multi-accent data comprising native, non-native, and accented speech. In addition, we leverage untranscribed accented training data by means of semi-supervised learning. Our experiments show that acoustic models trained with the proposed accent embeddings outperform those trained with conventional i-vector or x-vector speaker embeddings, and achieve a 15% relative word error rate (WER) reduction on nonnative and accented speech w.r.t. acoustic models trained with regular spectral features only. Semi-supervised training using just 1 hour of untranscribed speech per accent yields an additional 15% relative WER reduction w.r.t. models trained on native data only.",25/10/2020,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,1286-1290,ISCA,en,L1-or-L2,Interspeech 2020
2014,"Turco, Giuseppina; Delais-Roussarie, Elisabeth",A crosslinguistic and acquisitional perspective on intonational rises in French,Interspeech 2014,,10.21437/Interspeech.2014-547,https://www.isca-speech.org/archive/interspeech_2014/turco14_interspeech.html,"This study compares rising contours produced in the context of contrastive topics by French natives and by low and high proficient learners of French with German as mother tongue. Results show a systematic pattern for French natives who mostly produced a final rise LH*, and hardly ever a bridge accent on the whole phrase. Our results on French natives seem to support earlier claims that tonal patterns with late dip alignments may be recruited for encoding contrast meaning. Results on French learners show a development in the acquisition of the prosody-semantics mapping principles (shifting the accent position from the phrase-initial mon to the phrase-final image) and, not surprisingly, differences in the phonetic implementation of the final rises. Crucially, the impact of phonological and phonetic transfer is more complex than expected: text-to-tune associations are not easy to reprogramme when a new accent location has to be learnt. However, once the phonology is learnt, the phonetic implementation starts being problematic.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,2553-2557,ISCA,en,prosody,Interspeech 2014
2012,"Veilleux, Nanette; Barnes, Jonathan; Brugos, Alejna; Shattuck-Hufnagel, Stefanie",Perceptual foundations for naturalistic variability in the prosody of synthetic speech,Interspeech 2012,,10.21437/Interspeech.2012-656,https://www.isca-speech.org/archive/interspeech_2012/veilleux12_interspeech.html,"Recent studies have shown that the Tonal Center of Gravity is a better classifier than F0 Turning Points for at least two contrastively timed pitch accents in American English intonation contours. Within this framework, a binary F0 weighting function derived from the F0 contour can be used instead of the natural F0 contour without a degradation in discrimination performance. This success has important implications for speech synthesis. Just as we can capture the functional equivalence of a multitude of auditorily distinct F0 contour shapes in terms of their mapping to a single parameter (the TCoG) via a set of binary weighting functions, this same mapping could be run in reverse as a source to generate natural-sounding variability in speech synthesis.",09/09/2012,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,2534-2537,ISCA,en,prosody,Interspeech 2012
2010,"Vergyri, Dimitra; Lamel, Lori; Gauvain, Jean-Luc",Automatic speech recognition of multiple accented English data,Interspeech 2010,,10.21437/Interspeech.2010-477,https://www.isca-speech.org/archive/interspeech_2010/vergyri10_interspeech.html,"Accent variability is an important factor in speech that can signiﬁcantly degrade automatic speech recognition performance. We investigate the effect of multiple accents on an English broadcast news recognition system. A multi-accented English corpus is used for the task, including broadcast news segments from 6 different geographic regions: US, Great Britain, Australia, North Africa, Middle East and India. There is signiﬁcant performance degradation of a baseline system trained on only US data when confronted with shows from other regions. The results improve signiﬁcantly when data from all the regions are included for accent-independent acoustic model training. Further improvements are achieved when MAP-adapted accentdependent models are used in conjunction with a GMM accent classiﬁer.",26/09/2010,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,1652-1655,ISCA,en,L1,Interspeech 2010
2006,"Vieru-Dimulescu, Bianca; Boula de Mareüil, Philippe",Perceptual identification and phonetic analysis of 6 foreign accents in French,Interspeech 2006,,10.21437/Interspeech.2006-142,https://www.isca-speech.org/archive/interspeech_2006/vierudimulescu06_interspeech.html,"A perceptual experiment was designed to determine to what extent naïve French listeners are able to identify foreign accents in French: Arabic, English, German, Italian, Portuguese and Spanish. They succeed in recognizing the speaker’s mother tongue in more than 50% of cases (while rating their degree of accentedness as average). They perform best with Arabic speakers and worst with Portuguese speakers. The Spanish/Italian and English/German accents are the most mistaken ones. Phonetic analyses were conducted; clustering and scaling techniques were applied to the results, and were related to the listeners’ reactions that were recorded during the test. They support the idea that differences in the vowel realization (especially concerning the phoneme /y/) seem to outweigh rhythmic cues.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,paper 1251-Mon2CaP.11-0,ISCA,en,L2,Interspeech 2006
2019,"Viglino, Thibault; Motlicek, Petr; Cernak, Milos",End-to-End Accented Speech Recognition,Interspeech 2019,,10.21437/Interspeech.2019-2122,https://www.isca-speech.org/archive/interspeech_2019/viglino19_interspeech.html,"Correct pronunciation is known to be the most difﬁcult part to acquire for (native or non-native) language learners. The accented speech is thus more variable, and standard Automatic Speech Recognition (ASR) training approaches that rely on intermediate phone alignment might introduce errors during the ASR training. With end-to-end training we could alleviate this problem. In this work, we explore the use of multi-task training and accent embedding in the context of end-to-end ASR trained with the connectionist temporal classiﬁcation loss. Comparing to the baseline developed using conventional ASR framework exploiting time-delay neural networks trained on accented English, we show signiﬁcant relative improvement of about 25% in word error rate. Additional evaluation on unseen accent data yields relative improvements of of 31% and 2% for New Zealand English and Indian English, respectively.",15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:24,2140-2144,ISCA,en,L1-or-L2,Interspeech 2019
,"Viswanathan, Ramya; Paramasivam, Periyasamy; Vepa, Jithendra",Hierarchical Accent Determination and Application in a Large Scale ASR System,,,,,"In deploying Automatic Speech Recognition Systems (ASR) on a global scale, several challenges arise for supporting a widely used language such as English. The primary one among them is to deal with a wide variety of accents. We propose a Hierarchical Accent Determination system that deals with accent variations across large geographical regions at macro level and then the variations at the sub-regions within a selected large geographical region at micro level along with taking context cues. Eight accents [GB, US, Australian, Canadian, Spanish, Korean, Indian & Chinese] are identified at macro level and accent-specific models corresponding to the identified accents are used. The accuracy of the accent identification system is around 80% with ASR as well as using context cues such as phone language and keyboard language. The deployment of the accent identification system has improved the overall accuracy of Speech Recognition system by 10% for accented speech. It is planned to expand the approach to identify accents with significant variations found at subregional level in India such as Hindi, Tamil, Telugu, Malayalam, and Bengali.",,22/02/2023 10:34,22/02/2023 10:34,,,,en,L1-or-L2,
2014,"Vu, Ngoc Thang; Wang, Yuanfan; Klose, Marten; Mihaylova, Zlatka; Schultz, Tanja",Improving ASR performance on non-native speech using multilingual and crosslingual information,Interspeech 2014,,10.21437/Interspeech.2014-3,https://www.isca-speech.org/archive/interspeech_2014/vu14_interspeech.html,"This paper presents our latest investigation of automatic speech recognition (ASR) on non-native speech. We ﬁrst report on a non-native speech corpus - an extension of the GlobalPhone database - which contains English with Bulgarian, Chinese, German and Indian accent and German with Chinese accent. In this case, English is the spoken language (L2) and Bulgarian, Chinese, German and Indian are the mother tongues (L1) of the speakers. Afterwards, we investigate the effect of multilingual acoustic modeling on non-native speech. Our results reveal that a bilingual L1-L2 acoustic model signiﬁcantly improves the ASR performance on non-native speech. For the case that L1 is unknown or L1 data is not available, a multilingual ASR system trained without L1 speech data consistently outperforms the monolingual L2 ASR system. Finally, we propose a method called crosslingual accent adaptation, which allows using English with Chinese accent to improve the German ASR on German with Chinese accent and vice versa. Without using any intra lingual adaptation data, we achieve 15.8% relative improvement in average over the baseline system.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,Nov-15,ISCA,en,L2,Interspeech 2014
2009,"Wagner, Agnieszka",Analysis and recognition of accentual patterns,Interspeech 2009,,10.21437/Interspeech.2009-306,https://www.isca-speech.org/archive/interspeech_2009/wagner09_interspeech.html,"This study proposes a framework of automatic analysis and recognition of accentual patterns. In the first place we present the results of analyses which aimed at identification of acoustic cues signaling prominent syllables and different pitch accent types distinguished at the surface-phonological level. The resulting representation provides a framework of analysis of accentual patterns at the acoustic-phonetic level. The representation is compact - it consists of 13 acoustic features, has low redundancy – the features can not be derived from one another and wide coverage – it encodes distinctions between perceptually different utterances. Next, we train statistical models to automatically determine accentual patterns of utterances using the acoustic-phonetic representation which involves two steps: detection of accentual prominence and assigning pitch accent types to prominent syllables. The efficiency of the best models consists in achieving high accuracy (above 80% on average) using small acoustic feature vectors.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,2427-2430,ISCA,en,prosody,Interspeech 2009
2019,"Wagner, Petra; Bryhadyr, Nataliya; Schröer, Marin",Pitch Accent Trajectories Across Different Conditions of Visibility and Information Structure — Evidence from Spontaneous Dyadic Interaction,Interspeech 2019,,10.21437/Interspeech.2019-1619,https://www.isca-speech.org/archive/interspeech_2019/wagner19_interspeech.html,"Previous research identiﬁed a differential contribution of information structure and the visibility of facial and contextual information to the acoustic-prosodic expression of pitch accents. However, it is unclear whether pitch accent shapes are affected by these conditions as well. To investigate whether varying context cues have a differentiated impact on pitch accent trajectories produced in conversational interaction, we modiﬁed the visibility conditions in a spontaneous dyadic interaction task, i.e. a verbalized version of TicTacToe. Besides varying visibility, the game task allows for measuring the impact of information-structure on pitch accent trajectories, differentiating important and unpredictable game moves. Using GAMMs on four speaker groups (identiﬁed by a cluster analysis), we could isolate varying strategies of prosodic adaptation to contextual change. While few speaker groups showed a reaction to the availability of visible context cues (facial prosody or executed game moves), all groups differentiated the verbalization of unpredictable and predictable game moves with a groupspeciﬁc trajectory adaptation. The importance of game moves resulted in differentiated adaptations in two out of four speaker groups. The detected strategic trajectory adaptations were characterized by different characteristics of boundary tones, adaptations of the global f0-level, or the shape of the corresponding pitch accent.",15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,3985-3989,ISCA,en,prosody,Interspeech 2019
2008,"Walsh, Michael; Schweitzer, Katrin; Möbius, Bernd; Schütze, Hinrich",Examining pitch-accent variability from an exemplar-theoretic perspective,Interspeech 2008,,10.21437/Interspeech.2008-280,https://www.isca-speech.org/archive/interspeech_2008/walsh08_interspeech.html,"This paper presents an exemplar-theoretic account of pitchaccent variability. Results from two experiments are reported. The ﬁrst experiment examines variability / similarity across a range of pitch-accent contour types which vary in frequency of occurrence. The results report similar behaviour across the frequency bins and are indicative of pitch-accent immunity from frequency effects. The second experiment, in order to establish the impact of lexical frequency on pitch-accent production, examines the similarity of pitch-accent contours linked to high and low frequency syllables. The results indicate further autonomy on the part of pitch-accents and offer possible evidence for post-lexical pitch-accent generation.",22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,877-880,ISCA,en,prosody,Interspeech 2008
2013,"Walsh, Michael; Schweitzer, Katrin; Schauffler, Nadja",Exemplar-based pitch accent categorisation using the generalized context model,Interspeech 2013,,10.21437/Interspeech.2013-79,https://www.isca-speech.org/archive/interspeech_2013/walsh13_interspeech.html,"This paper presents the results of a pitch accent categorisation simulation which attempts to classify L*H and H*L accents using a psychologically motivated exemplar-theoretic model of categorisation. Pitch accents are represented in terms of six linguistically meaningful parameters describing their shape. No additional information is employed in the categorisation process. The results indicate that these accents can be successfully categorised, via exemplar-based comparison, using a limited number of purely tonal features.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,258-262,ISCA,en,prosody,Interspeech 2013
2005,"Wang, Hongyan; Heuven, Vincent J. van","Mutual intelligibility of american, Chinese and dutch-accented speakers of English",Interspeech 2005,,10.21437/Interspeech.2005-356,https://www.isca-speech.org/archive/interspeech_2005/wang05f_interspeech.html,"This paper presents the results of a comprehensive study of the mutual intelligibility of Chinese, Dutch (both foreignlanguage learners) and American (native language) speakers of English. Intelligibility is tested at the level of the segment, word and sentence, after careful selection of representative speakers from the three language backgrounds. The results show that production and perception skills are generally correlated at all levels, that both speakers and listeners are more successful in the order Chinese < Dutch < American. Against this background, however, intelligibility is unexpectedly good when speakers and listeners share the same mother tongue.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,2225-2228,ISCA,en,L2,Interspeech 2005
2013,"Wang, Hongyan; Heuven, Vincent J. van","Mutual intelligibility of American, Chinese and Dutch-accented speakers of English tested by SUS and SPIN sentences",Interspeech 2013,,10.21437/Interspeech.2013-129,https://www.isca-speech.org/archive/interspeech_2013/wang13_interspeech.html,"This paper investigates the mutual intelligibility of Chinese, Dutch (both foreign-language learners) and American (native language) speakers of English using SUS (Semantically Unpredictable Sentences) and SPIN (Speech in Noise) materials. We test the hypothesis that speakers and listeners who share the same native-language background have an advantage (interlanguage speech intelligibility benefit).",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,431-435,ISCA,en,L2,Interspeech 2013
2009,"Weber, Frederick; Bali, Kalika",Real voice and TTS accent effects on intelligibility and comprehension for indian speakers of English as a second language,Interspeech 2009,,10.21437/Interspeech.2009-193,https://www.isca-speech.org/archive/interspeech_2009/weber09_interspeech.html,"We investigate the effect of accent on comprehension of English for speakers of English as a second language in southern India. Subjects were exposed to real and TTS voices with US and several Indian accents, and were tested for intelligibility and comprehension. Performance trends indicate a measurable advantage for familiar accents, and are broken down by various demographic factors.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,532-535,ISCA,en,L2,Interspeech 2009
2006,"Wei, Si; Liu, Qing-Sheng; Hu, Yu; Wang, Ren-Hua",Automatic Mandarin pronunciation scoring for native learners with dialect accent,Interspeech 2006,,10.21437/Interspeech.2006-416,https://www.isca-speech.org/archive/interspeech_2006/wei06b_interspeech.html,"This paper studies pronunciation scoring algorithm in CALL system aiming at teaching native Chinese learn standard Mandarin. Most of the pronunciation scoring algorithms focus on non-native environment, which may not be suitable for native speakers. We bring up a new algorithm based on traditional posterior log-likelihood algorithm by weighting the initial part of Mandarin syllables, where final-initial’s duration ratio is introduced to control the weight. Experiments show that the proposed algorithm is much more effective than traditional posterior log-likelihood algorithm in the Mandarin learning system. The correlation with human score achieves an increase of 11%.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,paper 1669-Tue3CaP.8-0,ISCA,en,L1,Interspeech 2006
2019,"Weninger, Felix; Sun, Yang; Park, Junho; Willett, Daniel; Zhan, Puming",Deep Learning Based Mandarin Accent Identification for Accent Robust ASR,Interspeech 2019,,10.21437/Interspeech.2019-2737,https://www.isca-speech.org/archive/interspeech_2019/weninger19_interspeech.html,,15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,510-514,ISCA,en,L1,Interspeech 2019
2009,"White, Michael; Rajkumar, Rajakrishnan; Ito, Kiwako; Speer, Shari R.",Eye tracking for the online evaluation of prosody in speech synthesis: not so fast!,Interspeech 2009,,10.21437/Interspeech.2009-665,https://www.isca-speech.org/archive/interspeech_2009/white09b_interspeech.html,"This paper presents an eye-tracking experiment comparing the processing of different accent patterns in unit selection synthesis and human speech. The synthetic speech results failed to replicate the facilitative effect of contextually appropriate accent patterns found with human speech, while producing a more robust intonational garden-path effect with contextually inappropriate patterns, both of which could be due to processing delays seen with the synthetic speech. As the synthetic speech was of high quality, the results indicate that eye tracking holds promise as a highly sensitive and objective method for the online evaluation of prosody in speech synthesis.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,2523-2526,ISCA,en,prosody,Interspeech 2009
2011,"William, Freddy; Sangwan, Abhijeet; Hansen, John H. L.",Using human perception for automatic accent assessment,Interspeech 2011,,10.21437/Interspeech.2011-642,https://www.isca-speech.org/archive/interspeech_2011/william11_interspeech.html,"In this study, a new algorithm for automatic accent evaluation of native and non-native speakers is presented. The proposed system consists of two main steps: alignment and scoring. At the alignment step, the speech utterance is processed using a Weighted Finite State Transducer (WFST) based technique to automatically estimate the pronunciation errors. Subsequently, in the scoring step a Maximum Entropy (ME) based technique is employed to assign perceptually motivated scores to pronunciation errors. The combination of the two steps yields an approach that measures accent based on perceptual impact of pronunciation errors, and is termed as the Perceptual WFST (P-WFST). The P-WFST is evaluated on American English (AE) spoken by native and non-native (native speakers of Mandarin-Chinese) speakers from the CUAccent corpus. The proposed P-WFST algorithm shows higher and more consistent correlation with human evaluated accent scores, when compared to the Goodness Of Pronunciation (GOP) algorithm.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,2509-2512,ISCA,en,L1-or-L2,Interspeech 2011
2020,"Winata, Genta Indra; Cahyawijaya, Samuel; Liu, Zihan; Lin, Zhaojiang; Madotto, Andrea; Xu, Peng; Fung, Pascale",Learning Fast Adaptation on Cross-Accented Speech Recognition,Interspeech 2020,,10.21437/Interspeech.2020-45,https://www.isca-speech.org/archive/interspeech_2020/winata20_interspeech.html,"Local dialects inﬂuence people to pronounce words of the same language differently from each other. The great variability and complex characteristics of accents create a major challenge for training a robust and accent-agnostic automatic speech recognition (ASR) system. In this paper, we introduce a cross-accented English speech recognition task as a benchmark for measuring the ability of the model to adapt to unseen accents using the existing CommonVoice corpus. We also propose an accent-agnostic approach that extends the model-agnostic metalearning (MAML) algorithm for fast adaptation to unseen accents. Our approach signiﬁcantly outperforms joint training in both zero-shot, few-shot, and all-shot in the mixed-region and cross-region settings in terms of word error rate.",25/10/2020,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,1276-1280,ISCA,en,L1-or-L2,Interspeech 2020
2014,"Windmann, Andreas; Šimko, Juraj; Wagner, Petra",A unified account of prominence effects in an optimization-based model of speech timing,Interspeech 2014,,10.21437/Interspeech.2014-44,https://www.isca-speech.org/archive/interspeech_2014/windmann14_interspeech.html,"We show how our optimization-based model of speech timing reproduces three effects of prosodic prominence on suprasegmental timing patterns in speech: (1), the durational interaction between lexical stress and pitch accent, (2), polysyllabic shortening in pitch-accented words and (3), differential behavior of prominent and non-prominent syllables under speaking rate variation. We review the literature and present model simulations that replicate reported phenomena. Results underline the capacity of our model to provide a uniﬁed account of the temporal organization of speech.",14/09/2014,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,159-163,ISCA,en,prosody,Interspeech 2014
2011,"Witteman, Marijt J.; Weber, Andrea; McQueen, James M.","On the relationship between perceived accentedness, acoustic similarity, and processing difficulty in foreign-accented speech",Interspeech 2011,,10.21437/Interspeech.2011-583,https://www.isca-speech.org/archive/interspeech_2011/witteman11_interspeech.html,"Foreign-accented speech is often perceived as more difficult to understand than native speech. What causes this potential difficulty, however, remains unknown. In the present study, we compared acoustic similarity and accent ratings of American-accented Dutch with a cross-modal priming task designed to measure online speech processing. We focused on two Dutch diphthongs: ui and ij. Though both diphthongs deviated from standard Dutch to varying degrees and perceptually varied in accent strength, native Dutch listeners recognized words containing the diphthongs easily. Thus, not all foreign-accented speech hinders comprehension, and acoustic similarity and perceived accentedness are not always predictive of processing difficulties.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,2229-2232,ISCA,en,L1-or-L2,Interspeech 2011
2013,"Włodarczak, Marcin; Šimko, Juraj; Wagner, Petra",Pitch and duration as a basis for entrainment of overlapped speech onsets,Interspeech 2013,,10.21437/Interspeech.2013-150,https://www.isca-speech.org/archive/interspeech_2013/wodarczak13_interspeech.html,,25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,535-538,ISCA,en,prosody,Interspeech 2013
2006,"Woehrling, Cecile; Boula de Mareüil, Philippe",Identification of regional accents in French: perception and categorization,Interspeech 2006,,10.21437/Interspeech.2006-303,https://www.isca-speech.org/archive/interspeech_2006/woehrling06_interspeech.html,"This article is dedicated to the perceptual identification of French varieties by listeners from the surroundings of Paris and Marseilles. It is based on the geographical localization of about forty speakers from 6 Francophone regions: Normandy, Vendee, Romand Switzerland, Languedoc and the Basque Country. Contrary to the speech type (read or spontaneous speech) and the listeners’ region of origin, the speakers’ degree of accentedness has a major effect and interacts with the speakers’ age. The origin of the oldest speakers (who have the strongest accent according to Paris listeners’ judgments) is better recognized than the origin of the youngest speakers. However confusions are frequent among the Southern varieties. On the whole, three accents can be distinguished (by clustering and multidimensional scaling techniques): Northern French, Southern French and Romand Swiss.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,paper 1261-Wed1A3O.3-0,ISCA,en,L1,Interspeech 2006
2011,"Wollermann, Charlotte; Schade, Ulrich; Schröder, Bernhard",Variation of accent type and of context - influences on pragmatic focus interpretation,Interspeech 2011,,10.21437/Interspeech.2011-404,https://www.isca-speech.org/archive/interspeech_2011/wollermann11_interspeech.html,"We present an empirical study on the variation of accent type and of context on pragmatic focus interpretation. The material was based on audio-recordings of nine German speakers who were instructed to read dialogues with embedded questionanswer pairs in which the answers constituted the pragmatic focus of the utterance. Different accent types occurred for marking the focus constituent. The audio-material was presented to 53 subjects. Interpretation was tested by using pictures intended to illustrate the (non-)exhaustive reading. When presenting the picture illustrating the non-exhaustive reading, the results show in general a signiﬁcant inﬂuence of both context and prosody, but the contextual inﬂuence is stronger.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,1077-1080,ISCA,en,prosody,Interspeech 2011
2005,"Wu, Tingyao; Compernolle, Dirk Van; Duchateau, Jacques; Yang, Qian; Martens, Jean-Pierre",Improving the discrimination between native accents when recorded over different channels,Interspeech 2005,,10.21437/Interspeech.2005-714,https://www.isca-speech.org/archive/interspeech_2005/wu05c_interspeech.html,"Acoustic differences between native accents may prove to be too subtle for straightforward brute force techniques such as blindly clustered Gaussian mixture model (GMM) classiﬁers to yield satisfactory discrimination performance while these methods work well for classifying more pronounced differences such as language, gender or channel. In this paper it is shown that small channel differences are easier to detect by such coarse classiﬁers than native accent differences. Performance of native accent classiﬁcation can be improved considerably by incorporating the knowledge of the underlying phoneme sequence and using phoneme speciﬁc GMMs. Further improvements are obtained if optimal feature selection is combined with the phoneme dependent GMMs, resulting in usage of less than 10% of the original features. The presented methods result in a reduction of more than 40% in relative error rate in a 5-class classiﬁcation task.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,2821-2824,ISCA,en,L2,Interspeech 2005
2008,"Wu, Tingyao; Karsmakers, Peter; Van hamme, Hugo; Compernolle, Dirk Van",Comparison of variable selection methods and classifiers for native accent identification,Interspeech 2008,,10.21437/Interspeech.2008-140,https://www.isca-speech.org/archive/interspeech_2008/wu08_interspeech.html,"Acoustic differences are so subtle in a native accent identiﬁcation (AID) task that a brute force frame-based Gaussian Mixture Model (GMM) fails to discover the tiny distinctions [1]. Apart from the frame-based framework, in this paper we propose a vector-based speaker modeling method, to which common support vector machine (SVM) kernels can be applied. The vector-based speaker model is composed of the concatenation of the average acoustic representations of all phonemes. SVM and GMM classiﬁers are compared on the speaker models. Moreover, based on the observation that accents only differ in a limited number of phonemes, a variable selection framework is indispensable to select accent relevant features. We investigate a forward selection method, Analysis of Variance (ANOVA) , and a backward selection method, SVM - Recursive Feature Elimination (SVM-RFE). We ﬁnd that the multiclass SVM-RFE achieves comparable performance with the ANOVA on optimally selected variable sets, while it obtains excellent performance with very few features in low dimensions. Results demonstrate the effectiveness of the proposed speaker models together with the SVM classiﬁer both in low dimensions and in high dimensions as well as the necessity of variable selection.",22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,305-308,ISCA,en,L1,Interspeech 2008
2004,"Yan, Qin; Vaseghi, Saeed; Rentzos, Dimitrios; Ho, Ching-Hsiang","Modelling and ranking of differences across formants of british, australian and american accents",Interspeech 2004,,10.21437/Interspeech.2004-207,https://www.isca-speech.org/archive/interspeech_2004/yan04_interspeech.html,"The differences between formants of British, Australian and American English accents are analysed and ranked. An improved formant model based on linear prediction (LP) feature analysis and a two-dimensional(2D) hidden Markov model (HMM) of formants is employed for estimation of the formant frequencies and bandwidths of vowels and diphthongs. Comparative analysis of the formant trajectories, the formant target points and the bandwidth of the spectral resonance at formants of British, Australian and American accents are presented. British vowels and diphthongs have smaller formant bandwidth than Australian. A method for ranking the contribution of different formants in conveying an accent is proposed whereby formants are ranked according to the normalized distances between the formants across accents. The first two formants are considered more sensitive to accents than other formants.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,509-512,ISCA,en,L1; def,Interspeech 2004
2010,"Yanagisawa, Kayoko; Huckvale, Mark",A phonetic alternative to cross-language voice conversion in a text-dependent context: evaluation of speaker identity,Interspeech 2010,,10.21437/Interspeech.2010-593,https://www.isca-speech.org/archive/interspeech_2010/yanagisawa10_interspeech.html,"Spoken language conversion (SLC) aims to generate utterances in the voice of a speaker but in a language unknown to them, using speech synthesis systems and speech processing techniques. Previous approaches to SLC have been based on cross-language voice conversion (VC), which has underlying assumptions that ignore phonetic and phonological differences between languages, leading to a reduction in intelligibility of the output. Accent morphing (AM) was proposed as an alternative approach, and its intelligibility performance was investigated in a previous study. AM attempts to preserve the voice characteristics of the target speaker whilst modifying their accent, using phonetic knowledge obtained from a native speaker of the target language. This paper examines AM and VC in terms of how similar the output sounds like the target speaker. AM achieved similarity ratings at least equivalent to VC, but the study highlighted various difﬁculties in evaluating speaker identity in a SLC context.",26/09/2010,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,2150-2153,ISCA,en,L1-or-L2,Interspeech 2010
2022,"Yang, Mu; Hirschi, Kevin; Looney, Stephen Daniel; Kang, Okim; Hansen, John H.L.",Improving Mispronunciation Detection with Wav2vec2-based Momentum Pseudo-Labeling for Accentedness and Intelligibility Assessment,Interspeech 2022,,10.21437/Interspeech.2022-11039,https://www.isca-speech.org/archive/interspeech_2022/yang22v_interspeech.html,"Current leading mispronunciation detection and diagnosis (MDD) systems achieve promising performance via end-to-end phoneme recognition. One challenge of such end-to-end solutions is the scarcity of human-annotated phonemes on natural L2 speech. In this work, we leverage unlabeled L2 speech via a pseudo-labeling (PL) procedure and extend the fine-tuning approach based on pre-trained self-supervised learning (SSL) models. Specifically, we use Wav2vec 2.0 as our SSL model, and fine-tune it using original labeled L2 speech samples plus the created pseudo-labeled L2 speech samples. Our pseudo labels are dynamic and are produced by an ensemble of the online model on-the-fly, which ensures that our model is robust to pseudo label noise. We show that fine-tuning with pseudo labels achieves a 5.35% phoneme error rate reduction and 2.48% MDD F1 score improvement over a labeled-samples-only finetuning baseline. The proposed PL method is also shown to outperform conventional offline PL methods. Compared to the state-of-the-art MDD systems, our MDD solution produces a more accurate and consistent phonetic error diagnosis. In addition, we conduct an open test on a separate UTD-4Accents dataset, where our system recognition outputs show a strong correlation with human perception, based on accentedness and intelligibility.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:25,4481-4485,ISCA,en,L2,Interspeech 2022
2010,"Yanushevskaya, Irena; Gobl, Christer; Kane, John; Ní Chasaide, Ailbhe",An exploration of voice source correlates of focus,Interspeech 2010,,10.21437/Interspeech.2010-198,https://www.isca-speech.org/archive/interspeech_2010/yanushevskaya10_interspeech.html,"This pilot study explores how the voice source parameters vary in focally accented syllables. It examines the dynamics of the voice source parameters in an all-voiced short declarative utterance in which the focus placement was varied. The voice source parameters F0, EE, UP, OQ, RG, RA, RK and RD were obtained through inverse filtering and subsequent parameterisation using the LF-model. The results suggest that the focally accented syllables are marked not only by increased F0 but also by boosted EE, RG and UP. The non-focal realisations show reduced values for the above parameters along with a tendency towards higher OQ values, suggesting a more lax mode of phonation.",26/09/2010,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,462-465,ISCA,en,prosody,Interspeech 2010
2016,"Yanushevskaya, Irena; Murphy, Andy; Gobl, Christer; Chasaide, Ailbhe Ní",Perceptual Salience of Voice Source Parameters in Signaling Focal Prominence,Interspeech 2016,,10.21437/Interspeech.2016-1160,https://www.isca-speech.org/archive/interspeech_2016/yanushevskaya16_interspeech.html,"This paper describes listening tests investigating the perceptual role of voice source parameters (other than F0) in signaling focal prominence. Synthesized stimuli were constructed on the basis of an inverse filtered utterance ‘We were away a year ago’. Voice source parameters were manipulated in the two potentially accentable syllables WAY and YEAR (in terms of the absolute magnitude and alignment of peaks) and to provide source deaccentuation of post-focal material. Participants in the first listening test were asked to decide whether the syllable WAY, YEAR or neither was deemed the most prominent: judgments on the degree of prominence and naturalness were also indicated on a continuous visual analogue scale. In the second test listeners indicated the degree of prominence for every syllable in the phrase. For WAY, voice source manipulations can cue focal accentuation, and both the magnitude of the source manipulation of the syllable and the presence of source deaccentuation contribute to the effect. However, for YEAR, listeners’ perception of focal accentuation tended to show relatively minor increases in perceived prominence regardless of the source manipulations involved. It therefore appears that the source expression of focus is sensitive to the location of focus in the intonational phrase.",08/09/2016,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,3161-3165,ISCA,en,prosody,Interspeech 2016
2017,"Yanushevskaya, Irena; Chasaide, Ailbhe Ní; Gobl, Christer",Cross-Speaker Variation in Voice Source Correlates of Focus and Deaccentuation,Interspeech 2017,,10.21437/Interspeech.2017-1535,https://www.isca-speech.org/archive/interspeech_2017/yanushevskaya17_interspeech.html,"This paper describes cross-speaker variation in the voice source correlates of focal accentuation and deaccentuation. A set of utterances with varied narrow focus placement as well as broad focus and deaccented renditions were produced by six speakers of English. These were manually inverse filtered and parameterized on a pulse-by-pulse basis using the LF source model. Z-normalized F0, EE, OQ and RD parameters (selected through correlation and factor analysis) were used to generate speaker specific baseline voice profiles and to explore cross-speaker variation in focal and non-focal (post- and prefocal) syllables. As expected, source parameter values were found to differ in the focal and postfocal portions of the utterance. For four of the six speakers the measures revealed a trend of tenser phonation on the focal syllable (an increase in EE and F0 and typically, a decrease in OQ and RD) as well as increased laxness in the postfocal part of the utterance. For two of the speakers, however, the measurements showed a different trend. These speakers had very high F0 and often high EE on the focal accent. In these cases, RD and OQ values tended to be raised rather than lowered. The possible reasons for these differences are discussed.",20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,1034-1038,ISCA,en,prosody,Interspeech 2017
2005,"Yeou, Mohamed",Variability of F0 peak alignment in moroccan Arabic accentual focus,Interspeech 2005,,10.21437/Interspeech.2005-510,https://www.isca-speech.org/archive/interspeech_2005/yeou05_interspeech.html,"The present paper examines how phonetic duration due to syllable structure contributes to the alignment of F0 peaks in Moroccan Arabic. The F0 peak occurs within but near the end of the accented syllable if the vowel is phonetically long due its occurrence in a final CVC. If the accented vowel is phonetically short as in a penultimate CV, the F0 peak is aligned after the accented syllable.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,1433-1436,ISCA,en,prosody,Interspeech 2005
2013,"Ying, Jia; Shaw, Jason A.; Best, Catherine T.",L2 English learners' recognition of words spoken in familiar versus unfamiliar English accents,Interspeech 2013,,10.21437/Interspeech.2013-500,https://www.isca-speech.org/archive/interspeech_2013/ying13_interspeech.html,"How do L2 learners cope with L2 accent variation? We developed predictions based upon the Perceptual Assimilation Model-L2 (PAM-L2) and tested them in an eye-tracking experiment using the visual world paradigm. L2-English learners in Australia with Chinese L1 were presented with words spoken in familiar Australian-accented English (AusE), and two unfamiliar accents: Jamaican Mesolect English (JaME) and Cockney-accented English (CknE). AusE and JaME differ primarily in vowel pronunciations, while CknE differs primarily in consonant pronunciations. Words were selected to elicit two types of perceptual assimilations of JaME and CknE phonemes to AusE: Category Goodness (CG) and Category Shifting (CS) assimilations. The Perceptual Assimilation Model (PAM) predicts that, if the L2 learners have developed AusE categories, then CS differences should hinder spoken word recognition more than CG differences. Our results supported this prediction. For both unfamiliar accents, CS target words attracted more fixations to printed competitor words than did CG distracters.",25/08/2013,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,2108-2112,ISCA,en,L2,Interspeech 2013
2004,"Yoon, Kyuchul",A prosodic phrasing model for a Korean text-to-speech synthesis system,Interspeech 2004,,10.21437/Interspeech.2004-463,https://www.isca-speech.org/archive/interspeech_2004/yoon04_interspeech.html,,04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,1873-1876,ISCA,en,prosody,Interspeech 2004
2004,"Yoon, Tae-Jin; Chavarria, Sandra; Cole, Jennifer; Hasegawa-Johnson, Mark",Intertranscriber reliability of prosodic labeling on telephone conversation using toBI,Interspeech 2004,,10.21437/Interspeech.2004-659,https://www.isca-speech.org/archive/interspeech_2004/yoon04b_interspeech.html,"Two transcribers have labeled prosodic events independently on a subset of Switchboard corpus using adapted ToBI (TOnes and Break Indices) system. Transcriptions of two types of pitch accents (H* and L*), phrasal accents (H- and L-) and boundary tones (H% and L%) encoded independently by two transcribers are compared for intertranscriber reliability. Two commonly used methods of reliability measurement, ‘transcriber-pair-word’ comparison and kappa statistic, are used for comparison with previous reports on the intertranscriber consistency. The results obtained from transcriber-pair-word comparison are: The overall agreement on the presence or absence and choice of pitch accent is 86.57%. The agreement on the presence or absence and the choice of phrasal accent is 85.63%. The presence and choice of boundary tone is 89.33%. When both transcribers agreed that there is at least a phrasal tone, the agreement on the choice of the type of either phrasal accent or boundary tone is 73.86%. The kappa coefﬁcient of agreement (K) of 0.7 to 1 indicates the degree of reliability to be from good to perfect. A kappa coefﬁcient of 0.75 is obtained for agreement on the presence or absence of pitch accents, 0.67 for the presence of phrasal accents, and 0.61 for the strength of disjuncture between phrasal accent and boundary tone. Comparison of the present results with those of previous reliability studies [1][2][3][4] suggests that some higher agreement rates for this study may result from our adoption of fewer labeling distinctions in the transcription of pitch accent events. The results for phrase boundary labeling suggest that spontaneous speech of the type found in the Switchboard corpus is harder to code for the degree of disjuncture between prosodic domains than is read speech.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,2729-2732,ISCA,en,prosody,Interspeech 2004
2004,"Yoshida, Kenji",Spread of high tone in akita Japanese,Interspeech 2004,,10.21437/Interspeech.2004-83,https://www.isca-speech.org/archive/interspeech_2004/yoshida04_interspeech.html,"The present study explores the phonetic implementation of accentual H(igh) tone of the Akita dialect of Japanese, specifically its timing control. Lexical accent in the dialect is implemented as an eminence in F0. The conspicuous feature is that F0 does not fall sharply as in Tokyo Japanese. Two hypotheses are examined concerning the extent of the duration of the pitch summit. One is that the H lasts for some fixed period of time. The other is that it lasts until some prosodic edge appears. An experimental study was performed for two native speakers of Akita, with a speaker of Tokyo dialect. The comparison elucidates the conspicuous characteristics of the phonetic implementation of the lexical accent differing from Tokyo Japanese. The result grossly supports the latter hypothesis. It suggests that the H tone in the dialect is phonetically implemented so that it lasts until the end of a Intonational Phrase.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,1321-1324,ISCA,en,prosody,Interspeech 2004
2005,"You, Hong; Alwan, Abeer; Kazemzadeh, Abe; Narayanan, Shrikanth",Pronunciation variations of Spanish-accented English spoken by young children,Interspeech 2005,,10.21437/Interspeech.2005-349,https://www.isca-speech.org/archive/interspeech_2005/you05_interspeech.html,"When learning to speak English, non-native speakers may pronounce some English phonemes differently from native speakers. These pronunciation variations can degrade an automatic speech recognition system’s performance on accented English. This paper is a ﬁrst attempt to ﬁnd common pronunciation variations in Spanishaccented English as spoken by young children. The analysis of pronunciation variation is performed using dynamic programming-based transcription alignment on 4500 words spoken by children 5-7 years old whose ﬁrst language is Spanish. The ﬁndings are then compared with linguistic hypotheses.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,749-752,ISCA,en,L2,Interspeech 2005
2005,"Yuan, Jiahong; Brenier, Jason M.; Jurafsky, Daniel",Pitch accent prediction: effects of genre and speaker,Interspeech 2005,,10.21437/Interspeech.2005-504,https://www.isca-speech.org/archive/interspeech_2005/yuan05_interspeech.html,"To build a robust pitch accent prediction system, we need to understand the effects of speech genre and speaker variation. This paper reports our studies on genre and speaker variation in pitch accent placement and their effects on automatic pitch accent prediction. We find some interesting accentuation pattern differences that can be attributed to speech genre, and a set of textual features that are robust to genre in accent prediction. We also find that although there is significant variation among speakers in pitch accent placement, speaker dependent models are not needed in accent prediction. Finally, we show that after taking speaker variation into account, there is little room to improve for state-of-the-art classifiers on read news speech.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,1409-1412,ISCA,en,prosody,Interspeech 2005
,"Yuan, Jiahong",Linguistic Rhythm in Foreign Accent,,,,,"This study investigates the influence of L1 on L2 with respect to linguistic rhythm. The L2 English of French, German, Italian, Russian, and Spanish speakers is compared with L1 English. The results show that the linguistic rhythm of L1 transfers to L2. Compared to L1 English, L2 English has shorter stressed vowels but longer reduced vowel. Stressed vowels in the L2 English of stress-timed languages have a higher pitch contour than those in the L2 English of syllabletimed languages.",,22/02/2023 10:34,22/02/2023 10:34,,,,en,L2,
2015,"Zahner, Katharina; Pohl, Muna; Braun, Bettina",Pitch accent distribution in German infant-directed speech,Interspeech 2015,,10.21437/Interspeech.2015-10,https://www.isca-speech.org/archive/interspeech_2015/zahner15_interspeech.html,"Infant-directed speech exhibits slower speech rate, higher pitch and larger f0 excursions than adult-directed speech. Apart from these phonetic properties established in many languages, little is known on the intonational phonological structure in individual languages, i.e. pitch accents and boundary tones and their frequency distribution. Here, we investigated the intonation of infant-directed speech in German. We extracted all turns from the CHILDES database directed towards infants younger than one year (n=585). Two annotators labeled pitch accents and boundary tones according to the autosegmental-metrical intonation system GToBI. Additionally, the tonal movement surrounding the accentual syllable was analyzed. Main results showed a) that 45% of the words carried a pitch accent, b) that phrases ending in a low tone were most frequent, c) that H* accents were generally more frequent than L* accents, d) that H*, L+H* and L* are the most frequent pitch accent types in IDS, and e) that a pattern consisting of an accentual low-pitched syllable preceded by a low tone and followed by a rise or a high tone constitutes the most frequent single pattern. The analyses reveal that the IDS intonational properties lead to a speech style with many tonal alternations, particularly in the vicinity of accented syllables.",06/09/2015,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,46-50,ISCA,en,prosody,Interspeech 2015
2017,"Zahner, Katharina; Kember, Heather; Braun, Bettina",Mind the Peak: When Museum is Temporarily Understood as Musical in Australian English,Interspeech 2017,,10.21437/Interspeech.2017-839,https://www.isca-speech.org/archive/interspeech_2017/zahner17_interspeech.html,"Intonation languages signal pragmatic functions (e.g. information structure) by means of different pitch accent types. Acoustically, pitch accent types differ in the alignment of pitch peaks (and valleys) in regard to stressed syllables, which makes the position of pitch peaks an unreliable cue to lexical stress (even though pitch peaks and lexical stress often coincide in intonation languages). We here investigate the effect of pitch accent type on lexical activation in English. Results of a visual-world eye-tracking study show that Australian English listeners temporarily activate SWW-words (musical) if presented with WSW-words (museum) with earlypeak accents (H+!H*), compared to medial-peak accents (L+H*). Thus, in addition to signalling pragmatic functions, the alignment of tonal targets immediately affects lexical activation in English.",20/08/2017,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,1223-1227,ISCA,en,prosody,Interspeech 2017
2022,"Zeng, Qingcheng; Chong, Dading; Zhou, Peilin; Yang, Jie",Low-resource Accent Classification in Geographically-proximate Settings: A Forensic and Sociophonetics Perspective,Interspeech 2022,,10.21437/Interspeech.2022-11372,https://www.isca-speech.org/archive/interspeech_2022/zeng22b_interspeech.html,"Accented speech recognition and accent classification are relatively under-explored research areas in speech technology. Recently, deep learning-based methods and Transformer-based pretrained models have achieved superb performances in both areas. However, most accent classification tasks focused on classifying different kinds of English accents and little attention was paid to geographically-proximate accent classification, especially under a low-resource setting where forensic speech science tasks usually encounter. In this paper, we explored three main accent modelling methods combined with two different classifiers based on 105 speaker recordings retrieved from five urban varieties in Northern England. Although speech representations generated from pretrained models generally have better performances in downstream classification, traditional methods like Mel Frequency Cepstral Coefficients (MFCCs) and formant measurements are equipped with specific strengths. These results suggest that in forensic phonetics scenario where data are relatively scarce, a simple modelling method and classifier could be competitive with state-of-the-art pretrained speech models as feature extractors, which could enhance a sooner estimation for the accent information in practices. Besides, our findings also cross-validated a new methodology in quantifying sociophonetic changes.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,5308-5312,ISCA,en,L1-or-L2,Interspeech 2022
2006,"Zhang, Chi; Wu, Ji; Xiao, Xi; Wang, Zuoying",Pronunciation variation modeling for Mandarin with accent,Interspeech 2006,,10.21437/Interspeech.2006-246,https://www.isca-speech.org/archive/interspeech_2006/zhang06d_interspeech.html,"In order to solve the problem of the performance decrease when state-of-art automatic speech recognition (ASR) system facing accent speech, we propose the Pronunciation Variation Model (PVM). Two approaches are proposed to construct the PVM in this paper. 6.38% and 7.78% relative error rate reduction is achieved for Shanghai and Wuhan accent mandarin, respectively. The experiment on these two typical accent mandarin shows it is a possible way to deal with accent speech.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,paper 1849-Mon3FoP.5-0,ISCA,en,L1,Interspeech 2006
2021,"Zhang, Jicheng; Peng, Yizhou; Pham, Van Tung; Xu, Haihua; Huang, Hao; Chng, Eng Siong",E2E-Based Multi-Task Learning Approach to Joint Speech and Accent Recognition,Interspeech 2021,,10.21437/Interspeech.2021-1495,https://www.isca-speech.org/archive/interspeech_2021/zhang21j_interspeech.html,"In this paper, we propose a single multi-task learning framework to perform End-to-End (E2E) speech recognition (ASR) and accent recognition (AR) simultaneously. The proposed framework is not only more compact but can also yield comparable or even better results than standalone systems. Speciﬁcally, we found that the overall performance is predominantly determined by the ASR task, and the E2E-based ASR pretraining is essential to achieve improved performance, particularly for the AR task. Additionally, we conduct several analyses of the proposed method. First, though the objective loss for the AR task is much smaller compared with its counterpart of ASR task, a smaller weighting factor with the AR task in the joint objective function is necessary to yield better results for each task. Second, we found that sharing only a few layers of the encoder yields better AR results than sharing the overall encoder. Experimentally, the proposed method produces WER results close to the best standalone E2E ASR ones, while it achieves 7.7% and 4.2% relative improvement over standalone and single-task-based joint recognition methods on test set for accent recognition respectively.",30/08/2021,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,1519-1523,ISCA,en,L1-or-L2,Interspeech 2021
2022,"Zhang, Yuanyuan; Zhang, Yixuan; Halpern, Bence; Patel, Tanvina; Scharenborg, Odette",Mitigating bias against non-native accents,Interspeech 2022,,10.21437/Interspeech.2022-836,https://www.isca-speech.org/archive/interspeech_2022/zhang22n_interspeech.html,"Automatic speech recognition (ASR) systems have seen substantial improvements in the past decade; however, not for all speaker groups. Recent research shows that bias exists against different types of speech, including non-native accents, in stateof-the-art (SOTA) ASR systems. To attain inclusive speech recognition, i.e., ASR for everyone irrespective of how one speaks or the accent one has, bias mitigation is necessary. Here we focus on bias mitigation against non-native accents using two different approaches: data augmentation and by using more effective training methods. We used an autoencoderbased cross-lingual voice conversion (VC) model to increase the amount of non-native accented speech training data in addition to data augmentation through speed perturbation. Moreover, we investigate two training methods, i.e., fine-tuning and domain adversarial training (DAT), to see whether they can use the limited non-native accented speech data more effectively than a standard training approach. Experimental results show that VCbased data augmentation successfully mitigates the bias against non-native accents for the SOTA end-to-end (E2E) Dutch ASR system. Combining VC and speed perturbed data gave the lowest word error rate (WER) and the smallest bias against nonnative accents. Fine-tuning and DAT reduced the bias against non-native accents but at the cost of native performance.",18/09/2022,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,3168-3172,ISCA,en,L2,Interspeech 2022
2018,"Zhao, Guanlong; Sonsaat, Sinem; Silpachai, Alif; Lucic, Ivana; Chukharev-Hudilainen, Evgeny; Levis, John; Gutierrez-Osuna, Ricardo",L2-ARCTIC: A Non-native English Speech Corpus,Interspeech 2018,,10.21437/Interspeech.2018-1110,https://www.isca-speech.org/archive/interspeech_2018/zhao18b_interspeech.html,"In this paper, we introduce L2-ARCTIC, a speech corpus of non-native English that is intended for research in voice conversion, accent conversion, and mispronunciation detection. This initial release includes recordings from ten non-native speakers of English whose first languages (L1s) are Hindi, Korean, Mandarin, Spanish, and Arabic, each L1 containing recordings from one male and one female speaker. Each speaker recorded approximately one hour of read speech from the Carnegie Mellon University ARCTIC prompts, from which we generated orthographic and forced-aligned phonetic transcriptions. In addition, we manually annotated 150 utterances per speaker to identify three types of mispronunciation errors: substitutions, deletions, and additions, making it a valuable resource not only for research in voice conversion and accent conversion but also in computer-assisted pronunciation training. The corpus is publicly accessible at https://psi.engr.tamu.edu/l2-arctic-corpus/.",02/09/2018,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,2783-2787,ISCA,en,L2,Interspeech 2018
2019,"Zhao, Guanlong; Ding, Shaojin; Gutierrez-Osuna, Ricardo",Foreign Accent Conversion by Synthesizing Speech from Phonetic Posteriorgrams,Interspeech 2019,,10.21437/Interspeech.2019-1778,https://www.isca-speech.org/archive/interspeech_2019/zhao19f_interspeech.html,"Methods for foreign accent conversion (FAC) aim to generate speech that sounds similar to a given non-native speaker but with the accent of a native speaker. Conventional FAC methods borrow excitation information (F0 and aperiodicity; produced by a conventional vocoder) from a reference (i.e., native) utterance during synthesis time. As such, the generated speech retains some aspects of the voice quality of the native speaker. We present a framework for FAC that eliminates the need for conventional vocoders (e.g., STRAIGHT, World) and therefore the need to use the native speaker’s excitation. Our approach uses an acoustic model trained on a native speech corpus to extract speaker-independent phonetic posteriorgrams (PPGs), and then train a speech synthesizer to map PPGs from the non-native speaker into the corresponding spectral features, which in turn are converted into the audio waveform using a high-quality neural vocoder. At runtime, we drive the synthesizer with the PPG extracted from a native reference utterance. Listening tests show that the proposed system produces speech that sounds more clear, natural, and similar to the non-native speaker compared with a baseline system, while significantly reducing the perceived foreign accent of nonnative utterances.",15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,2843-2847,ISCA,en,L2,Interspeech 2019
2005,"Zheng, Yanli; Sproat, Richard; Gu, Liang; Shafran, Izhak; Zhou, Haolang; Su, Yi; Jurafsky, Daniel; Starr, Rebecca; Yoon, Su-Youn",Accent detection and speech recognition for Shanghai-accented Mandarin,Interspeech 2005,,10.21437/Interspeech.2005-112,https://www.isca-speech.org/archive/interspeech_2005/zheng05_interspeech.html,"As speech recognition systems are used in ever more applications, it is crucial for the systems to be able to deal with accented speakers. Various techniques, such as acoustic model adaptation and pronunciation adaptation, have been reported to improve the recognition of non-native or accented speech. In this paper, we propose a new approach that combines accent detection, accent discriminative acoustic features, acoustic adaptation and model selection for accented Chinese speech recognition. Experimental results show that this approach can improve the recognition of accented speech.",04/09/2005,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,217-220,ISCA,en,L1; def,Interspeech 2005
2011,"Zheng, Rong; Zhang, Ce; Xu, Bo",Data-driven UBM generation via tied Gaussians for GMM-supervector based accent identification,Interspeech 2011,,10.21437/Interspeech.2011-325,https://www.isca-speech.org/archive/interspeech_2011/zheng11b_interspeech.html,"This paper presents a new approach to exploit data-driven universal background model (UBM) generation using tied Gaussians for accent identification (AID). The motivation of the proposed algorithm is to potentially utilize broad phoneticspecific accent characteristics by Gaussian mixture model (GMM) and examine data-driven phonetically-inspired UBM creation for GMM-supervector based accent classification. In this work, we discuss the issues involved in applying cumulative posterior probability based Gaussian selection and tree structure based UBM parameter estimation. Derivation and validation of the UBM refined by tied Gaussians are reported in this paper. Performance evaluations comparing our system with other well-known techniques for AID are also provided. Better performance is further achieved by fusing these acoustic-based accent classifiers. Comparison experiments conducted on the CSLU foreign-accented English (FAE) dataset show the effectiveness of the proposed method.",27/08/2011,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,845-848,ISCA,en,L1-or-L2,Interspeech 2011
2016,"Zheng, Hao; Zhang, Shanshan; Qiao, Liwei; Li, Jianping; Liu, Wenju",Improving Large Vocabulary Accented Mandarin Speech Recognition with Attribute-Based I-Vectors,Interspeech 2016,,10.21437/Interspeech.2016-378,https://www.isca-speech.org/archive/interspeech_2016/zheng16b_interspeech.html,"It has been well-recognized that the accent has a great impact on the ASR of Chinese Mandarin, therefore, how to improve the performance on the accented speech has become a critical issue in this ﬁeld. The attribute feature has been proven effective on modelling accented speech, resulting in a signiﬁcantly improved performance in accent recognition. In this paper, we propose an attribute-based i-vector to improve the performance of speech recognition system on large vocabulary accented Mandarine speech task. The system with proposed attribute features works well especially with sufﬁcient training data. To further promote the performance on conditions such as resource limited condition or training data mismatched condition, we also develop Multi-Task Learning Deep Neural Networks (MTLDNNs) with attribute classiﬁcation as the secondary task to improve the discriminative ability on Mandarin speech. Experiments on the 450-hour Intel accented Mandarin speech corpus demonstrate that the system with attribute-based i-vectors achieves a signiﬁcant performance improvement on sufﬁcient training data compared with the baseline DNN-HMM system. The MTL-DNNs complement the shortage of attribute-based ivectors on data limited and mismatched conditions and obtain obvious CER reductions.",08/09/2016,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,3454-3458,ISCA,en,L1,Interspeech 2016
2010,"Zhu, Taotao; Ke, Dengfeng; Chen, Zhenbiao; Xu, Bo",A new approach for automatic tone error detection in strong accented Mandarin based on dominant set,Interspeech 2010,,10.21437/Interspeech.2010-283,https://www.isca-speech.org/archive/interspeech_2010/zhu10b_interspeech.html,"In this paper, we proposed a new approach based on dominant set [1] for tone error detection in strong accented Mandarin. First, the ﬁnal boundary generated from forced alignment is regulated by the F0 contour in order to locate the ﬁnal domain more accurately. After that, proper normalization techniques are explored for the tone features. Finally, clustering and classiﬁcation methods based on dominant set are utilized for the tone error detection. The proposed approach is tested in comparison with the traditional k-means based method, experimental results show that it achieves more satisfying performance with an average Cross-Correlation 0.84 between human and machine, reaches to that between humans, which have veriﬁed the effectiveness of the proposed approach. The main advantage of this approach lies in not only the error pronunciation of tone can be well identiﬁed, but also the F0 pattern of the tone error can be informatively provided as the feedback.",26/09/2010,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:26,777-780,ISCA,en,L1,Interspeech 2010
2019,"Zhu, Han; Wang, Li; Zhang, Pengyuan; Yan, Yonghong",Multi-Accent Adaptation Based on Gate Mechanism,Interspeech 2019,,10.21437/Interspeech.2019-3155,https://www.isca-speech.org/archive/interspeech_2019/zhu19_interspeech.html,"When only a limited amount of accented speech data is available, to promote multi-accent speech recognition performance, the conventional approach is accent-speciﬁc adaptation, which adapts the baseline model to multiple target accents independently. To simplify the adaptation procedure, we explore adapting the baseline model to multiple target accents simultaneously with multi-accent mixed data. Thus, we propose using accent-speciﬁc top layer with gate mechanism (AST-G) to realize multi-accent adaptation. Compared with the baseline model and accent-speciﬁc adaptation, AST-G achieves 9.8% and 1.9% average relative WER reduction respectively. However, in realworld applications, we can’t obtain the accent category label for inference in advance. Therefore, we apply using an accent classiﬁer to predict the accent label. To jointly train the acoustic model and the accent classiﬁer, we propose the multi-task learning with gate mechanism (MTL-G). As the accent label prediction could be inaccurate, it performs worse than the accentspeciﬁc adaptation. Yet, in comparison with the baseline model, MTL-G achieves 5.1% average relative WER reduction.",15/09/2019,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:27,744-748,ISCA,en,L1-or-L2,Interspeech 2019
2020,"Zuluaga-Gomez, Juan; Motlicek, Petr; Zhan, Qingran; Veselý, Karel; Braun, Rudolf",Automatic Speech Recognition Benchmark for Air-Traffic Communications,Interspeech 2020,,10.21437/Interspeech.2020-2173,https://www.isca-speech.org/archive/interspeech_2020/zuluagagomez20_interspeech.html,"Advances in Automatic Speech Recognition (ASR) over the last decade opened new areas of speech-based automation such as in Air-Trafﬁc Control (ATC) environments. Currently, voice communication and data links communications are the only way of contact between pilots and Air-Trafﬁc Controllers (ATCo), where the former is the most widely used and the latter is a non-spoken method mandatory for oceanic messages and limited for some domestic issues. ASR systems on ATCo environments inherit increasing complexity due to accents from nonEnglish speakers, cockpit noise, speaker-dependent biases and small in-domain ATC databases for training. Hereby, we introduce CleanSky EC-H2020 ATCO2, a project that aims to develop an ASR-based platform to collect, organize and automatically pre-process ATCo speech-data from air space. This paper conveys an exploratory benchmark of several state-ofthe-art ASR models trained on more than 170 hours of ATCo speech-data. We demonstrate that the cross-accent ﬂaws due to speakers’ accents are minimized due to the amount of data, making the system feasible for ATC environments. The developed ASR system achieves an averaged word error rate (WER) of 7.75% across four databases. An additional 35% relative improvement in WER is achieved on one test set when training a TDNNF system with byte-pair encoding.",25/10/2020,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:27,2297-2301,ISCA,en,L1-or-L2,Interspeech 2020
2004,"Aalburg, Stefanie; Hoege, Harald",Foreign-accented speaker-independent speech recognition,Interspeech 2004,,10.21437/Interspeech.2004-558,https://www.isca-speech.org/archive/interspeech_2004/aalburg04_interspeech.html,"This research investigated whether acoustic-phonetic knowledge of the mother tongue of a non-native speaker can be used to adapt an existing target language phoneme HMM recognizer. For this purpose three sets of phoneme HMMs were generated, one representing the target language (German), one the mother tongue of the non-native speaker (Turkish), and the third the foreign-accented pronunciation of the target language (German spoken by Turkish speakers). The latter served as a benchmark for the tested adaptation methods. A derived Hidden Markov Model (HMM) clustering algorithm was applied on the target language phoneme HMM set using the mother tongue phoneme HMM set of the non-native speaker. Following the HMM adaptation a phoneme-level pronunciation technique was applied to generate phoneme mapping rules for the lexicon adaptation task. The results revealed a relative reduction of about 6% in WER for the adapted HMM. No further improvements were observed from the lexicon adaptation task.",04/10/2004,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:27,1465-1468,ISCA,en,L2,Interspeech 2004
2008,"Alotaibi, Yousef A.; Abdullah-Al-Mamun, Khondaker; Muhammad, Ghulam",Study on unique pharyngeal and uvular consonants in foreign accented Arabic,Interspeech 2008,,10.21437/Interspeech.2008-233,https://www.isca-speech.org/archive/interspeech_2008/alotaibi08_interspeech.html,"This paper investigates the unique pharyngeal and uvular consonants of Arabic from the automatic speech recognition (ASR) point of view. Comparisons of the recognition error rates for these phonemes are analyzed in five experiments that involve different combinations of native and non-native Arabic speakers. The most three confusing consonants for every investigated consonant are uncovered and discussed. Results confirm that these Arabic distinct consonants are a major source of difficulty for ASR. While the recognition rate for certain of these unique consonants such as /H/ can drop below 35% when uttered by non-native speakers, there are advantages to including non-native speakers in ASR. Regional differences in the pronunciation of Modern Standard Arabic by native Arabic speakers require attention of Arabic ASR research.",22/09/2008,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:27,751-754,ISCA,en,L2,Interspeech 2008
2009,"Amino, Kanae; Arai, Takayuki",Dialectal characteristics of osaka and tokyo Japanese: analyses of phonologically identical words,Interspeech 2009,,10.21437/Interspeech.2009-652,https://www.isca-speech.org/archive/interspeech_2009/amino09_interspeech.html,"This study investigates the characteristics of the two major dialects of Japanese: Osaka and Tokyo dialects. We recorded the utterances of the speakers of both dialects, and analysed the differences that appear in the accentuation of the words at the phonetic-acoustic level. The Japanese words that are phonologically identical in both dialects were used as the analysis target. The results showed that the pitch patterns contained the dialect-dependent features of Osaka Japanese. Furthermore, these patterns could not be fully mimicked by speakers of Tokyo Japanese. These results show that there is a phonetics-phonology gap in the dialectal differences, and that we may exploit this gap for forensic purposes.",06/09/2009,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:27,2303-2306,ISCA,en,L1,Interspeech 2009
2006,"Ananthakrishnan, Sankaranarayanan; Narayanan, Shrikanth","Combining acoustic, lexical, and syntactic evidence for automatic unsupervised prosody labeling",Interspeech 2006,,10.21437/Interspeech.2006-106,https://www.isca-speech.org/archive/interspeech_2006/ananthakrishnan06_interspeech.html,"Automatic labeling of prosodic events in speech has potentially signiﬁcant implications for spoken language processing applications, and has received much attention over the years, especially after the introduction of annotation standards such as ToBI. Current labeling techniques are based on supervised learning, relying on the availability of a corpus that is annotated with the prosodic labels of interest in order to train the system. However, creating such resources is an expensive and time-consuming task. In this paper, we examine an unsupervised labeling algorithm for accent (prominence) and prosodic phrase boundary detection at the linguistic syllable level, and evaluate their performance on an standard, manually annotated corpus. We obtain labeling accuracies of 77.8% and 88.5% for the accent and boundary labeling tasks, respectively. These ﬁgures compare well against previously reported performance levels for supervised labelers.",17/09/2006,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:27,paper 1335-Mon2A3O.1-0,ISCA,en,prosody,Interspeech 2006
2021,"Gong, Xun; Lu, Yizhou; Zhou, Zhikai; Qian, Yanmin",Layer-Wise Fast Adaptation for End-to-End Multi-Accent Speech Recognition,Interspeech 2021,,10.21437/Interspeech.2021-1075,https://www.isca-speech.org/archive/interspeech_2021/gong21c_interspeech.html,,30/08/2021,22/02/2023 10:34,22/02/2023 10:34,06/02/2023 15:31,1274-1278,ISCA,en,L1-or-L2,Interspeech 2021
