Publication Year,Author,Title,Publication Title,ISBN,DOI,Url,Abstract Note,Date,Date Added,Date Modified,Access Date,Pages,Publisher,Language,Manual Tags,Conference Name
2012,"Andreeva, Bistra; Barry, William; Wolska, Magdalena",Language differences in the perceptual weight of prominence-lending properties,Interspeech 2012,,10.21437/Interspeech.2012-635,https://www.isca-speech.org/archive/interspeech_2012/andreeva12_interspeech.html,"A Bulgarian and a German sentence were presented to Bulgarian and German listeners together with a question which either expected an early narrow focus or a late narrow focus. The answering sentences were manipulated so that the word in the latefocused position ranged from completely de-accented to strongly accented. The early focused position was neutral, allowing latefocus perception with late strong accentuation and early focus with de-accentuation of the late-focus position. Accentuation strength of the late position was varied by changing the duration, intensity and f0 values individually between accented and low de-accented. Subjects were asked to judge the suitability of the answers to the question. Results show the relative contribution of the three parameters to the acceptability of the word in the late focus position as focally accented or de-accented. Differences between Bulgarian and German in the relative weighting of the parameters are revealed.",09/09/2012,22/02/2023 10:36,22/02/2023 10:36,30/01/2023 14:17,2426-2429,ISCA,en,prosody,Interspeech 2012
2015,"Aryal, Sandesh; Gutierrez-Osuna, Ricardo",Articulatory-based conversion of foreign accents with deep neural networks,Interspeech 2015,,10.21437/Interspeech.2015-145,https://www.isca-speech.org/archive/interspeech_2015/aryal15_interspeech.html,"We present an articulatory-based method for real-time accent conversion using deep neural networks (DNN). The approach consists of two steps. First, we train a DNN articulatory synthesizer for the non-native speaker that estimates acoustics from contextualized articulatory gestures. Then we drive the DNN with articulatory gestures from a reference native speaker –mapped to the nonnative articulatory space via a Procrustes transform. We evaluate the accent-conversion performance of the DNN through a series of listening tests of intelligibility, voice identity and nonnative accentedness. Compared to a baseline method based on Gaussian mixture models, the DNN accent conversions were found to be 31% more intelligible, and were perceived more native-like in 68% of the cases. The DNN also succeeded in preserving the voice identity of the nonnative speaker.",06/09/2015,22/02/2023 10:36,26/02/2023 12:55,30/01/2023 14:17,3385-3389,ISCA,en,L2; voice-conversion; no-motivation; no-description-of-accent,Interspeech 2015
2007,"Barry, William; Andreeva, Bistra; Steiner, Ingmar",The phonetic exponency of phrasal accentuation in French and German,Interspeech 2007,,10.21437/Interspeech.2007-355,https://www.isca-speech.org/archive/interspeech_2007/barry07_interspeech.html,"The acoustic-phonetic properties of words spoken with three different levels of accentuation (de-accented, pre-nuclear and nuclear accented in broad-focus and nuclear accented in narrow-focus) are examined in question-answer elicited sentences and iterative imitations (on the syllable da) produced by six French and six German speakers. Normalised parameter values allow a comparative weighting of the properties employed in differentiating the three levels of accentuation. Clear differences are found between French and German in the weighting hierarchy of the acoustic properties.",27/08/2007,22/02/2023 10:36,22/02/2023 10:36,30/01/2023 14:17,1010-1013,ISCA,en,prosody,Interspeech 2007
2015,"Chen, Mingming; Yang, Zhanlei; Liang, Jizhong; Li, Yanpeng; Liu, Wenju",Improving deep neural networks based multi-accent Mandarin speech recognition using i-vectors and accent-specific top layer,Interspeech 2015,,10.21437/Interspeech.2015-718,https://www.isca-speech.org/archive/interspeech_2015/chen15s_interspeech.html,"In this paper, we propose a method that use i-vectors and model adaptation techniques to improve the performance of deep neural networks(DNNs) based multi-accent Mandarin speech recognition. I-vectors which are speaker-speciﬁc features have been proved to be effective when used in accent identiﬁcation. They can be used in company with conventional spectral features as the input features of DNNs to improve the discrimination for different accents. Meanwhile, we adapt DNNs to different accents by using an accent-speciﬁc top layer and shared hidden layers. The accent-speciﬁc top layer is used to adapt to different accents while the share hidden layers which can be seen as feature extractors can extract discriminative highlevel features between different accents. These two techniques are complementary and can be easily combined together. Our experiments on the 400-hours Intel Accented Mandarin Speech Recognition Corpus show that our proposed method can signiﬁcantly improve the performance of DNNs-based accented Mandarin speech recognition.",06/09/2015,22/02/2023 10:36,07/03/2023 11:32,30/01/2023 14:17,3620-3624,ISCA,en,mandarin; L1; no-description-of-accent; wrong-def; lang-in-title,Interspeech 2015
2022,"Chung, Raymond; Mak, Brian",Synthesizing Near Native-accented Speech for a Non-native Speaker by Imitating the Pronunciation and Prosody of a Native Speaker,Interspeech 2022,,10.21437/Interspeech.2022-11124,https://www.isca-speech.org/archive/interspeech_2022/chung22_interspeech.html,"This paper investigates how to reduce foreign accent in the synthesis of native (L1) speech for a non-native (L2) speaker. We focus on two major aspects of foreign accents: mispronunciations and improper prosody (rhythm, phonemes duration, and pauses). Firstly, to reduce mispronunciations, the melspectrograms generated by an L2 text-to-speech (TTS) model are fed to a pre-trained speech recognizer and the mispronunciation information is fed back to the TTS model during back-propagation to help the model learn correct native melspectrograms. Secondly, to imitate L1 speech prosody, a recent data augmentation (DA) technique originally proposed for speaking style transfer is applied to transfer L1 speaking style to L2 speakers. The DA technique creates additional L2 speeches when L2 speakers try to imitate L1 speeches. Automatic speech recognition on native-accented speeches synthesized from nonnative speakers by the proposed method gives a lower word error rate. The speaker embeddings produced by a pre-trained speaker veriﬁer from the original L2 speakers’ speech and their synthesized speech are highly similar. Finally, subjective MOS scores on the synthesized speech show that they have good quality and reduced accentedness.",18/09/2022,22/02/2023 10:36,27/02/2023 07:42,30/01/2023 14:17,4302-4306,ISCA,en,L2; voice-conversion; synthesis; TTS; teaching; accentedness-rating,Interspeech 2022
2018,"Davis, Chris; Kim, Jeesun",Characterizing Rhythm Differences between Strong and Weak Accented L2 Speech,Interspeech 2018,,10.21437/Interspeech.2018-1798,https://www.isca-speech.org/archive/interspeech_2018/davis18_interspeech.html,"This study examined the rhythmic characteristics of accented L2 speech by using two relatively novel measures of prosodic rhythm: The S-AMPH measure, an index of the degree of synchrony between the stress and syllable amplitude modulation rates; and the Allan Factor measure, that determines the nested clustering of temporal events (in this case peaks in the amplitude envelope) over different timescales. An extremegroup design was used to select strong versus weak foreign accent recordings from a group of Korean and French L2 English talkers saying the same 69-word English passage. For the Korean talkers, both the S-AMPH and the Allan Factor measures differed as a function of the strength of foreign accent. This was not the case for the French talkers, where neither measure differed as a function of foreign accent strength. The difference in outcome between the Korean and French talkers suggests that the measures are not indexing some general property of L2 accent (e.g., production fluency) but rather that picking up some property specific to the strongly accented Korean talkers. We consider several options.",02/09/2018,22/02/2023 10:36,07/03/2023 12:47,30/01/2023 14:17,2568-2572,ISCA,en,L2; perception-study; some-description; accentedness-rating; unaccented/non-accented; speaker-description; no-listener-description,Interspeech 2018
2021,"Deng, Keqi; Cao, Songjun; Ma, Long",Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning,Interspeech 2021,,10.21437/Interspeech.2021-1186,https://www.isca-speech.org/archive/interspeech_2021/deng21b_interspeech.html,"Recently, self-supervised pre-training has gained success in automatic speech recognition (ASR). However, considering the difference between speech accents in real scenarios, how to identify accents and use accent features to improve ASR is still challenging. In this paper, we employ the self-supervised pre-training method for both accent identiﬁcation and accented speech recognition tasks. For the former task, a standard deviation constraint loss (SDC-loss) based end-to-end (E2E) architecture is proposed to identify accents under the same language. As for accented speech recognition task, we design an accent-dependent ASR system, which can utilize additional accent input features. Furthermore, we propose a frame-level accent feature, which is extracted based on the proposed accent identiﬁcation model and can be dynamically adjusted. We pretrain our models using 960 hours unlabeled LibriSpeech dataset and ﬁne-tune them on AESRC2020 speech dataset. The experimental results show that our proposed accent-dependent ASR system is signiﬁcantly ahead of the AESRC2020 baseline and achieves 6.5% relative word error rate (WER) reduction compared with our accent-independent ASR system.",30/08/2021,22/02/2023 10:36,22/02/2023 10:36,30/01/2023 14:17,1504-1508,ISCA,en,accent-identification,Interspeech 2021
2006,"Ding, Pei; He, Lei; Yan, Xiang; Hao, Jie",Robust automatic speech recognition for accented Mandarin in car environments,Interspeech 2006,,10.21437/Interspeech.2006-637,https://www.isca-speech.org/archive/interspeech_2006/ding06_interspeech.html,,17/09/2006,22/02/2023 10:36,07/03/2023 11:33,30/01/2023 14:17,paper 1764-Thu2CaP.6-0,ISCA,en,ASR; mandarin; L1; no-description-of-accent; lang-in-title,Interspeech 2006
2008,"Ding, Guo-Hong",Phonetic confusion analysis and robust phone set generation for Shanghai-accented Mandarin speech recognition,Interspeech 2008,,10.21437/Interspeech.2008-344,https://www.isca-speech.org/archive/interspeech_2008/ding08d_interspeech.html,"In this paper, accent issues are discussed for Shanghai-accented Mandarin speech recognition. The phonetic confusion is analyzed in detail based on the alignment between the surface form and the baseform transcriptions. Mutual information is used as the measure to extract the most confusing phoneme pairs. It was found that each phoneme in one pair can be easily misrecognized with the other. To remove the phonetic confusion, it is better to replace the two phonemes in one pair with a newly generated one. Consequentially new phone sets are derived. The phonetic confusion analysis and the experimental evaluation are performed on a Shanghai-accented Mandarin speech corpus. Experimental results show that compared to the canonical phone set, the generated one can reduce the substitution error greatly and achieve a 0.72% absolute Chinese character error rate (CER) reduction. When it is combined with pronunciation modeling, the absolute CER reduction is 1.58%.",22/09/2008,22/02/2023 10:36,07/03/2023 11:32,30/01/2023 14:17,1129-1132,ISCA,en,ASR; mandarin; L1; some-description; accent-in-title,Interspeech 2008
2004,"Dohen, Marion; Loevenbruck, Helene","Pre-focal rephrasing, focal enhancement and postfocal deaccentuation in French",Interspeech 2004,,10.21437/Interspeech.2004-296,https://www.isca-speech.org/archive/interspeech_2004/dohen04_interspeech.html,"This study aims at better describing the acoustic correlates of contrastive focus in French. A corpus was recorded from a male native speaker of French. It consisted of sentences with a subject-verb-object (SVO) structure under four conditions: focus on each phrase (S,V,O) and broad focus. The focal, pre-focal and post-focal constituents were studied separately. The acoustic analysis showed that: a) the pitch of the focal constituent rises, b) that of the surrounding constituents decreases, c) the duration of the focal syllables and of the pre-focal syllable increases, the onset of the focal constituent increasing the most, d) the pre-focal sequence is rephrased, e) the post-focal sequence is deaccented.",04/10/2004,22/02/2023 10:36,22/02/2023 10:36,30/01/2023 14:18,785-788,ISCA,en,prosody,Interspeech 2004
2018,"Fukuda, Takashi; Fernandez, Raul; Rosenberg, Andrew; Thomas, Samuel; Ramabhadran, Bhuvana; Sorin, Alexander; Kurata, Gakuto",Data Augmentation Improves Recognition of Foreign Accented Speech,Interspeech 2018,,10.21437/Interspeech.2018-1211,https://www.isca-speech.org/archive/interspeech_2018/fukuda18_interspeech.html,"Speech recognition of foreign accented (non-native or L2) speech remains a challenge to the state-of-the-art. The most common approach to address this scenario involves the collection and transcription of accented speech, and incorporating this into the training data. However, the amount of accented data is dwarfed by the amount of material from native (L1) speakers, limiting the impact of the additional material. In this work, we address this problem via data augmentation. We create modiﬁed copies of two accents, Latin American and Asian accented English speech with voice transformation (modifying glottal source and vocal tract parameters), noise addition, and speed modiﬁcation. We investigate both supervised (where transcription of the accented data is available) and unsupervised approaches to using the accented data and associated augmentations. We ﬁnd that all augmentations provide improvements, with the largest gains coming from speed modiﬁcation, then voice transformation and noise addition providing the least improvement. The improvements from training accent speciﬁc models with the augmented data are substantial. Improvements from supervised and unsupervised adaptation (or training with soft labels) with the augmented data are relatively minor. Overall, we ﬁnd speed modiﬁcation to be a remarkably reliable data augmentation technique for improving recognition of foreign accented speech. Our strategies with associated augmentations provide Word Error Rate (WER) reductions of up to 30% relative over a baseline trained with only the accented data.",02/09/2018,22/02/2023 10:36,01/03/2023 17:01,30/01/2023 14:18,2409-2413,ISCA,en,ASR; L2; data-augmentation; definition; some-description,Interspeech 2018
2015,"Grohe, Ann-Kathrin; Poarch, Gregory J.; Hanulíková, Adriana; Weber, Andrea",Production inconsistencies delay adaptation to foreign accents,Interspeech 2015,,10.21437/Interspeech.2015-627,https://www.isca-speech.org/archive/interspeech_2015/grohe15_interspeech.html,"The effects of production inconsistencies and speaker’s accented production preferences on speech comprehension were investigated in an eyetracking experiment. Using the visual world paradigm, native speakers of German with L2 English listened to single English words produced by a German speaker that had their th either pronounced canonically or substituted with an /s/ or a /t/. Looks to the target word were most likely for the canonical pronunciation and did not differ between the substitutes. However, target looks increased for items with th substitutions in the course of the experiment, indicating slow adaptation to inconsistently foreign accented speech.",06/09/2015,22/02/2023 10:36,07/03/2023 13:57,30/01/2023 14:18,3115-3119,ISCA,en,english; L2; not-tech; perception-study; some-description; listener-description; no-speaker-description,Interspeech 2015
2020,"Hirschi, Kevin; Kang, Okim; Cucchiarini, Catia; Hansen, John H.L.; Evanini, Keelan; Strik, Helmer",Mobile-Assisted Prosody Training for Limited English Proficiency: Learner Background and Speech Learning Pattern,Interspeech 2020,,10.21437/Interspeech.2020-2901,https://www.isca-speech.org/archive/interspeech_2020/hirschi20_interspeech.html,"The use of Mobile-Assisted Pronunciation Training (MAPT) has been increasing drastically due to the personal and interactive nature of mobile devices. However, MAPT applications lack support from empirical evidence as research on MAPT-based acquisition, particularly related to prosody, has been rare. The present study employs a MAPT application with lessons on lexical stress and prominence with Limited English Proficiency (LEP) users (n = 31) of mixed ages and first languages. Then, 16 experienced raters conducted discoursebased prosodic analysis on unconstrained speech collected at the beginning and the end of the intervention. A series of mixedeffect model analyses were conducted on learner effort, improvement and learner background to investigate their relationship with accentedness and comprehensibility. The results indicated that present MAPT prosody interventions were effective for comprehensibility but not accentedness, however, learner effort on lexical stress and prominence exhibit differing patterns. Similar to previous findings, learner age impacts production more than the length of residency or history of language study. Implications include a prosody-based MAPT application; support for the treatment of accentedness and comprehensibility as separate, but related constructs; and a further understanding of the role of learner-related factors in prosody intervention.",25/10/2020,22/02/2023 10:36,07/03/2023 11:27,30/01/2023 14:18,4452-4456,ISCA,en,ASR; L2; teaching; accentedness-rating; almost-no-description; lang-in-title,Interspeech 2020
2013,"Hou, Luying; Jia, Yuan; Li, Aijun",Phonetic manifestation and influence of zero anaphora in Chinese reading texts,Interspeech 2013,,10.21437/Interspeech.2013-372,https://www.isca-speech.org/archive/interspeech_2013/hou13_interspeech.html,"The present paper conducts a pioneering study on the phonetic manifestation and influence of zero anaphora in Chinese reading texts. The stress degree of the boundary syllable and the duration of the pause at the anaphoric position are examined. The results show: i) the boundary syllable after zero anaphoric form is more accented; for the two types of zero anaphora concerned in this study, the boundary syllable after distant zero anaphoric form is more accented than that after immediate zero anaphoric form; ii) the boundary syllable before immediate anaphoric form is more accented than that before distant anaphoric form; iii) the pause before immediate zero anaphoric form is shorter than that before other types of anaphoric forms. Based on these results, the study further proposes that the syllable weight of the underlying anaphoric form is projected to the following syllable in the surface representation. Moreover, semantic distance and relation can account for the differences between distant and immediate zero anaphora.",25/08/2013,22/02/2023 10:36,22/02/2023 10:36,30/01/2023 14:18,1424-1428,ISCA,en,prosody; mandarin,Interspeech 2013
2017,"Hou, Luying; Bruyn, Bert Le; Kager, René",Disambiguate or not? — The Role of Prosody in Unambiguous and Potentially Ambiguous Anaphora Production in Strictly Mandarin Parallel Structures,Interspeech 2017,,10.21437/Interspeech.2017-1214,https://www.isca-speech.org/archive/interspeech_2017/hou17_interspeech.html,"It has been observed that the interpretation of pronouns can depend on their accentuation patterns in parallel sentences as “John hit Bill and then George hit him”, in which ‘him’ refers to Bill when unaccented but shifts to John when accented. While accentuation is widely regarded as a means of disambiguation, some studies have noticed that it also extends to unambiguous anaphors [7-10]. From the perspective of production, however, no strong experimental confirmation was found for the ‘shift’ function of accented pronouns, which is due to the fact that production research has mainly focused on corpora [5, 6]. Hence, the nature of the accent on anaphors still remains obscure. By manipulating referential shift and ambiguity, this study explores the role of prosody in anaphora production in strictly Mandarin parallel structures. The results reveal a significantly higher F0 and longer duration for anaphors in referentially shifted conditions, suggesting that anaphoric accentuation signals a referential change in strictly parallel structures in Mandarin. No evidence was found that ambiguity plays a role in anaphoric accentuation. This finding challenges the general view on accented pronouns and will deepen our understanding on semantics-prosody relationship.",20/08/2017,22/02/2023 10:36,22/02/2023 10:36,30/01/2023 14:18,1393-1397,ISCA,en,prosody; mandarin,Interspeech 2017
2018,"Jain, Abhinav; Upreti, Minali; Jyothi, Preethi",Improved Accented Speech Recognition Using Accent Embeddings and Multi-task Learning,Interspeech 2018,,10.21437/Interspeech.2018-1864,https://www.isca-speech.org/archive/interspeech_2018/jain18_interspeech.html,"One of the major remaining challenges in modern automatic speech recognition (ASR) systems for English is to be able to handle speech from users with a diverse set of accents. ASR systems that are trained on speech from multiple English accents still underperform when confronted with a new speech accent. In this work, we explore how to use accent embeddings and multi-task learning to improve speech recognition for accented speech. We propose a multi-task architecture that jointly learns an accent classiﬁer and a multi-accent acoustic model. We also consider augmenting the speech input with accent information in the form of embeddings extracted by a separate network. These techniques together give signiﬁcant relative performance improvements of 15% and 10% over a multi-accent baseline system on test sets containing seen and unseen accents, respectively.",02/09/2018,22/02/2023 10:36,27/02/2023 08:14,30/01/2023 14:18,2454-2458,ISCA,en,ASR; L1-or-L2; no-description-of-accent; definition,Interspeech 2018
2005,"Jilka, Matthias",Exploration of different types of intonational deviations in foreign-accented and synthesized speech,Interspeech 2005,,10.21437/Interspeech.2005-44,https://www.isca-speech.org/archive/interspeech_2005/jilka05_interspeech.html,"The study provides an analysis of the basic manifestations of intonational deviations in foreign-accented (American English accent in German) and synthesized speech. It takes into account the crucial influence of the used model of intonation description and makes a major distinction between individual deviations that cause the impression of foreignness or unnaturalness immediately when they occur, and others that do so only when an accumulation of several such deviations does not allow for a meaningful interpretation anymore. It is argued that this is due to the high variability allowed in prosodic contexts. A closer description of the first group of deviations includes the transfer of categories and of the phonetic realizations of categories as well as a discussion of seemingly unmotivated errors and the most likely causes of intonation errors in synthesized speech. Finally, it is shown that in the case of foreign accent the language-specific manifestations of the presented deviations combine to create a characteristic overall impression of foreignness that is recognizable independently of the segmental content of an utterance.",04/09/2005,22/02/2023 10:36,26/02/2023 11:17,30/01/2023 14:18,2393-2396,ISCA,en,L2; teaching; speech-error-detection; some-description; foreign-accent,Interspeech 2005
2020,"Khandelwal, Kartik; Jyothi, Preethi; Awasthi, Abhijeet; Sarawagi, Sunita",Black-Box Adaptation of ASR for Accented Speech,Interspeech 2020,,10.21437/Interspeech.2020-3162,https://www.isca-speech.org/archive/interspeech_2020/khandelwal20_interspeech.html,"We introduce the problem of adapting a black-box, cloud-based ASR system to speech from a target accent. While leading online ASR services obtain impressive performance on mainstream accents, they perform poorly on sub-populations — we observed that the word error rate (WER) achieved by Google’s ASR API on Indian accents is almost twice the WER on US accents. Existing adaptation methods either require access to model parameters or overlay an error correcting module on output transcripts. We highlight the need for correlating outputs with the original speech to ﬁx accent errors. Accordingly, we propose a novel coupling of an open-source accent-tuned local model with the black-box service where the output from the service guides frame-level inference in the local model. Our ﬁne-grained merging algorithm is better at ﬁxing accent errors than existing word-level combination strategies. Experiments on Indian and Australian accents with three leading ASR models as service, show that we achieve upto 28% relative reduction in WER over both the local and service models.",25/10/2020,22/02/2023 10:36,27/02/2023 08:14,30/01/2023 14:18,1281-1285,ISCA,en,ASR; L1-or-L2; some-description; no-def,Interspeech 2020
2006,"Li, Aijun; Fang, Qiang; Xiong, Ziyu","Phonetic research on accented Chinese in three dialectal regions: Shanghai, Wuhan and Xiamen",Interspeech 2006,,10.21437/Interspeech.2006-245,https://www.isca-speech.org/archive/interspeech_2006/li06e_interspeech.html,"There are 10 major dialects in China. Most people in dialectal regions are bilingual speakers, i.e. native dialect and Mandarin. Although lots of people can speak Mandarin, they speak it with different accents (called regional accented Chinese in this paper) depending on how well they grasp the language. In this study, we categorize the regional accented Chinese into 3 levels of accents according to phonetic annotation and subjective evaluation on a regional accented speech corpus of three regions: Shanghai, Wuhan and Xiamen. Three accent evaluation methods, namely segmental annotation, clustering on phonetic annotation and subjective evaluation, are compared based on phonetic error rates. The results show that objective evaluation score based on segmental pronunciation is higher than subjective evaluation for the same speaker. This implies that supra-segmental features play an important role in rating accent degree and segmental features alone are not enough for objective evaluation. In accent level criterion, the errors from prosodic and segmental aspects are not equal and the percentage of these two parts are various for different regional speakers. The result is helpful for machine evaluation, L2 teaching and acquisition.",17/09/2006,22/02/2023 10:36,07/03/2023 11:32,30/01/2023 14:18,paper 1143-Mon3FoP.4-0,ISCA,en,mandarin; L1; not-tech; speech-error-detection; accent-in-title,Interspeech 2006
2020,"Li, Yanping; Best, Catherine T.; Tyler, Michael D.; Burnham, Denis",Tone Variations in Regionally Accented Mandarin,Interspeech 2020,,10.21437/Interspeech.2020-1235,https://www.isca-speech.org/archive/interspeech_2020/li20ja_interspeech.html,"The present study investigated tone variations in regionally accented Mandarin (i.e., Standard Mandarin [SM] spoken by dialectal Chinese speakers) as influenced by the varying tone systems of their native dialects. 12 female speakers, four each from Guangzhou, Shanghai and Yantai, were recruited to produce monosyllabic words in SM that included minimal contrasts among the four Mandarin lexical tones. Since SM developed from the Beijing dialect, their pronunciations were compared to the same Mandarin words produced by four Beijing female speakers. Regional Mandarin speakers successfully produced the four Mandarin lexical tones, but their productions varied from SM. Two crucial acoustic measures for Mandarin lexical tones, F0 (fundamental frequency) and duration values, were fitted into linear mixed-effects models on differences between regional and Beijing accents. Regional speakers had longer word duration and different F0 height when producing SM, resulting in variations in Mandarin lexical tones across the regional accents. These findings shed light on regional accent variations in Mandarin lexical tones and lay a foundation for deeper understanding of their impact on perception of accented Mandarin lexical tones by native (Beijing) Mandarin listeners.",25/10/2020,22/02/2023 10:36,07/03/2023 12:49,30/01/2023 14:18,4158-4162,ISCA,en,mandarin; L1; not-tech; description-of-accent; perception-study; accent-in-title; speaker-description; listener-description,Interspeech 2020
2005,"Liu, Yi; Fung, Pascale",Acoustic and phonetic confusions in accented speech recognition,Interspeech 2005,,10.21437/Interspeech.2005-147,https://www.isca-speech.org/archive/interspeech_2005/liu05_interspeech.html,"Accented speech recognition is more challenging than standard speech recognition due to the effects of phonetic and acoustic confusions. Phonetic confusion in accented speech occurs when an expected phone is pronounced as a different one, which leads to erroneous recognition. Acoustic confusion occurs when the pronounced phone is found to lie acoustically between two baseform models and can be equally recognized as either one. We propose that it is necessary to analyze and model these confusions separately in order to improve accented speech recognition without degrading standard speech recognition. We propose using likelihood ratio test to measure phonetic confusion, and asymmetric acoustic distance to measure acoustic confusion. Only accent-specific phonetic units with low acoustic confusion are used in an augmented pronunciation dictionary, while phonetic models with high acoustic confusion are reconstructed using decision tree merging. Experimental results show that our approach is effective and superior to methods modeling phonetic confusion or acoustic confusion alone in accented speech, with a significant 5.7% absolute WER reduction, without degrading standard speech recognition.",04/09/2005,22/02/2023 10:36,27/02/2023 07:52,30/01/2023 14:18,3033-3036,ISCA,en,ASR; L1-or-L2; no def; some-description,Interspeech 2005
2017,"Maastricht, Lieke van; Zee, Tim; Krahmer, Emiel; Swerts, Marc","L1 Perceptions of L2 Prosody: The Interplay Between Intonation, Rhythm, and Speech Rate and Their Contribution to Accentedness and Comprehensibility",Interspeech 2017,,10.21437/Interspeech.2017-1150,https://www.isca-speech.org/archive/interspeech_2017/maastricht17_interspeech.html,"This study investigates the cumulative effect of (non-)native intonation, rhythm, and speech rate in utterances produced by Spanish learners of Dutch on Dutch native listeners’ perceptions. In order to assess the relative contribution of these language-specific properties to perceived accentedness and comprehensibility, speech produced by Spanish learners of Dutch was manipulated using transplantation and resynthesis techniques. Thus, eight manipulation conditions reflecting all possible combinations of L1 and L2 intonation, rhythm, and speech rate were created, resulting in 320 utterances that were rated by 50 Dutch natives on their degree of foreign accent and ease of comprehensibility.",20/08/2017,22/02/2023 10:36,07/03/2023 13:55,30/01/2023 14:18,364-368,ISCA,en,L2; not-tech; perception-study; definition; some-description; accentedness-rating; speaker-description; listener-description,Interspeech 2017
2013,"Michelas, Amandine; Portes, Cristel; Champagne-Lavau, Maud",Intonational contrasts encode speaker's certainty in neutral vs. incredulity declarative questions in French,Interspeech 2013,,10.21437/Interspeech.2013-227,https://www.isca-speech.org/archive/interspeech_2013/michelas13_interspeech.html,"While recent crosslinguistic studies have shown that the degree of speaker’s commitment or certainty is encoded intonationally either in a gradient or categorical fashion, our understanding of how French speakers use Intonational-Phrase (IP) final contours to signal their degree of certainty is limited. This paper investigates the contribution of a penultimate peak contour in French to convey speakers’ uncertainty. Participants read target sentences in a neutral vs. incredulity declarative question context. Prosodic annotation revealed that incredulity declarative questions consistently exhibited the presence of an additional f0 peak in the penultimate syllable of the IP which was unaccented. The acoustic analyses showed that the H tone of the unaccented penultimate peak was not downstepped and thus approximately scaled to the same height of the last pitch accent. The findings of this study provide the first quantitative description of a phonological contrast between H*H% and H+ H*H% to signal speakers’ certainty in declarative questions in French.",25/08/2013,22/02/2023 10:36,22/02/2023 10:36,30/01/2023 14:18,783-787,ISCA,en,prosody,Interspeech 2013
2014,"Motlicek, Petr; Imseng, David; Cernak, Milos; Kim, Namhoon",Development of bilingual ASR system for MediaParl corpus,Interspeech 2014,,10.21437/Interspeech.2014-342,https://www.isca-speech.org/archive/interspeech_2014/motlicek14_interspeech.html,"The development of an Automatic Speech Recognition (ASR) system for the bilingual MediaParl corpus is challenging for several reasons: (1) reverberant recordings, (2) accented speech, and (3) no prior information about the language. In that context, we employ frequency domain linear prediction-based (FDLP) features to reduce the effect of reverberation, exploit bilingual deep neural networks applied in Tandem and hybrid acoustic modeling approaches to signiﬁcantly improve ASR for accented speech and develop a fully bilingual ASR system using entropy-based decoding-graph selection. Our experiments indicate that the proposed bilingual ASR system performs similar to a language-speciﬁc ASR system if approximately ﬁve seconds of speech are available.",14/09/2014,22/02/2023 10:36,26/02/2023 12:51,30/01/2023 14:18,1391-1394,ISCA,en,ASR; L2; no-description-of-accent; no-def,Interspeech 2014
2014,"Najafian, Maryam; DeMarco, Andrea; Cox, Stephen; Russell, Martin",Unsupervised model selection for recognition of regional accented speech,Interspeech 2014,,10.21437/Interspeech.2014-495,https://www.isca-speech.org/archive/interspeech_2014/najafian14_interspeech.html,"This paper is concerned with automatic speech recognition (ASR) for accented speech. Given a small amount of speech from a new speaker, is it better to apply speaker adaptation to the baseline, or to use accent identiﬁcation (AID) to identify the speaker’s accent and select an accent-dependent acoustic model? Three accent-based model selection methods are investigated: using the ‘true’ accent model, and unsupervised model selection using i-Vector and phonotactic-based AID. All three methods outperform the unadapted baseline. Most signiﬁcantly, AID-based model selection using 43s of speech performs better than unsupervised speaker adaptation, even if the latter uses ﬁve times more adaptation data. Combining unsupervised AIDbased model selection and speaker adaptation gives an average relative reduction in ASR error rate of up to 47%.",14/09/2014,22/02/2023 10:36,26/02/2023 10:56,30/01/2023 14:18,2967-2971,ISCA,en,english; ASR; L1; description-of-accent; definition,Interspeech 2014
2022,"Nguyen, Tuan Nam; Pham, Ngoc-Quan; Waibel, Alexander",Accent Conversion using Pre-trained Model and Synthesized Data from Voice Conversion,Interspeech 2022,,10.21437/Interspeech.2022-10729,https://www.isca-speech.org/archive/interspeech_2022/nguyen22d_interspeech.html,"Accent conversion (AC) aims to generate synthetic audios by changing the pronunciation pattern and prosody of source speakers (in source audios) while preserving voice quality and linguistic content. There has not been a parallel corpus that contains pairs of audios having the same contents yet coming from the same speakers in different accents, the authors hence work on a solution to synthesize one as training input. The training pipeline is conducted via two steps. First, a voice conversion (VC) model is constructed to synthesize a training data set, containing pairs of audios in the same voice but two different accents. Second, an AC model is trained with the synthesized data to convert a source accented speech to a target accented speech. Given the recognized success of self-supervised learning speech representation (wav2vec 2.0) on certain speech problems such as VC, speech recognition, speech translation, and speech-tospeech translation, we adopt this architecture with some customization to train the AC model in the second step. With just 9-hour synthesized training data, the encoder initialized by the weight of the pre-trained wav2vec 2.0 model outperforms the LSTM-based encoder.",18/09/2022,22/02/2023 10:36,27/02/2023 08:20,30/01/2023 14:18,2583-2587,ISCA,en,L1-or-L2; voice-conversion; no-description-of-accent; no-def,Interspeech 2022
2013,"Ní Chasaide, Ailbhe; Yanushevskaya, Irena; Kane, John; Gobl, Christer",The voice prominence hypothesis: the interplay of F0 and voice source features in accentuation,Interspeech 2013,,10.21437/Interspeech.2013-759,https://www.isca-speech.org/archive/interspeech_2013/nichasaide13_interspeech.html,"This paper explores the interplay of source correlates of accentuation, examining a hypothesis (the Voice Prominence Hypothesis) that different source parameters are involved and may serve as equivalent. It predicts that where accentuation is not marked by pitch salience there will be more extensive changes in other source parameters. This follows our assumption that prosodic entities such as accentuation, focus, declination, etc. involve adjustments to the entire voice source and not simply to F0. Twelve 3-accent sentences of Connemara Irish (declaratives, WH questions and Yes/No questions) were analysed. These are typically produced and transcribed as H* H* H*L. Of particular interest were the second accents: although they are heard as accented, there are no particular pitch excursions that would account for their salience. Inverse filtering and subsequent source parameterisation was carried out to yield measures for a range of source parameters. Results support the voice prominence hypothesis: as predicted, the most striking source adjustments were found in the second accent. Even where there is substantial pitch movement (final accent), parameters other than F0 appear to be contributing to the salience of the accented syllable. The precise source changes associated with accentuation varied across sentence types and within the prosodic phrase.",25/08/2013,22/02/2023 10:36,22/02/2023 10:36,30/01/2023 14:18,3527-3531,ISCA,en,prosody,Interspeech 2013
2019,"Pellegrini, Thomas; Farinas, Jérôme; Delpech, Estelle; Lancelot, François",The Airbus Air Traffic Control Speech Recognition 2018 Challenge: Towards ATC Automatic Transcription and Call Sign Detection,Interspeech 2019,,10.21437/Interspeech.2019-1962,https://www.isca-speech.org/archive/interspeech_2019/pellegrini19_interspeech.html,"In this paper, we describe the outcomes of the challenge organized and run by Airbus and partners in 2018 on Air Trafﬁc Control (ATC) speech recognition. The challenge consisted of two tasks applied to English ATC speech: 1) automatic speechto-text transcription, 2) call sign detection (CSD). The registered participants were provided with 40 hours of speech along with manual transcriptions. Twenty-two teams submitted predictions on a ﬁve hour evaluation set. ATC speech processing is challenging for several reasons: high speech rate, foreignaccented speech with a great diversity of accents, noisy communication channels. The best ranked team achieved a 7.62% Word Error Rate and a 82.41% CSD F1-score. Transcribing pilots’ speech was found to be twice as harder as controllers’ speech. Remaining issues towards solving ATC ASR are also discussed in the paper.",15/09/2019,22/02/2023 10:36,27/02/2023 08:05,30/01/2023 14:18,2993-2997,ISCA,en,ASR; L1-or-L2; no-description-of-accent; no-def,Interspeech 2019
2022,"Pérez Ramón, Rubén; Cooke, Martin; Garcia Lecumberri, Maria Luisa",Generating iso-accented stimuli for second language research: methodology and a dataset for Spanish-accented English,Interspeech 2022,,10.21437/Interspeech.2022-850,https://www.isca-speech.org/archive/interspeech_2022/perezramon22_interspeech.html,"A non-native accent can be conveyed at both the segmental and suprasegmental level. Previous studies have developed techniques to isolate the effect of segmental foreign accent by splicing accented segments from a bilingual speaker into nonaccented words produced by the same speaker. The current work addresses the issue of between-segment variability by developing a technique to convert from acoustically-equal accent gradations to perceptually-equal steps. The procedure is used to derive the ﬁrst corpus of Spanish-accented English composed of lexical tokens each generated with one of ﬁve degrees of nonnative accent. As an example application, corpus tokens are used to elicit accentedness judgements from four listener cohorts with ﬁrst languages which differ as to whether they share the native language, the non-native (accented) language of the corpus or have a closer phonological inventory to one or the other. Findings highlight the importance of the relationship between listeners’ phonological systems and those of the native and non-native languages of the corpus, especially for vowels, with respect to sensitivity to foreign accent.",18/09/2022,22/02/2023 10:36,07/03/2023 13:39,30/01/2023 14:18,1846-1850,ISCA,en,L2; not-tech; description-of-accent; perception-study; accentedness-rating; accent-in-title; speaker-description; listener-description,Interspeech 2022
2005,"Psutka, Josef; Ircing, Pavel; Psutka, J. V.; Hajic, Jan; Byrne, William J.; Mírovský, Jirí","Automatic transcription of Czech, Russian, and Slovak spontaneous speech in the MALACH project",Interspeech 2005,,10.21437/Interspeech.2005-489,https://www.isca-speech.org/archive/interspeech_2005/psutka05_interspeech.html,"This paper describes the 3.5-years effort put into building LVCSR systems for recognition of spontaneous speech of Czech, Russian, and Slovak witnesses of the Holocaust in the MALACH project. For processing of colloquial, highly emotional and heavily accented speech of elderly people containing many non-speech events we have developed techniques that very effectively handle both non-speech events and colloquial and accented variants of uttered words. Manual transcripts as one of the main sources for language modeling were automatically „normalized” using standardized lexicon, which brought about 2 to 3% reduction of the word error rate (WER). The subsequent interpolation of such LMs with models built from an additional collection (consisting of topically selected sentences from general text corpora) resulted into an additional improvement of performance of up to 3 % .",04/09/2005,22/02/2023 10:36,07/03/2023 11:33,30/01/2023 14:19,1349-1352,ISCA,en,ASR; L1; description-of-accent; lang-in-title,Interspeech 2005
2015,"Rasipuram, Ramya; Cernak, Milos; Nachen, Alexandre; Magimai-Doss, Mathew",Automatic accentedness evaluation of non-native speech using phonetic and sub-phonetic posterior probabilities,Interspeech 2015,,10.21437/Interspeech.2015-233,https://www.isca-speech.org/archive/interspeech_2015/rasipuram15_interspeech.html,"Automatic evaluation of non-native speech accentedness has potential implications for not only language learning and accent identiﬁcation systems but also for speaker and speech recognition systems. From the perspective of speech production, the two primary factors inﬂuencing the accentedness are the phonetic and prosodic structure. In this paper, we propose an approach for automatic accentedness evaluation based on comparison of instances of native and non-native speakers at the acoustic-phonetic level. Speciﬁcally, the proposed approach measures accentedness by comparing phone class conditional probability sequences corresponding to the instances of native and non-native speakers, respectively. We evaluate the proposed approach on the EMIME bilingual and EMIME Mandarin bilingual corpora, which contains English speech from native English speakers and various non-native English speakers, namely Finnish, German and Mandarin. We also investigate the inﬂuence of the granularity of the phonetic unit representation on the performance of the proposed accentedness measure. Our results indicate that the accentedness ratings by the proposed approach correlate consistently with the human ratings of accentedness. In addition, our studies show that the granularity of the phonetic unit representation that yields the best correlation with the human accentedness ratings varies with respect to the native language of the non-native speakers.",06/09/2015,22/02/2023 10:36,07/03/2023 13:42,30/01/2023 14:19,648-652,ISCA,en,english; L2; perception-study; some-description; accentedness-rating; no-listener-description; no-speaker-description,Interspeech 2015
2019,"Roessig, Simon; Mücke, Doris; Pagel, Lena",Dimensions of Prosodic Prominence in an Attractor Model,Interspeech 2019,,10.21437/Interspeech.2019-2227,https://www.isca-speech.org/archive/interspeech_2019/roessig19_interspeech.html,"Speakers of intonation languages use bundles of cues to express prosodic prominence. This work contributes further evidence for the multi-dimensionality of prosodic prominence in German reporting articulatory (3D EMA) and acoustic recordings from 27 speakers. In particular, we show that speakers use speciﬁc categorical and continuous modiﬁcations of the laryngeal system (tonal onglide) as well as continuous modiﬁcations of the supra-laryngeal system (lip aperture and tongue body position) to mark focus structure prosodically. These modiﬁcations are found between unaccented and accented but also within the group of accented words, revealing that speakers use prosodic modulations to directly encode prominence. On the basis of these ﬁndings we develop a dynamical model of prosodic patterns that is able to capture the manipulations as the modulation of an attractor landscape that is shaped by the different prosodic dimensions involved.",15/09/2019,22/02/2023 10:36,22/02/2023 10:36,30/01/2023 14:19,2533-2537,ISCA,en,prosody,Interspeech 2019
2012,"Rosenberg, Andrew",Using prominence and phrasing predictions to improve weighted dictionary pronunciation models,Interspeech 2012,,10.21437/Interspeech.2012-631,https://www.isca-speech.org/archive/interspeech_2012/rosenberg12c_interspeech.html,"Prosody impacts the pronunciation variation of lexical items in a number of ways. Accented syllables tend to be pronounced with their canonical (dictionary) vowel. Deaccented vowels are more likely to be reduced. Coarticulatory inﬂuences rarely span intonational phrase boundaries. In this work, we investigate the use of automatically generated prosodic hypotheses to improve a weighted dictionary pronunciation model. We use the phonemically transcribed, Buckeye Corpus for this investigation. We ﬁnd that predictions of pitch accent and intonational phrase boundaries can be used to lower pronunciation model perplexity.",09/09/2012,22/02/2023 10:36,22/02/2023 10:36,30/01/2023 14:19,2410-2413,ISCA,en,prosody,Interspeech 2012
2006,"Sakti, Sakriani; Markov, Konstantin; Nakamura, Satoshi","The use of Bayesian network for incorporating accent, gender and wide-context dependency information",Interspeech 2006,,10.21437/Interspeech.2006-438,https://www.isca-speech.org/archive/interspeech_2006/sakti06_interspeech.html,"We propose a new method of incorporating the additional knowledge of accent, gender, and wide-context dependency information into ASR systems by utilizing the advantages of Bayesian networks. First, we only incorporate pentaphone-context dependency information. After that, accent and gender information are also integrated. In this method, we can easily extend conventional triphone HMMs to cover various sources of knowledge. The probabilistic dependencies between a triphone context unit and additional knowledge are learned through a BN. Another advantage is that during recognition, additional knowledge variables are assumed to be hidden, so that the existing standard triphone-based decoding system can be used without modiﬁcation. The performance of the proposed model was evaluated on an LVCSR task using two different types of accented English speech data. Experimental results show that this proposed method improves word accuracy with respect to standard triphone models.",17/09/2006,22/02/2023 10:36,27/02/2023 07:57,30/01/2023 14:19,paper 1812-Wed1BuP.4-0,ISCA,en,ASR; L1-or-L2; no-description-of-accent,Interspeech 2006
2012,"Scharenborg, Odette; Witteman, Marijt; Weber, Andrea",Computational modelling of the recognition of foreign-accented speech,Interspeech 2012,,10.21437/Interspeech.2012-267,https://www.isca-speech.org/archive/interspeech_2012/scharenborg12b_interspeech.html,"In foreign-accented speech, pronunciation typically deviates from the canonical form to some degree. For native listeners, it has been shown that word recognition is more difficult for strongly-accented words than for less strongly-accented words. Furthermore recognition of strongly-accented words becomes easier with additional exposure to the foreign accent. In this paper, listeners’ behaviour was simulated with Fine-tracker, a computational model of word recognition that uses real speech as input. The simulations showed that, in line with human listeners, 1) Fine-Tracker’s recognition outcome is modulated by the degree of accentedness and 2) it improves slightly after brief exposure with the accent. On the level of individual words, however, Fine-tracker failed to correctly simulate listeners’ behaviour, possibly due to differences in overall familiarity with the chosen accent (German-accented Dutch) between human listeners and Fine-Tracker.",09/09/2012,22/02/2023 10:36,26/02/2023 12:21,30/01/2023 14:19,883-886,ISCA,en,ASR; L2; some-description; foreign-accent,Interspeech 2012
2019,"Shor, Joel; Emanuel, Dotan; Lang, Oran; Tuval, Omry; Brenner, Michael; Cattiau, Julie; Vieira, Fernando; McNally, Maeve; Charbonneau, Taylor; Nollstadt, Melissa; Hassidim, Avinatan; Matias, Yossi",Personalizing ASR for Dysarthric and Accented Speech with Limited Data,Interspeech 2019,,10.21437/Interspeech.2019-1427,https://www.isca-speech.org/archive/interspeech_2019/shor19_interspeech.html,"Automatic speech recognition (ASR) systems have dramatically improved over the last few years. ASR systems are most often trained from ‘typical’ speech, which means that underrepresented groups don’t experience the same level of improvement. In this paper, we present and evaluate ﬁnetuning techniques to improve ASR for users with non-standard speech. We focus on two types of non-standard speech: speech from people with amyotrophic lateral sclerosis (ALS) and accented speech. We train personalized models that achieve 62% and 35% relative WER improvement on these two groups, bringing the absolute WER for ALS speakers, on a test set of message bank phrases, down to 10% for mild dysarthria and 20% for more serious dysarthria. We show that 71% of the improvement comes from only 5 minutes of training data. Finetuning a particular subset of layers (with many fewer parameters) often gives better results than ﬁnetuning the entire model. This is the ﬁrst step towards building state of the art ASR models for dysarthric speech.",15/09/2019,22/02/2023 10:36,27/02/2023 08:14,30/01/2023 14:19,784-788,ISCA,en,ASR; L1-or-L2; no-description-of-accent; some-def,Interspeech 2019
2013,"Siddins, Jessica; Harrington, Jonathan; Kleber, Felicitas; Reubold, Ulrich",The influence of accentuation and polysyllabicity on compensatory shortening in German,Interspeech 2013,,10.21437/Interspeech.2013-177,https://www.isca-speech.org/archive/interspeech_2013/siddins13_interspeech.html,"The aim of this study was to investigate the relationship between compensatory shortening and coarticulation in German tense and lax vowels in trochees and iambs and to determine whether this relationship was inﬂuenced by prosodic accentuation. Speakers produced near minimal pairs differing in vowel tensity in monosyllabic and disyllabic words (both trochees and iambs) in accented and deaccented contexts. We found signiﬁcant effects of polysyllabic shortening, but only in tense vowels of nuclear-accented target words. Both stress patterns (trochaic and iambic) showed equal effects of polysyllabic shortening. Thus, while the duration of tense vowels in this study depended on accentuation and syllabicity, perhaps in order to provide perceptual cues for the listener, lax vowels were immune from lengthening and shortening phenomena. As a result, the durational difference between tense and lax vowels appears to lessen in prosodically weak contexts. The greater overlap of acoustic duration in deaccented contexts may contribute to the origin of the diachronic merger of tense and lax vowels in some languages.",25/08/2013,22/02/2023 10:36,22/02/2023 10:36,30/01/2023 14:19,1002-1006,ISCA,en,prosody,Interspeech 2013
2016,"Stehwien, Sabrina; Vu, Ngoc Thang",Exploring the Correlation of Pitch Accents and Semantic Slots for Spoken Language Understanding,Interspeech 2016,,10.21437/Interspeech.2016-511,https://www.isca-speech.org/archive/interspeech_2016/stehwien16_interspeech.html,"We investigate the correlation between pitch accents and semantic slots in human-machine speech. Using an automatic pitch accent detector on the ATIS corpus, we ﬁnd that most words labelled with semantic slots also carry a pitch accent. Most of the pitch accented words that are not associated with a semantic label are still meaningful, pointing towards the speaker’s intention. Our ﬁndings show that prosody constitutes a relevant and useful resource for spoken language understanding, especially considering the fact that our pitch accent detector does not require any kind of manual transcriptions during testing time.",08/09/2016,22/02/2023 10:36,22/02/2023 10:36,30/01/2023 14:19,730-734,ISCA,en,prosody,Interspeech 2016
2005,"Tomokiyo, Laura Mayfield; Black, Alan W.; Lenzo, Kevin A.",Foreign accents in synthetic speech: development and evaluation,Interspeech 2005,,10.21437/Interspeech.2005-519,https://www.isca-speech.org/archive/interspeech_2005/tomokiyo05_interspeech.html,"This paper addresses the generation and evaluation of foreign-accented speech in concatenative text-to-speech (TTS) synthesis. We describe three possible methods of building a Spanish-accented English voice, and evaluate and compare them with respect to preference, intelligibility, and smoothness. Effects of speaking rate and content are also examined.",04/09/2005,22/02/2023 10:36,26/02/2023 11:24,30/01/2023 14:19,1469-1472,ISCA,en,L2; TTS; some-description,Interspeech 2005
2006,"Vieru-Dimulescu, Bianca; Boula de Mareüil, Philippe",Perceptual identification and phonetic analysis of 6 foreign accents in French,Interspeech 2006,,10.21437/Interspeech.2006-142,https://www.isca-speech.org/archive/interspeech_2006/vierudimulescu06_interspeech.html,"A perceptual experiment was designed to determine to what extent naïve French listeners are able to identify foreign accents in French: Arabic, English, German, Italian, Portuguese and Spanish. They succeed in recognizing the speaker’s mother tongue in more than 50% of cases (while rating their degree of accentedness as average). They perform best with Arabic speakers and worst with Portuguese speakers. The Spanish/Italian and English/German accents are the most mistaken ones. Phonetic analyses were conducted; clustering and scaling techniques were applied to the results, and were related to the listeners’ reactions that were recorded during the test. They support the idea that differences in the vowel realization (especially concerning the phoneme /y/) seem to outweigh rhythmic cues.",17/09/2006,22/02/2023 10:36,07/03/2023 12:52,30/01/2023 14:19,paper 1251-Mon2CaP.11-0,ISCA,en,L2; not-tech; accent-identification; description-of-accent; perception-study; accentedness-rating; foreign-accent; lang-in-title; speaker-description; no-listener-description,Interspeech 2006
2019,"Viglino, Thibault; Motlicek, Petr; Cernak, Milos",End-to-End Accented Speech Recognition,Interspeech 2019,,10.21437/Interspeech.2019-2122,https://www.isca-speech.org/archive/interspeech_2019/viglino19_interspeech.html,"Correct pronunciation is known to be the most difﬁcult part to acquire for (native or non-native) language learners. The accented speech is thus more variable, and standard Automatic Speech Recognition (ASR) training approaches that rely on intermediate phone alignment might introduce errors during the ASR training. With end-to-end training we could alleviate this problem. In this work, we explore the use of multi-task training and accent embedding in the context of end-to-end ASR trained with the connectionist temporal classiﬁcation loss. Comparing to the baseline developed using conventional ASR framework exploiting time-delay neural networks trained on accented English, we show signiﬁcant relative improvement of about 25% in word error rate. Additional evaluation on unseen accent data yields relative improvements of of 31% and 2% for New Zealand English and Indian English, respectively.",15/09/2019,22/02/2023 10:36,27/02/2023 08:14,30/01/2023 14:19,2140-2144,ISCA,en,ASR; L1-or-L2; no-description-of-accent; some-def,Interspeech 2019
2005,"Wang, Hongyan; Heuven, Vincent J. van","Mutual intelligibility of american, Chinese and dutch-accented speakers of English",Interspeech 2005,,10.21437/Interspeech.2005-356,https://www.isca-speech.org/archive/interspeech_2005/wang05f_interspeech.html,"This paper presents the results of a comprehensive study of the mutual intelligibility of Chinese, Dutch (both foreignlanguage learners) and American (native language) speakers of English. Intelligibility is tested at the level of the segment, word and sentence, after careful selection of representative speakers from the three language backgrounds. The results show that production and perception skills are generally correlated at all levels, that both speakers and listeners are more successful in the order Chinese < Dutch < American. Against this background, however, intelligibility is unexpectedly good when speakers and listeners share the same mother tongue.",04/09/2005,22/02/2023 10:36,07/03/2023 13:47,30/01/2023 14:19,2225-2228,ISCA,en,L2; not-tech; perception-study; some-description; accent-in-title; speaker-description; no-listener-description,Interspeech 2005
2013,"Wang, Hongyan; Heuven, Vincent J. van","Mutual intelligibility of American, Chinese and Dutch-accented speakers of English tested by SUS and SPIN sentences",Interspeech 2013,,10.21437/Interspeech.2013-129,https://www.isca-speech.org/archive/interspeech_2013/wang13_interspeech.html,"This paper investigates the mutual intelligibility of Chinese, Dutch (both foreign-language learners) and American (native language) speakers of English using SUS (Semantically Unpredictable Sentences) and SPIN (Speech in Noise) materials. We test the hypothesis that speakers and listeners who share the same native-language background have an advantage (interlanguage speech intelligibility benefit).",25/08/2013,22/02/2023 10:36,07/03/2023 12:56,30/01/2023 14:19,431-435,ISCA,en,L2; not-tech; no-description-of-accent; perception-study; accent-in-title; speaker-description; no-listener-description,Interspeech 2013
2019,"Weninger, Felix; Sun, Yang; Park, Junho; Willett, Daniel; Zhan, Puming",Deep Learning Based Mandarin Accent Identification for Accent Robust ASR,Interspeech 2019,,10.21437/Interspeech.2019-2737,https://www.isca-speech.org/archive/interspeech_2019/weninger19_interspeech.html,,15/09/2019,22/02/2023 10:36,07/03/2023 11:32,30/01/2023 14:19,510-514,ISCA,en,ASR; mandarin; L1; some-description; lang-in-title,Interspeech 2019
2020,"Winata, Genta Indra; Cahyawijaya, Samuel; Liu, Zihan; Lin, Zhaojiang; Madotto, Andrea; Xu, Peng; Fung, Pascale",Learning Fast Adaptation on Cross-Accented Speech Recognition,Interspeech 2020,,10.21437/Interspeech.2020-45,https://www.isca-speech.org/archive/interspeech_2020/winata20_interspeech.html,"Local dialects inﬂuence people to pronounce words of the same language differently from each other. The great variability and complex characteristics of accents create a major challenge for training a robust and accent-agnostic automatic speech recognition (ASR) system. In this paper, we introduce a cross-accented English speech recognition task as a benchmark for measuring the ability of the model to adapt to unseen accents using the existing CommonVoice corpus. We also propose an accent-agnostic approach that extends the model-agnostic metalearning (MAML) algorithm for fast adaptation to unseen accents. Our approach signiﬁcantly outperforms joint training in both zero-shot, few-shot, and all-shot in the mixed-region and cross-region settings in terms of word error rate.",25/10/2020,22/02/2023 10:36,27/02/2023 08:34,30/01/2023 14:19,1276-1280,ISCA,en,ASR; L1-or-L2; some-description; some-def,Interspeech 2020
2014,"Windmann, Andreas; Šimko, Juraj; Wagner, Petra",A unified account of prominence effects in an optimization-based model of speech timing,Interspeech 2014,,10.21437/Interspeech.2014-44,https://www.isca-speech.org/archive/interspeech_2014/windmann14_interspeech.html,"We show how our optimization-based model of speech timing reproduces three effects of prosodic prominence on suprasegmental timing patterns in speech: (1), the durational interaction between lexical stress and pitch accent, (2), polysyllabic shortening in pitch-accented words and (3), differential behavior of prominent and non-prominent syllables under speaking rate variation. We review the literature and present model simulations that replicate reported phenomena. Results underline the capacity of our model to provide a uniﬁed account of the temporal organization of speech.",14/09/2014,22/02/2023 10:36,22/02/2023 10:36,30/01/2023 14:19,159-163,ISCA,en,prosody,Interspeech 2014
2011,"Witteman, Marijt J.; Weber, Andrea; McQueen, James M.","On the relationship between perceived accentedness, acoustic similarity, and processing difficulty in foreign-accented speech",Interspeech 2011,,10.21437/Interspeech.2011-583,https://www.isca-speech.org/archive/interspeech_2011/witteman11_interspeech.html,"Foreign-accented speech is often perceived as more difficult to understand than native speech. What causes this potential difficulty, however, remains unknown. In the present study, we compared acoustic similarity and accent ratings of American-accented Dutch with a cross-modal priming task designed to measure online speech processing. We focused on two Dutch diphthongs: ui and ij. Though both diphthongs deviated from standard Dutch to varying degrees and perceptually varied in accent strength, native Dutch listeners recognized words containing the diphthongs easily. Thus, not all foreign-accented speech hinders comprehension, and acoustic similarity and perceived accentedness are not always predictive of processing difficulties.",27/08/2011,22/02/2023 10:36,07/03/2023 13:45,30/01/2023 14:19,2229-2232,ISCA,en,L2; perception-study; some-description; accentedness-rating; foreign-accent; foreignness; small-sample-size; unaccented/non-accented; listener-description; no-speaker-description,Interspeech 2011
2022,"Yang, Mu; Hirschi, Kevin; Looney, Stephen Daniel; Kang, Okim; Hansen, John H.L.",Improving Mispronunciation Detection with Wav2vec2-based Momentum Pseudo-Labeling for Accentedness and Intelligibility Assessment,Interspeech 2022,,10.21437/Interspeech.2022-11039,https://www.isca-speech.org/archive/interspeech_2022/yang22v_interspeech.html,"Current leading mispronunciation detection and diagnosis (MDD) systems achieve promising performance via end-to-end phoneme recognition. One challenge of such end-to-end solutions is the scarcity of human-annotated phonemes on natural L2 speech. In this work, we leverage unlabeled L2 speech via a pseudo-labeling (PL) procedure and extend the fine-tuning approach based on pre-trained self-supervised learning (SSL) models. Specifically, we use Wav2vec 2.0 as our SSL model, and fine-tune it using original labeled L2 speech samples plus the created pseudo-labeled L2 speech samples. Our pseudo labels are dynamic and are produced by an ensemble of the online model on-the-fly, which ensures that our model is robust to pseudo label noise. We show that fine-tuning with pseudo labels achieves a 5.35% phoneme error rate reduction and 2.48% MDD F1 score improvement over a labeled-samples-only finetuning baseline. The proposed PL method is also shown to outperform conventional offline PL methods. Compared to the state-of-the-art MDD systems, our MDD solution produces a more accurate and consistent phonetic error diagnosis. In addition, we conduct an open test on a separate UTD-4Accents dataset, where our system recognition outputs show a strong correlation with human perception, based on accentedness and intelligibility.",18/09/2022,22/02/2023 10:36,27/02/2023 07:47,30/01/2023 14:19,4481-4485,ISCA,en,L2; no-description-of-accent; teaching; speech-error-detection; no-def,Interspeech 2022
2017,"Yanushevskaya, Irena; Chasaide, Ailbhe Ní; Gobl, Christer",Cross-Speaker Variation in Voice Source Correlates of Focus and Deaccentuation,Interspeech 2017,,10.21437/Interspeech.2017-1535,https://www.isca-speech.org/archive/interspeech_2017/yanushevskaya17_interspeech.html,"This paper describes cross-speaker variation in the voice source correlates of focal accentuation and deaccentuation. A set of utterances with varied narrow focus placement as well as broad focus and deaccented renditions were produced by six speakers of English. These were manually inverse filtered and parameterized on a pulse-by-pulse basis using the LF source model. Z-normalized F0, EE, OQ and RD parameters (selected through correlation and factor analysis) were used to generate speaker specific baseline voice profiles and to explore cross-speaker variation in focal and non-focal (post- and prefocal) syllables. As expected, source parameter values were found to differ in the focal and postfocal portions of the utterance. For four of the six speakers the measures revealed a trend of tenser phonation on the focal syllable (an increase in EE and F0 and typically, a decrease in OQ and RD) as well as increased laxness in the postfocal part of the utterance. For two of the speakers, however, the measurements showed a different trend. These speakers had very high F0 and often high EE on the focal accent. In these cases, RD and OQ values tended to be raised rather than lowered. The possible reasons for these differences are discussed.",20/08/2017,22/02/2023 10:36,22/02/2023 10:36,30/01/2023 14:19,1034-1038,ISCA,en,prosody,Interspeech 2017
2005,"Zheng, Yanli; Sproat, Richard; Gu, Liang; Shafran, Izhak; Zhou, Haolang; Su, Yi; Jurafsky, Daniel; Starr, Rebecca; Yoon, Su-Youn",Accent detection and speech recognition for Shanghai-accented Mandarin,Interspeech 2005,,10.21437/Interspeech.2005-112,https://www.isca-speech.org/archive/interspeech_2005/zheng05_interspeech.html,"As speech recognition systems are used in ever more applications, it is crucial for the systems to be able to deal with accented speakers. Various techniques, such as acoustic model adaptation and pronunciation adaptation, have been reported to improve the recognition of non-native or accented speech. In this paper, we propose a new approach that combines accent detection, accent discriminative acoustic features, acoustic adaptation and model selection for accented Chinese speech recognition. Experimental results show that this approach can improve the recognition of accented speech.",04/09/2005,22/02/2023 10:36,07/03/2023 11:33,30/01/2023 14:19,217-220,ISCA,en,mandarin; L1; accent-identification; description-of-accent; accent-in-title,Interspeech 2005
2016,"Zheng, Hao; Zhang, Shanshan; Qiao, Liwei; Li, Jianping; Liu, Wenju",Improving Large Vocabulary Accented Mandarin Speech Recognition with Attribute-Based I-Vectors,Interspeech 2016,,10.21437/Interspeech.2016-378,https://www.isca-speech.org/archive/interspeech_2016/zheng16b_interspeech.html,"It has been well-recognized that the accent has a great impact on the ASR of Chinese Mandarin, therefore, how to improve the performance on the accented speech has become a critical issue in this ﬁeld. The attribute feature has been proven effective on modelling accented speech, resulting in a signiﬁcantly improved performance in accent recognition. In this paper, we propose an attribute-based i-vector to improve the performance of speech recognition system on large vocabulary accented Mandarine speech task. The system with proposed attribute features works well especially with sufﬁcient training data. To further promote the performance on conditions such as resource limited condition or training data mismatched condition, we also develop Multi-Task Learning Deep Neural Networks (MTLDNNs) with attribute classiﬁcation as the secondary task to improve the discriminative ability on Mandarin speech. Experiments on the 450-hour Intel accented Mandarin speech corpus demonstrate that the system with attribute-based i-vectors achieves a signiﬁcant performance improvement on sufﬁcient training data compared with the baseline DNN-HMM system. The MTL-DNNs complement the shortage of attribute-based ivectors on data limited and mismatched conditions and obtain obvious CER reductions.",08/09/2016,22/02/2023 10:36,07/03/2023 11:32,30/01/2023 14:19,3454-3458,ISCA,en,ASR; mandarin; L1; description-of-accent; lang-in-title,Interspeech 2016
2010,"Zhu, Taotao; Ke, Dengfeng; Chen, Zhenbiao; Xu, Bo",A new approach for automatic tone error detection in strong accented Mandarin based on dominant set,Interspeech 2010,,10.21437/Interspeech.2010-283,https://www.isca-speech.org/archive/interspeech_2010/zhu10b_interspeech.html,"In this paper, we proposed a new approach based on dominant set [1] for tone error detection in strong accented Mandarin. First, the ﬁnal boundary generated from forced alignment is regulated by the F0 contour in order to locate the ﬁnal domain more accurately. After that, proper normalization techniques are explored for the tone features. Finally, clustering and classiﬁcation methods based on dominant set are utilized for the tone error detection. The proposed approach is tested in comparison with the traditional k-means based method, experimental results show that it achieves more satisfying performance with an average Cross-Correlation 0.84 between human and machine, reaches to that between humans, which have veriﬁed the effectiveness of the proposed approach. The main advantage of this approach lies in not only the error pronunciation of tone can be well identiﬁed, but also the F0 pattern of the tone error can be informatively provided as the feedback.",26/09/2010,22/02/2023 10:36,07/03/2023 11:33,30/01/2023 14:19,777-780,ISCA,en,mandarin; L1; no-description-of-accent; teaching; speech-error-detection; lang-in-title,Interspeech 2010
2008,"Alotaibi, Yousef A.; Abdullah-Al-Mamun, Khondaker; Muhammad, Ghulam",Study on unique pharyngeal and uvular consonants in foreign accented Arabic,Interspeech 2008,,10.21437/Interspeech.2008-233,https://www.isca-speech.org/archive/interspeech_2008/alotaibi08_interspeech.html,"This paper investigates the unique pharyngeal and uvular consonants of Arabic from the automatic speech recognition (ASR) point of view. Comparisons of the recognition error rates for these phonemes are analyzed in five experiments that involve different combinations of native and non-native Arabic speakers. The most three confusing consonants for every investigated consonant are uncovered and discussed. Results confirm that these Arabic distinct consonants are a major source of difficulty for ASR. While the recognition rate for certain of these unique consonants such as /H/ can drop below 35% when uttered by non-native speakers, there are advantages to including non-native speakers in ASR. Regional differences in the pronunciation of Modern Standard Arabic by native Arabic speakers require attention of Arabic ASR research.",22/09/2008,22/02/2023 10:36,07/03/2023 11:26,30/01/2023 14:19,751-754,ISCA,en,L2; description-of-accent; foreign-accent; production-study; lang-in-title,Interspeech 2008
2006,"Clarke, Constance; Jurafsky, Daniel",Limitations of MLLR adaptation with Spanish-accented English: an error analysis,Interspeech 2006,,10.21437/Interspeech.2006-342,https://www.isca-speech.org/archive/interspeech_2006/clarke06_interspeech.html,"We studied the effect of MLLR adaptation with Spanishaccented English to understand the strengths and weaknesses of MLLR with unseen foreign accents. We trained a global MLLR transform on 10 adaptation sentences per speaker, giving a 3.4% absolute decrease in phone error rate. We then studied the pattern of improvements across phones and phone classes. Phones that improved the least tended to be those that do not exist in Spanish. Results suggest the poorer performance is related to increased insertion and substituter rates during the adaptation phase, as well as greater acoustic variability.",17/09/2006,22/02/2023 10:36,07/03/2023 11:29,31/01/2023 08:25,paper 1611-Tue2BuP.7-0,ISCA,en,ASR; L2; some-description; accent-in-title,Interspeech 2006
2005,"Dalton, Martha; Ní Chasaide, Ailbhe",Peak timing in two dialects of connaught irish,Interspeech 2005,,10.21437/Interspeech.2005-496,https://www.isca-speech.org/archive/interspeech_2005/dalton05_interspeech.html,A comparison of the peak location in nuclear and initial prenuclear accents was carried out for two closely related dialects of Connaught Irish: Cois Fharraige and Inis Oirr. This was done across conditions where the number of unstressed syllables following the nuclear and preceding the initial prenuclear accents was varied from 2-0. Clear differences in peak timing emerged between the two dialects. In Cois Fharraige Irish the timing of the peak is unaffected by the presence and/or number of adjacent unstressed syllables. In Inis Oirr Irish there is variability in peak timing for both prenuclear and nuclear positions. In nuclear position Inis Oirr peak realizations for the different conditions range from the left edge of the accented vowel to the post accented vowel. In prenuclear position realizations range from the left-edge of the accented vowel as far as the right edge of the post accented syllable.,04/09/2005,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:25,1377-1380,ISCA,en,prosody,Interspeech 2005
2021,"Das, Nilaksh; Bodapati, Sravan; Sunkara, Monica; Srinivasan, Sundararajan; Chau, Duen Horng",Best of Both Worlds: Robust Accented Speech Recognition with Adversarial Transfer Learning,Interspeech 2021,,10.21437/Interspeech.2021-1888,https://www.isca-speech.org/archive/interspeech_2021/das21b_interspeech.html,"Training deep neural networks for automatic speech recognition (ASR) requires large amounts of transcribed speech. This becomes a bottleneck for training robust models for accented speech which typically contains high variability in pronunciation and other semantics, since obtaining large amounts of annotated accented data is both tedious and costly. Often, we only have access to large amounts of unannotated speech from different accents. In this work, we leverage this unannotated data to provide semantic regularization to an ASR model that has been trained only on one accent, to improve its performance for multiple accents. We propose Accent Pre-Training (Acc-PT), a semi-supervised training strategy that combines transfer learning and adversarial training. Our approach improves the performance of a state-of-the-art ASR model by 33% on average over the baseline across multiple accents, training only on annotated samples from one standard accent, and as little as 105 minutes of unannotated speech from a target accent.",30/08/2021,22/02/2023 10:36,27/02/2023 07:40,31/01/2023 08:25,1314-1318,ISCA,en,ASR; L1-or-L2; no-description-of-accent; wrong-def,Interspeech 2021
2014,"Fox, Robert Allen; Jacewicz, Ewa; Hardjono, Florence",Non-native perception of regionally accented speech in a multitalker context,Interspeech 2014,,10.21437/Interspeech.2014-546,https://www.isca-speech.org/archive/interspeech_2014/fox14b_interspeech.html,"Noisy listening conditions are challenging to non-native listeners who typically perform poorly while attending to several competing talkers. This study examined whether nonnative listeners are able to utilize dialect-related cues in the target and in the masking speech, even if they do not reach the proficiency level of the native listeners. 35 Indonesian-English bilinguals residing in the United States were presented with speech stimuli from two American English dialects, General American English and Southern American English, which were systematically varied both in the target sentences and in 2-talker masking babble at three sound-to-noise ratios (SNR). We found that the non-native listeners were (1) sensitive to dialect-specific phonetic details in speech of competing talkers and (2) performed in a manner similar to native listeners despite their apparent deficit. However, their performance differed significantly when the speech levels of the competing talkers were equal (0 dB SNR). The differential sensitivity of non-native listeners may reflect their inability to separate utterances of competing talkers when there is not enough contrast in their voice levels. In turn, the lack of sufficient contrast may reduce their ability to benefit from the phonetic-acoustic details necessary to encode the signal and comprehend a message.",14/09/2014,22/02/2023 10:36,07/03/2023 13:40,31/01/2023 08:25,2548-2552,ISCA,en,L1; not-tech; description-of-accent; perception-study; great-description-of-subjects; speaker-description; listener-description,Interspeech 2014
2018,"Ghorbani, Shahram; Hansen, John H.L.",Leveraging Native Language Information for Improved Accented Speech Recognition,Interspeech 2018,,10.21437/Interspeech.2018-1378,https://www.isca-speech.org/archive/interspeech_2018/ghorbani18_interspeech.html,"Recognition of accented speech is a long-standing challenge for automatic speech recognition (ASR) systems, given the increasing worldwide population of bi-lingual speakers with English as their second language. If we consider foreign-accented speech as an interpolation of the native language (L1) and English (L2), using a model that can simultaneously address both languages would perform better at the acoustic level for accented speech. In this study, we explore how an end-to-end recurrent neural network (RNN) trained system with English and native languages (Spanish and Indian languages) could leverage data of native languages to improve performance for accented English speech. To this end, we examine pre-training with native languages, as well as multi-task learning (MTL) in which the main task is trained with native English and the secondary task is trained with Spanish or Indian Languages. We show that the proposed MTL model performs better than the pre-training approach and outperforms a baseline model trained simply with English data. We suggest a new setting for MTL in which the secondary task is trained with both English and the native language, using the same output set. This proposed scenario yields better performance with +11.95% and +17.55% character error rate gains over baseline for Hispanic and Indian accents, respectively.",02/09/2018,22/02/2023 10:36,26/02/2023 13:43,31/01/2023 08:25,2449-2453,ISCA,en,ASR; L2; some-description,Interspeech 2018
2013,"Graham, Calbert; Post, Brechtje",Realisation of tonal alignment in the English of Japanese-English late bilinguals,Interspeech 2013,,10.21437/Interspeech.2013-557,https://www.isca-speech.org/archive/interspeech_2013/graham13_interspeech.html,"Several factors have been attested to affect the temporal synchronisation of tonal targets such as syllable duration, segmental structure and proximity to word or intonational boundaries, e.g. [1], [2], [3]. Given the apparent languagespecific nature of tonal alignment [4], it can be expected that late bilinguals who are acquiring a second language will need to learn the alignment implementation rules of that language, in addition to other aspects. This study compared the tonal alignment patterns of Japanese late bilingual English speakers and monolingual English speakers in order to investigate to what extent learners transfer their native implementation strategies to the interlanguage, and whether alignment changes with proficiency. The results show that, although initialaccented words were aligned later than final-accented words for all groups, as expected, the Japanese bilinguals aligned the former significantly later than the monolinguals. Further analyses revealed that their off-target realisations were generally limited to a specific type of syllable structure that we speculate may be linked to peak delay in their L1.These results are taken as evidence of prosodic transfer and suggest that late bilinguals will need to learn the L2 phonetic implementation rules of alignment independently of their acquisition of the phonology.",25/08/2013,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:25,2390-2394,ISCA,en,prosody,Interspeech 2013
2004,"Heggtveit, Per Olav; Natvig, Jon Emil",Automatic prosody labeling of read norwegian,Interspeech 2004,,10.21437/Interspeech.2004-662,https://www.isca-speech.org/archive/interspeech_2004/heggtveit04_interspeech.html,In this paper we present initial work on a method for automatic stress and boundary labelling of read EastNorwegian. The context of this work is automatic corpus annotation for unit selection speech synthesis.,04/10/2004,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:25,2741-2744,ISCA,en,prosody,Interspeech 2004
2011,"Kalaldeh, Raya",Tonal alignment defined: the case of southern irish English,Interspeech 2011,,10.21437/Interspeech.2011-452,https://www.isca-speech.org/archive/interspeech_2011/kalaldeh11_interspeech.html,"This paper proposes to define tonal alignment features as either intrinsic; the default alignment, or extrinsic; the shifts away from the default alignment due to prosodic contextual factors. Intrinsic alignment is different for pre-nuclear (PN) and nuclear (N) accents. This distinction is illustrated for a variety of Irish English (IrE), Drogheda English (DroghE) where the PN and the N peaks of H* accents are intrinsically aligned at a time point 70% ~80% and 60% ~75% into the vowel of the accented syllable, respectively. Extrinsic alignment shifts of PN and N peaks are very small not exceeding the accented vowel boundaries.",27/08/2011,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:25,1373-1376,ISCA,en,prosody,Interspeech 2011
2016,"Kapolowicz, Michelle R.; Montazeri, Vahid; Assmann, Peter F.",The Role of Spectral Resolution in Foreign-Accented Speech Perception,Interspeech 2016,,10.21437/Interspeech.2016-1585,https://www.isca-speech.org/archive/interspeech_2016/kapolowicz16_interspeech.html,"Several studies have shown that diminished spectral resolution leads to poorer speech recognition in adverse listening conditions such as competing background noise or in cochlear implants. Although intelligibility is also reduced when the talker has a foreign accent, it is unknown how limited spectral resolution interacts with foreign-accent perception. It is hypothesized that limited spectral resolution will further impair perception of foreign-accented speech. To test this, we assessed the contribution of spectral resolution to the intelligibility of foreign-accented speech by varying the number of spectral channels in a tone vocoder. We also examined listeners’ abilities to discriminate between native and foreign-accented speech in each condition to determine the effect of reduced spectral resolution on accent detection. Results showed that increasing the spectral resolution improves intelligibility for foreign-accented speech while also improving listeners’ ability to detect a foreign accent but not to the level of accuracy for broadband speech. Results also reveal a correlation between intelligibility and accent detection. Overall, results suggest that greater spectral resolution is needed for perception of foreign-accented speech compared to native speech.",08/09/2016,22/02/2023 10:36,07/03/2023 13:56,31/01/2023 08:25,3289-3293,ISCA,en,L2; perception-study; some-description; accentedness-rating; unaccented/non-accented; speaker-description; listener-description,Interspeech 2016
2011,"Karhila, Reima; Wester, Mirjam",Rapid adaptation of foreign-accented HMM-based speech synthesis,Interspeech 2011,,10.21437/Interspeech.2011-701,https://www.isca-speech.org/archive/interspeech_2011/karhila11_interspeech.html,"This paper presents ﬁndings of listeners’ perception of speaker identity in synthetic speech. Speciﬁcally, we investigated what the effect is on the perceived identity of a speaker when using differently accented average voice models and limited amounts (ﬁve and ﬁfteen sentences) of a speaker’s data to create the synthetic stimuli. A speaker discrimination task was used to measure speaker identity. Native English listeners were presented with natural and synthetic speech stimuli in English and were asked to decide whether they thought the sentences were spoken by the same person or not. An accent rating task was also carried out to measure the perceived accents of the synthetic speech stimuli. The results show that listeners, for the most part, perform as well at speaker discrimination when the stimuli have been created using ﬁve or ﬁfteen adaptation sentences as when using 105 sentences. Furthermore, the accent of the average voice model does not affect listeners’ speaker discrimination performance even though the accent rating task shows listeners are perceiving different accents in the synthetic stimuli. Listeners do not base their speaker similarity decisions on perceived accent.",27/08/2011,22/02/2023 10:36,07/03/2023 13:59,31/01/2023 08:25,2801-2804,ISCA,en,L2; TTS; no-description-of-accent; perception-study; no-listener-description; no-speaker-description,Interspeech 2011
2022,"Kukk, Kunnar; Alumäe, Tanel",Improving Language Identification of Accented Speech,Interspeech 2022,,10.21437/Interspeech.2022-10455,https://www.isca-speech.org/archive/interspeech_2022/kukk22_interspeech.html,"Language identification from speech is a common preprocessing step in many spoken language processing systems. In recent years, this field has seen fast progress, mostly due to the use of self-supervised models pretrained on multilingual data and the use of large training corpora. This paper shows that for speech with a non-native or regional accent, the accuracy of spoken language identification systems drops dramatically, and that the accuracy of identifying the language is inversely correlated with the strength of the accent. We also show that using the output of a lexicon-free speech recognition system of the particular language helps to improve language identification performance on accented speech by a large margin, without sacrificing accuracy on native speech. We obtain relative error rate reductions ranging from to 35 to 63% over the state-of-the-art model across several non-native speech datasets.",18/09/2022,22/02/2023 10:36,27/02/2023 07:44,31/01/2023 08:25,1288-1292,ISCA,en,L2; language-identification; definition; some-description,Interspeech 2022
2014,"Lecumberri, María Luisa García; Barra-Chicote, Roberto; Ramón, Rubén Pérez; Yamagishi, Junichi; Cooke, Martin",Generating segmental foreign accent,Interspeech 2014,,10.21437/Interspeech.2014-324,https://www.isca-speech.org/archive/interspeech_2014/lecumberri14_interspeech.html,"For most of us, speaking in a non-native language involves deviating to some extent from native pronunciation norms. However, the detailed basis for foreign accent (FA) remains elusive, in part due to methodological challenges in isolating segmental from suprasegmental factors. The current study examines the role of segmental features in conveying FA through the use of a generative approach in which accent is localised to single consonantal segments. Three techniques are evaluated: the ﬁrst requires a highly-proﬁciency bilingual to produce words with isolated accented segments; the second uses cross-splicing of context-dependent consonants from the non-native language into native words; the third employs hidden Markov model synthesis to blend voice models for both languages. Using English and Spanish as the native/non-native languages respectively, listener cohorts from both languages identiﬁed words and rated their degree of FA. All techniques were capable of generating accented words, but to differing degrees. Naturally-produced speech led to the strongest FA ratings and synthetic speech the weakest, which we interpret as the outcome of over-smoothing. Nevertheless, the ﬂexibility offered by synthesising localised accent encourages further development of the method.",14/09/2014,22/02/2023 10:36,26/02/2023 12:45,31/01/2023 08:25,1302-1306,ISCA,en,L2; TTS; no def; some-description; unaccented/non-accented,Interspeech 2014
2022,"Lesnichaia, Mariia; Mikhailava, Veranika; Bogach, Natalia; Lezhenin, Iurii; Blake, John; Pyshkin, Evgeny",Classification of Accented English Using CNN Model Trained on Amplitude Mel-Spectrograms,Interspeech 2022,,10.21437/Interspeech.2022-462,https://www.isca-speech.org/archive/interspeech_2022/lesnichaia22_interspeech.html,"Automatic speech recognition is hindered by the linguistic differences occurring in accented speech. This paper advances a classification method for accented speech using a CNN-based model trained and tested on English with Germanic, Romance and Slavic accents. The input feature set was examined to find the optimal combination of time-frequency and energy characteristics of speech fed into the machine learning model. We also tuned model hyperparameters and the dimensionality of input features. We argue that mel-scale amplitude spectrograms on a liner scale appear more powerful in accent classification tasks compared to conventional feature sets based on MFCCs and raw spectrograms. Our models used only sparse data from the Speech Accent Archive, yet produced state-of-the-art classification results for English with Germanic, Romance and Slavic accents. The accuracy of our models trained on linear scale amplitude mel-spectrograms ranged from 0.964 to 0.987, outperforming existing models classifying accents using the same dataset.",18/09/2022,22/02/2023 10:36,07/03/2023 11:28,31/01/2023 08:25,3669-3673,ISCA,en,L2; accent-identification; definition; some-description; lang-in-title,Interspeech 2022
2012,"Ludusan, Bogdan; Ziegler, Stefan; Gravier, Guillaume",Integrating stress information in large vocabulary continuous speech recognition,Interspeech 2012,,10.21437/Interspeech.2012-507,https://www.isca-speech.org/archive/interspeech_2012/ludusan12_interspeech.html,"In this paper we propose a novel method for integrating stress information in the decoding step of a speech recognizer. A multiscale rhythm model was used to determine the stress scores for each syllable, which are further used to reinforce paths during search. Two strategies for integrating the stress were employed: the ﬁrst one reinforces paths through all the syllables with a value proportional to the their stress score, while the second one enhances paths passing only through stressed syllables, but with a constant value. The former strategy slightly outperforms the later, bringing a relative improvement of more than 2% over the baseline. Furthermore, the stress information proved to be a robust feature, by performing well even for foreign-accented speech.",09/09/2012,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:25,2642-2645,ISCA,en,prosody,Interspeech 2012
2011,"Minematsu, Nobuaki; Okabe, Koji; Ogaki, Keisuke; Hirose, Keikichi",Measurement of objective intelligibility of Japanese accented English using ERJ (English read by Japanese) database,Interspeech 2011,,10.21437/Interspeech.2011-310,https://www.isca-speech.org/archive/interspeech_2011/minematsu11_interspeech.html,"In many schools, English is taught as international communication tool and the goal of English pronunciation training is generally to acquire intelligible enough pronunciation, which is not always native-sounding pronunciation. However, the deﬁnition of the intelligible pronunciation is not easy because it depends on the speaking skill of a speaker, the predictability of a content, and the language background of a listener. One kind of accented pronunciation, which is intelligible enough for some listeners, is often less intelligible for others. This paper focuses on objective intelligibility of Japanese English through the ears of American English speakers with little exposure to Japanese English. A large listening test was conducted using ERJ (English Read by Japanese) database. A balanced subset of this database were presented over a telephone line to the American listeners who were asked to repeat what they heard. Totally, 17,416 repetitive responses were collected and they were transcribed manually. This paper describes the design of this experiment and some results of analyzing the results of transcription.",27/08/2011,22/02/2023 10:36,07/03/2023 11:28,31/01/2023 08:25,1481-1484,ISCA,en,L2; no-description-of-accent; teaching; intelligibility; accent-in-title,Interspeech 2011
2009,"Mixdorff, Hansjörg; Ingram, John",Prosodic analysis of foreign-accented English,Interspeech 2009,,10.21437/Interspeech.2009-666,https://www.isca-speech.org/archive/interspeech_2009/mixdorff09b_interspeech.html,"This study compares utterances by Vietnamese learners of Australian English with those of native subjects. In a previous study the utterances had been rated for foreign accent and intelligibility. We aim to find measurable prosodic differences accounting for the perceptual results. Our outcomes indicate, inter alia, that unaccented syllables are relatively longer compared with accented ones in the Vietnamese corpus than those in the Australian English corpus. Furthermore, the correlations of syllabic durations in utterances of one and the same sentence are much higher for Australian English subjects than for Vietnamese learners of English. Vietnamese speakers use a larger range of f0 and produce more pitch-accents than Australian speakers.",06/09/2009,22/02/2023 10:36,07/03/2023 11:26,31/01/2023 08:25,2527-2530,ISCA,en,L2; some-description; accentedness-rating; production-study; lang-in-title,Interspeech 2009
2013,"Mixdorff, Hansjörg; Niebuhr, Oliver",The influence of F0 contour continuity on prominence perception,Interspeech 2013,,10.21437/Interspeech.2013-73,https://www.isca-speech.org/archive/interspeech_2013/mixdorff13_interspeech.html,"The presented study concerns the influence of the syllabic structure on perceived prominence. We examined how gaps in the F0 contour due to unvoiced consonants affect prominence perception, given that such gaps can either be filled or blinded out by listeners. For this purpose we created a stimulus set of real disyllabic words which differed in the quantity of the vowel of the accented syllable nucleus and the types of subsequent intervocalic consonant(s). Results include, inter alia, that stimuli with unvoiced gaps in the F0 contour are indeed perceived as less prominent. The prominence reduction is smaller for monotonous stimuli than for stimuli with F0 excursions across the accented syllable. Moreover, in combination with F0 excursions, it also mattered whether F0 had to be interpolated or extrapolated, and whether or not the gap included a fricative sound. The results support both the filling-in and blinding-out of F0 gaps, which fits in well with earlier experiments on the production and perception of pitch.",25/08/2013,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:25,230-234,ISCA,en,prosody,Interspeech 2013
2005,"Mori, Laura; Barkat-Defradas, Melissa",Acoustic properties of foreign accent: VOT variations in Moroccan-accented Italian,Interspeech 2005,,10.21437/Interspeech.2005-768,https://www.isca-speech.org/archive/interspeech_2005/mori05b_interspeech.html,"The present study investigates the temporal parameter of VOT from a cross-language perspective, as far as native Moroccan, native Italian and Moroccanaccented Italian are concerned. The comparative analysis carried out underlines a language effect on the VOT duration across the three language varieties.",04/09/2005,22/02/2023 10:36,07/03/2023 11:27,31/01/2023 08:25,2909-2912,ISCA,en,L2; not-tech; some-description; foreign-accent; production-study; accent-in-title,Interspeech 2005
2012,"Nallasamy, Udhyakumar; Metze, Florian; Schultz, Tanja",Enhanced polyphone decision tree adaptation for accented speech recognition,Interspeech 2012,,10.21437/Interspeech.2012-516,https://www.isca-speech.org/archive/interspeech_2012/nallasamy12_interspeech.html,"State-of-the-art Automatic Speech Recognition (ASR) systems struggle to handle accented speech, particularly if the target accent is under-represented in the training data. The acoustic variations presented by an unfamiliar accent render the ASR polyphone decision tree (PDT) and its associated Gaussian mixture models (GMM) misﬁt to the test data. In this paper, we improve on the previous work of adapting the polyphone decision tree, using a semi-continuous model based approach to address the problem of data sparsity. We extend the existing PDT to introduce additional states with shared parameters, corresponding to the new contextual variations identiﬁed in the adaptation data, while still robustly estimating the state-speciﬁc parameters on a relatively small dataset. We conduct ASR experiments on Arabic and English accents and show that our technique performs better than Maximum A-Posteriori (MAP) adaptation and a previous implementation of polyphone decision tree specialization (PDTS). Compared to MAP adapted system, we obtain 7% relative improvement in Word Error Rate (WER) for Arabic and 13.7% relative improvement for English accent adaptation.",09/09/2012,22/02/2023 10:36,27/02/2023 08:14,31/01/2023 08:26,1902-1905,ISCA,en,ASR; L1-or-L2; no-description-of-accent; definition,Interspeech 2012
2007,"Ni, Xinqiang; Chen, Yining; Soong, Frank K.; Chu, Min; Zhang, Ping",An unsupervised approach to automatic prosodic annotation,Interspeech 2007,,10.21437/Interspeech.2007-225,https://www.isca-speech.org/archive/interspeech_2007/ni07_interspeech.html,"Accent is probably the most prominent part in prosodic events. Automatic accent labeling is important for both speech synthesis and automatic speech understanding. However, manually labeling data for traditional supervised learning is expensive and time consuming. In this paper, we propose an unsupervised learning algorithm to label accent automatically. First, we assume all content words are accented. We build an initial acoustic model with accented vowels in content words and high confidence unaccented vowels in function words. Then an iterative progress is executed to convergence. Experimental results show that this unsupervised learning algorithm achieves about 90% agreement on accent labeling. Compared with 84.3%, the accuracy of a typical linguistic classifier, a 30% relative error reduction is obtained.",27/08/2007,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:26,486-489,ISCA,en,prosody,Interspeech 2007
2020,"Pérez-Ramón, Rubén; Lecumberri, María Luisa García; Cooke, Martin",The Effect of Language Proficiency on the Perception of Segmental Foreign Accent,Interspeech 2020,,10.21437/Interspeech.2020-1023,https://www.isca-speech.org/archive/interspeech_2020/perezramon20_interspeech.html,"Foreign accent has different effects on speech intelligibility for native and non-native listeners. However, not much is known about the impact of individual foreign-accented segments on listeners with different levels of proﬁciency in the language. Using a technique developed to generate degrees of segmental foreign accent, this study investigates how native and non-native listeners differing in language proﬁciency categorise and discriminate degrees of accentedness at the segmental level. Listeners responded to continua ranging from Spanish-accented tokens to English tokens, constructed by inserting accented segments into words. Six continua were chosen, based on known problems faced by Spanish speakers of English. Whether foreign accent categorisation performance differed across native and nonnative listeners was found to depend on the status of the segment in the listeners’ ﬁrst language. For certain sounds both high and low proﬁciency non-native groups resembled native listener responses. For other sounds, categorisation revealed a clear effect of proﬁciency, with the high-proﬁciency group closer to native performance than the low proﬁciency cohort. This behaviour indicates an ongoing process of new second language phonemic category creation by the more proﬁcient learners.",25/10/2020,22/02/2023 10:36,07/03/2023 13:52,31/01/2023 08:26,2362-2366,ISCA,en,L2; perception-study; some-description; accentedness-rating; speaker-description; listener-description,Interspeech 2020
2012,"Saikachi, Yoko; Kitahara, Mafuyu; Nishikawa, Ken'ya; Kanato, Ai; Mazuka, Reiko",The F0 fall delay of lexical pitch accent in Japanese infant-directed speech,Interspeech 2012,,10.21437/Interspeech.2012-644,https://www.isca-speech.org/archive/interspeech_2012/saikachi12_interspeech.html,"The current study examined the acoustic modifications of the lexical pitch accent in Tokyo Japanese infant-directed speech (IDS), with the focus on the F0 fall delay, where the alignment of the F0 turning points associated with pitch accents were delayed with respect to the accented mora. The RIKEN MotherInfant Conversation Corpus (R-JMICC) [1] produced by 21 mothers from Tokyo area, was used to investigate the alignment of the F0 turning points. Two-piece linear regression was used to locate the turning points and the frequency of F0 fall delay was computed in IDS and in adult-directed speech (ADS). The results revealed that the frequency of F0 fall delay depended on the syllable structures of the accented syllable as well as the prosodic conditions (the presence of the boundary pitch movements and non-lexical lengthening) typically observed in Japanese IDS. We found significantly more frequent F0 fall delay in IDS compared to ADS, when the prosodic conditions were taken into account. The results indicate that the languagespecific prosodic structure should be considered in order to characterize the F0 fall delay of lexical pitch accents in IDS.",09/09/2012,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:26,2486-2489,ISCA,en,prosody,Interspeech 2012
2009,"Sangwan, Abhijeet; Hansen, John H. L.",On the use of phonological features for automatic accent analysis,Interspeech 2009,,10.21437/Interspeech.2009-68,https://www.isca-speech.org/archive/interspeech_2009/sangwan09_interspeech.html,"In this paper, we present an automatic accent analysis system that is based on phonological features (PFs). The proposed system exploits the knowledge of articulation embedded in phonology by rapidly build Markov models (MMs) of PFs extracted from accented speech. The Markov models capture information in the PF space along two dimensions of articulation: PF state-transitions and state-durations. Furthermore, by utilizing MMs of native and non-native accents a new statistical measure of “accentedness” is developed which rates the articulation of a word on a scale of native-like (−1) to non-native like (+1. The proposed methodology is then used to perform an automatic cross-sectional study of accented English spoken by native speakers of Mandarin Chinese (N-MC). The experimental results demonstrate the capability of the proposed system to rapidly perform quantitative as well as qualitative analysis of foreign accents. The work developed in this paper is easily assimilated into language learning systems, and has impact in the areas of speaker and speech recognition.",06/09/2009,22/02/2023 10:36,26/02/2023 11:50,31/01/2023 08:26,172-175,ISCA,en,english; L2; accent-identification; teaching; some-description; accentedness-rating,Interspeech 2009
2016,"Scharenborg, Odette; Kolkman, Elea; Kakouros, Sofoklis; Post, Brechtje",The Effect of Sentence Accent on Non-Native Speech Perception in Noise,Interspeech 2016,,10.21437/Interspeech.2016-19,https://www.isca-speech.org/archive/interspeech_2016/scharenborg16b_interspeech.html,"This paper investigates the uptake and use of prosodic information signalling sentence accent during native and nonnative speech perception in the presence of background noise. A phoneme monitoring experiment was carried out in which English, Dutch, and Finnish listeners were presented with target phonemes in semantically unpredictable yet meaningful English sentences. Sentences were presented in different levels of speech-shaped noise and, crucially, in two prosodic contexts in which the target-bearing word was either deaccented or accented. Results showed that overall performance was high for both the native and the non-native listeners; however, where native listeners seemed able to partially overcome the problems at the acoustic level in degraded listening conditions by using prosodic information signalling upcoming sentence accent, non-native listeners could not do so to the same extent. These results support the hypothesis that the performance difference between native and non-native listeners in the presence of background noise is, at least partially, caused by a reduced exploitation of contextual information during speech processing by non-native listeners.",08/09/2016,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:26,863-867,ISCA,en,prosody; not-teh,Interspeech 2016
2010,"Schweitzer, Katrin; Walsh, Michael; Möbius, Bernd; Schütze, Hinrich",Frequency of occurrence effects on pitch accent realisation,Interspeech 2010,,10.21437/Interspeech.2010-69,https://www.isca-speech.org/archive/interspeech_2010/schweitzer10_interspeech.html,"This paper presents the results of a corpus study which examines the impact of frequency of occurrence of accented words on the realisation of pitch accents. In particular, statistical analyses explore this inﬂuence on pitch accent range and alignment. The results indicate a signiﬁcant effect of frequency of occurrence on the relative height of L*H and H*L pitch accents and an also signiﬁcant but more subtle effect on the alignment of L*H accents.",26/09/2010,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:26,138-141,ISCA,en,prosody,Interspeech 2010
2007,"Shue, Yen-Liang; Iseli, Markus; Veilleux, Nanette; Alwan, Abeer",Pitch accent versus lexical stress: quantifying acoustic measures related to the voice source,Interspeech 2007,,10.21437/Interspeech.2007-690,https://www.isca-speech.org/archive/interspeech_2007/shue07_interspeech.html,"In this paper, we explore acoustic correlates of pitch accent and main lexical stress in American English, and the interaction of these cues with other factors that affect prosody. In a controlled study, we varied presence or absence and type of pitch accent (L∗ vs H∗), boundary-related tone sequence (L-L% vs. HH%) and gender of the talker, for the sentence “Dagada gave Bobby doodads”. The measures were duration, F0 (fundamental frequency), H1∗−H2∗ (related to open quotient), and H1∗−A∗3 (related to spectral tilt). Contour approximations were used to analyze time-course movements of these measures. For “Dagada” we found that, consistent with earlier literature, a) H∗ and L∗ pitch accents showed different F0 contours, b) pitchaccented syllables were longer than unaccented ones, c) stressed “ga” syllables had lower H1∗ − H2∗ values than surrounding unstressed syllables, and for male talkers, lower H1∗ − A∗3 values, indicating lesser spectral tilt. Unexpectedly, F0 maxima associated with an H∗ accent occurred most of the time later in the accented syllable than F0 minima associated with L∗. The cues to lexical stress were consistent with or without pitch accent (e.g. lower H1∗ − H2∗), but they sometimes interacted with gender and/or boundary tones: for example, lower H1∗ − A∗3 in stressed “ga” syllables was only found for female talkers in unaccented cases, and some cues of both accent and stress were less pronounced in the ﬁnal word “doodads”, which also carried boundary-related tones.",27/08/2007,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:26,2625-2628,ISCA,en,prosody,Interspeech 2007
2008,"Shue, Yen-Liang; Shattuck-Hufnagel, Stefanie; Iseli, Markus; Jun, Sun-Ah; Veilleux, Nanette; Alwan, Abeer",Effects of intonational phrase boundaries on pitch-accented syllables in american English,Interspeech 2008,,10.21437/Interspeech.2008-279,https://www.isca-speech.org/archive/interspeech_2008/shue08_interspeech.html,"Recent studies of the acoustic correlates of various prosodic elements in American English, such as prominence (in the form of phrase-level pitch accents and word-level lexical stress) and boundaries (in the form of boundary-marking tones), have begun to clarify the nature of the acoustic cues to different types and levels of these prosodic markers. This study focuses on the importance of controlling for context in such investigations, illustrating the effects of adjacent context by examining the cues to H* and L* pitch accent in early and late position in the Intonational Phrase, and how these cues vary when the accented syllable is followed immediately by boundary tones. Results show that F0 peaks for H* accents occur significantly earlier in words that also carry boundary tones, and that energy patterns are also affected; some effects on voice quality measures were also noted. Such findings highlight the caveat that the context of a particular prosodic target may significantly influence its acoustic correlates.",22/09/2008,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:26,873-876,ISCA,en,prosody,Interspeech 2008
2005,"Tjalve, Michael; Huckvale, Mark",Pronunciation variation modelling using accent features,Interspeech 2005,,10.21437/Interspeech.2005-487,https://www.isca-speech.org/archive/interspeech_2005/tjalve05_interspeech.html,"In this paper, we propose a novel method for modelling native accented speech. As an alternative to the notion of dialect, we work with the lower level phonological components of accents, which we term accent features. This provides us with a better understanding of how pronunciation varies and it allows us to give a much more detailed picture of a person’s speech.",04/09/2005,22/02/2023 10:36,27/02/2023 07:56,31/01/2023 08:26,1341-1344,ISCA,en,ASR; L1-or-L2; description-of-accent; definition,Interspeech 2005
2015,"Toman, Markus; Pucher, Michael",Evaluation of state mapping based foreign accent conversion,Interspeech 2015,,10.21437/Interspeech.2015-122,https://www.isca-speech.org/archive/interspeech_2015/toman15_interspeech.html,We present an evaluation of the perception of foreign-accented natural and synthetic speech in comparison to accent-reduced synthetic speech. Our method for foreign accent conversion is based on mapping of Hidden Semi-Markov Model states between accented and non-accented voice models and does not need an average voice model of accented speech. We employ the method on recorded data of speakers with ﬁrst language (L1) from different European countries and second language (L2) being Austrian German. Results from a subjective evaluation show that the proposed method is able to signiﬁcantly reduce the perceived accent. It also retains speaker similarity when an average voice model of the same gender is used. Accentedness of synthetic speech was rated signiﬁcantly lower than natural speech by the participants and listeners were unable to identify accents correctly for 81% of the natural and 85% of the synthesized samples. Our evaluation shows the feasibility of accent conversion with a limited amount of speech resources.,06/09/2015,22/02/2023 10:36,07/03/2023 13:44,31/01/2023 08:26,304-308,ISCA,en,L2; no-description-of-accent; perception-study; teaching; accentedness-rating; unaccented/non-accented; accent-reduction; no-listener-description; no-speaker-description,Interspeech 2015
2018,"Tu, Ming; Grabek, Anna; Liss, Julie; Berisha, Visar",Investigating the Role of L1 in Automatic Pronunciation Evaluation of L2 Speech,Interspeech 2018,,10.21437/Interspeech.2018-1350,https://www.isca-speech.org/archive/interspeech_2018/tu18_interspeech.html,"Automatic pronunciation evaluation plays an important role in pronunciation training and second language education. This ﬁeld draws heavily on concepts from automatic speech recognition (ASR) to quantify how close the pronunciation of nonnative speech is to native-like pronunciation. However, it is known that the formation of accent is related to pronunciation patterns of both the target language (L2) and the speaker’s ﬁrst language (L1). In this paper, we propose to use two native speech acoustic models, one trained on L2 speech and the other trained on L1 speech. We develop two sets of measurements that can be extracted from two acoustic models given accented speech. A new utterance-level feature extraction scheme is used to convert these measurements into a ﬁxed-dimension vector which is used as an input to a statistical model to predict the accentedness of a speaker. On a data set consisting of speakers from 4 different L1 backgrounds, we show that the proposed system yields improved correlation with human evaluators compared to systems only using the L2 acoustic model.",02/09/2018,22/02/2023 10:36,07/03/2023 13:54,31/01/2023 08:26,1636-1640,ISCA,en,L2; perception-study; teaching; accentedness-rating; unaccented/non-accented; no-listener-description; no-speaker-description,Interspeech 2018
2010,"Vergyri, Dimitra; Lamel, Lori; Gauvain, Jean-Luc",Automatic speech recognition of multiple accented English data,Interspeech 2010,,10.21437/Interspeech.2010-477,https://www.isca-speech.org/archive/interspeech_2010/vergyri10_interspeech.html,"Accent variability is an important factor in speech that can signiﬁcantly degrade automatic speech recognition performance. We investigate the effect of multiple accents on an English broadcast news recognition system. A multi-accented English corpus is used for the task, including broadcast news segments from 6 different geographic regions: US, Great Britain, Australia, North Africa, Middle East and India. There is signiﬁcant performance degradation of a baseline system trained on only US data when confronted with shows from other regions. The results improve signiﬁcantly when data from all the regions are included for accent-independent acoustic model training. Further improvements are achieved when MAP-adapted accentdependent models are used in conjunction with a GMM accent classiﬁer.",26/09/2010,22/02/2023 10:36,27/02/2023 08:14,31/01/2023 08:26,1652-1655,ISCA,en,ASR; L1-or-L2; no-description-of-accent; no-def,Interspeech 2010
2010,"Yanushevskaya, Irena; Gobl, Christer; Kane, John; Ní Chasaide, Ailbhe",An exploration of voice source correlates of focus,Interspeech 2010,,10.21437/Interspeech.2010-198,https://www.isca-speech.org/archive/interspeech_2010/yanushevskaya10_interspeech.html,"This pilot study explores how the voice source parameters vary in focally accented syllables. It examines the dynamics of the voice source parameters in an all-voiced short declarative utterance in which the focus placement was varied. The voice source parameters F0, EE, UP, OQ, RG, RA, RK and RD were obtained through inverse filtering and subsequent parameterisation using the LF-model. The results suggest that the focally accented syllables are marked not only by increased F0 but also by boosted EE, RG and UP. The non-focal realisations show reduced values for the above parameters along with a tendency towards higher OQ values, suggesting a more lax mode of phonation.",26/09/2010,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:26,462-465,ISCA,en,prosody,Interspeech 2010
2005,"You, Hong; Alwan, Abeer; Kazemzadeh, Abe; Narayanan, Shrikanth",Pronunciation variations of Spanish-accented English spoken by young children,Interspeech 2005,,10.21437/Interspeech.2005-349,https://www.isca-speech.org/archive/interspeech_2005/you05_interspeech.html,"When learning to speak English, non-native speakers may pronounce some English phonemes differently from native speakers. These pronunciation variations can degrade an automatic speech recognition system’s performance on accented English. This paper is a ﬁrst attempt to ﬁnd common pronunciation variations in Spanishaccented English as spoken by young children. The analysis of pronunciation variation is performed using dynamic programming-based transcription alignment on 4500 words spoken by children 5-7 years old whose ﬁrst language is Spanish. The ﬁndings are then compared with linguistic hypotheses.",04/09/2005,22/02/2023 10:36,07/03/2023 11:29,31/01/2023 08:26,749-752,ISCA,en,L2; not-tech; description-of-accent; production-study; accent-in-title,Interspeech 2005
2022,"Zhang, Yuanyuan; Zhang, Yixuan; Halpern, Bence; Patel, Tanvina; Scharenborg, Odette",Mitigating bias against non-native accents,Interspeech 2022,,10.21437/Interspeech.2022-836,https://www.isca-speech.org/archive/interspeech_2022/zhang22n_interspeech.html,"Automatic speech recognition (ASR) systems have seen substantial improvements in the past decade; however, not for all speaker groups. Recent research shows that bias exists against different types of speech, including non-native accents, in stateof-the-art (SOTA) ASR systems. To attain inclusive speech recognition, i.e., ASR for everyone irrespective of how one speaks or the accent one has, bias mitigation is necessary. Here we focus on bias mitigation against non-native accents using two different approaches: data augmentation and by using more effective training methods. We used an autoencoderbased cross-lingual voice conversion (VC) model to increase the amount of non-native accented speech training data in addition to data augmentation through speed perturbation. Moreover, we investigate two training methods, i.e., fine-tuning and domain adversarial training (DAT), to see whether they can use the limited non-native accented speech data more effectively than a standard training approach. Experimental results show that VCbased data augmentation successfully mitigates the bias against non-native accents for the SOTA end-to-end (E2E) Dutch ASR system. Combining VC and speed perturbed data gave the lowest word error rate (WER) and the smallest bias against nonnative accents. Fine-tuning and DAT reduced the bias against non-native accents but at the cost of native performance.",18/09/2022,22/02/2023 10:36,27/02/2023 07:53,31/01/2023 08:26,3168-3172,ISCA,en,ASR; L2; definition; some-description,Interspeech 2022
2011,"Zheng, Rong; Zhang, Ce; Xu, Bo",Data-driven UBM generation via tied Gaussians for GMM-supervector based accent identification,Interspeech 2011,,10.21437/Interspeech.2011-325,https://www.isca-speech.org/archive/interspeech_2011/zheng11b_interspeech.html,"This paper presents a new approach to exploit data-driven universal background model (UBM) generation using tied Gaussians for accent identification (AID). The motivation of the proposed algorithm is to potentially utilize broad phoneticspecific accent characteristics by Gaussian mixture model (GMM) and examine data-driven phonetically-inspired UBM creation for GMM-supervector based accent classification. In this work, we discuss the issues involved in applying cumulative posterior probability based Gaussian selection and tree structure based UBM parameter estimation. Derivation and validation of the UBM refined by tied Gaussians are reported in this paper. Performance evaluations comparing our system with other well-known techniques for AID are also provided. Better performance is further achieved by fusing these acoustic-based accent classifiers. Comparison experiments conducted on the CSLU foreign-accented English (FAE) dataset show the effectiveness of the proposed method.",27/08/2011,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:26,845-848,ISCA,en,accent-identification,Interspeech 2011
2004,"Aalburg, Stefanie; Hoege, Harald",Foreign-accented speaker-independent speech recognition,Interspeech 2004,,10.21437/Interspeech.2004-558,https://www.isca-speech.org/archive/interspeech_2004/aalburg04_interspeech.html,"This research investigated whether acoustic-phonetic knowledge of the mother tongue of a non-native speaker can be used to adapt an existing target language phoneme HMM recognizer. For this purpose three sets of phoneme HMMs were generated, one representing the target language (German), one the mother tongue of the non-native speaker (Turkish), and the third the foreign-accented pronunciation of the target language (German spoken by Turkish speakers). The latter served as a benchmark for the tested adaptation methods. A derived Hidden Markov Model (HMM) clustering algorithm was applied on the target language phoneme HMM set using the mother tongue phoneme HMM set of the non-native speaker. Following the HMM adaptation a phoneme-level pronunciation technique was applied to generate phoneme mapping rules for the lexicon adaptation task. The results revealed a relative reduction of about 6% in WER for the adapted HMM. No further improvements were observed from the lexicon adaptation task.",04/10/2004,22/02/2023 10:36,26/02/2023 11:13,31/01/2023 08:26,1465-1468,ISCA,en,ASR; L2; some-description; foreign-accent,Interspeech 2004
2012,"Badino, Leonardo; Clark, Robert A. J.; Wester, Mirjam",Towards hierarchical prosodic prominence generation in TTS synthesis,Interspeech 2012,,10.21437/Interspeech.2012-628,https://www.isca-speech.org/archive/interspeech_2012/badino12_interspeech.html,"We address the problem of identiﬁcation (from text) and generation of pitch accents in HMM-based English TTS synthesis. We show, through a large scale perceptual test, that a large improvement of the binary discrimination between pitch accented and non-accented words has no effect on the quality of the speech generated by the system. On the other side adding a third accent type that emphatically marks words that convey ”contrastive” focus (automatically identiﬁed from text) produces beneﬁcial effects on the synthesized speech. These results support the accounts on prosodic prominence that consider the prosodic patterns of utterances as hierarchical structured and point out the limits of a ﬂattening of such structure resulting from a simple accent/non-accent distinction.",09/09/2012,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:26,2398-2401,ISCA,en,prosody,Interspeech 2012
2013,"Cheng, Jian; Bojja, Nikhil; Chen, Xin",Automatic accent quantification of indian speakers of English,Interspeech 2013,,10.21437/Interspeech.2013-579,https://www.isca-speech.org/archive/interspeech_2013/cheng13_interspeech.html,"In addition to measuring job candidates spoken English proﬁciency, quantifying the degree of accentedness may help companies assign employees to appropriate job categories, or identify employees who could beneﬁt from additional speech training. In this paper, we discuss methods for automatic accent quantiﬁcation of Indian English speakers. Similar to techniques used in speaker recognition, we used Gaussian mixture models (GMMs) for the modeling of accent spectral characteristics in different groups of subjects. Computationally, we veriﬁed that certain consonants in Indian English have more discriminative power than others in quantifying an Indian accent. As a result, we propose the idea of using GMMs to model only certain phonemes with high predictive power. By combining features from GMMs with others, we achieved a human-machine correlation coefﬁcient of 0.84 at the participant level. The results validate the use of new proposed methods to quantify accents automatically.",25/08/2013,22/02/2023 10:36,07/03/2023 13:48,31/01/2023 08:26,2574-2578,ISCA,en,english; L2; accent-identification; linguistic-discrimination; perception-study; wrong-def; some-description; accentedness-rating; accent-in-title; lang-in-title; no-listener-description; no-speaker-description,Interspeech 2013
2016,"Jügler, Jeanin; Zimmerer, Frank; Trouvain, Jürgen; Möbius, Bernd",The Perceptual Effect of L1 Prosody Transplantation on L2 Speech: The Case of French Accented German,Interspeech 2016,,10.21437/Interspeech.2016-1268,https://www.isca-speech.org/archive/interspeech_2016/jugler16_interspeech.html,"Research has shown that language learners are not only challenged by segmental differences between their native language (L1) and the second language (L2). They also have problems with the correct production of suprasegmental structures, like phone/syllable duration and the realization of pitch. These difﬁculties often lead to a perceptible foreign accent. This study investigates the inﬂuence of prosody transplantation on foreign accent ratings. Syllable duration and pitch contour were transferred from utterances of a male and female German native speaker to utterances of ten French native speakers speaking German. Acoustic measurements show that French learners spoke with a signiﬁcantly lower speaking rate. As expected, results of a perception experiment judging the accentedness of 1) German native utterances, 2) unmanipulated and 3) manipulated utterances of French learners of German suggest that the transplantation of the prosodic features syllable duration and pitch leads to a decrease in accentedness rating. These ﬁndings conﬁrm results found in similar studies investigating prosody transplantation with different L1 and L2 and provide a beneﬁcial technique for (computer-assisted) pronunciation training.",08/09/2016,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:44,67-71,ISCA,en,not-tech,Interspeech 2016
2020,"Turan, M.A. Tuğtekin; Vincent, Emmanuel; Jouvet, Denis",Achieving Multi-Accent ASR via Unsupervised Acoustic Model Adaptation,Interspeech 2020,,10.21437/Interspeech.2020-2742,https://www.isca-speech.org/archive/interspeech_2020/turan20_interspeech.html,"Current automatic speech recognition (ASR) systems trained on native speech often perform poorly when applied to non-native or accented speech. In this work, we propose to compute xvector-like accent embeddings and use them as auxiliary inputs to an acoustic model trained on native data only in order to improve the recognition of multi-accent data comprising native, non-native, and accented speech. In addition, we leverage untranscribed accented training data by means of semi-supervised learning. Our experiments show that acoustic models trained with the proposed accent embeddings outperform those trained with conventional i-vector or x-vector speaker embeddings, and achieve a 15% relative word error rate (WER) reduction on nonnative and accented speech w.r.t. acoustic models trained with regular spectral features only. Semi-supervised training using just 1 hour of untranscribed speech per accent yields an additional 15% relative WER reduction w.r.t. models trained on native data only.",25/10/2020,22/02/2023 10:36,27/02/2023 08:16,31/01/2023 08:44,1286-1290,ISCA,en,ASR; L1-or-L2; some-description; no-def,Interspeech 2020
2005,"Yeou, Mohamed",Variability of F0 peak alignment in moroccan Arabic accentual focus,Interspeech 2005,,10.21437/Interspeech.2005-510,https://www.isca-speech.org/archive/interspeech_2005/yeou05_interspeech.html,"The present paper examines how phonetic duration due to syllable structure contributes to the alignment of F0 peaks in Moroccan Arabic. The F0 peak occurs within but near the end of the accented syllable if the vowel is phonetically long due its occurrence in a final CVC. If the accented vowel is phonetically short as in a penultimate CV, the F0 peak is aligned after the accented syllable.",04/09/2005,22/02/2023 10:36,22/02/2023 10:36,31/01/2023 08:50,1433-1436,ISCA,en,prosody,Interspeech 2005
